[{"path":"/CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributions - interactions surrounding- project abide USGS Code Scientific Conduct. contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http:contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":"/DISCLAIMER.html","id":null,"dir":"","previous_headings":"","what":"Disclaimer","title":"Disclaimer","text":"software preliminary provisional subject revision. provided meet need timely best science. software received final approval U.S. Geological Survey (USGS). warranty, expressed implied, made USGS U.S. Government functionality software related material shall fact release constitute warranty. software provided condition neither USGS U.S. Government shall held liable damages resulting authorized unauthorized use software.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"License","title":"License","text":"Unless otherwise noted, project public domain United States contains materials originally came United States Geological Survey, agency United States Department Interior. information, see official USGS copyright policy https://www.usgs.gov/information-policies--instructions/copyrights--credits Additionally, waive copyright related rights work worldwide CC0 1.0 Universal public domain dedication.","code":""},{"path":"/LICENSE.html","id":"cc0-10-universal-summary","dir":"","previous_headings":"","what":"CC0 1.0 Universal Summary","title":"License","text":"human-readable summary Legal Code (read full text).","code":""},{"path":"/LICENSE.html","id":"no-copyright","dir":"","previous_headings":"CC0 1.0 Universal Summary","what":"No Copyright","title":"License","text":"person associated work deed dedicated work public domain waiving rights work worldwide copyright law, including related neighboring rights, extent allowed law. can copy, modify, distribute perform work, even commercial purposes, without asking permission.","code":""},{"path":"/LICENSE.html","id":"other-information","dir":"","previous_headings":"CC0 1.0 Universal Summary","what":"Other Information","title":"License","text":"way patent trademark rights person affected CC0, rights persons may work work used, publicity privacy rights. Unless expressly stated otherwise, person associated work deed makes warranties work, disclaims liability uses work, fullest extent permitted applicable law. using citing work, imply endorsement author affirmer.","code":""},{"path":"/articles/AlternativeQMethod.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using a WRTDS model where the discharge variable is not daily discharge","text":"Sometimes usual formulation WRTDS ideal, believe daily discharge sampling day good explanatory variable, idea better variable might use. Dams reservoirs create situations may issue. common example might discharge sampling location really just determined decision dam operator real measure hydrologic conditions watershed reservoir. work example data set Green River near Greendale, UT, variable interest total dissolved solids. streamgage immediately downstream Flaming Gorge Reservoir. period water quality record work covers water years 1966 2000. daily discharge record site strongly controlled release decisions made dam (delivery downstream water users hydropower) closely related hydrologic conditions watershed (covers 19,400 square miles) includes high mountain areas Wind River Range well lot high desert southwestern Wyoming. attempt use streamgage located just upstream reservoir, Green River near Green River Wyoming (location John Wesley Powell started famous journey Grand Canyon). streamgage drainage area 14,000 square miles, much intervening drainage area two streamgages quite arid, flows upper gage make large fraction water comes downstream end full watershed. thinking TDS values dam might much better explained running mean discharges upstream site, indicative basin-wide hydrologic conditions. reservoir stores much water, expect concentrations outflow change gradually given large mixing volume reservoir. fact, full-pool capacity reservoir equal 2.5 years streamflow. start pulling data sets Greendale streamgage running standard WRTDS model TDS, also pull discharge data Green River streamgage use later. setting example also input two functions EGRET point. called “errorStats.R” “estDailyFromSurfacesNEW.R”.     think seeing final plot end 1977 drought, WRTDS model expects concentrations come back normal range, actually end higher drought usual low-TDS inflow Spring Summer 1977 never really came thus contents reservoir went much higher concentration one expect time year. can evaluate accuracy WRTDS model whole period modeled computing R-square value. computed (Var(log(C)) - Var(errors log(C))) / Var(log(C). use code “computeRsq.R” . Notice Rsquared log(Flux) high, nearly 98%. , really “dishonest” measure quality model, much flux determined discharge. really honest measure quality model Rsquared log(Concentration) 58%.","code":"library(EGRET) library(zoo) # zoo is a time series package, needed for rolling means ##  ## Attaching package: 'zoo' ## The following objects are masked from 'package:base': ##  ##     as.Date, as.Date.numeric ################## sta <- \"09234500\" param <- \"70301\" startDate <- \"1966-10-01\" endDate <- \"2000-09-30\" INFO <- readNWISInfo(sta, param, interactive = FALSE) Daily <- readNWISDaily(sta, \"00060\", startDate, endDate) ## There are 12419 data points, and 12419 days. Sample <- readNWISSample(sta, param, startDate, endDate) ## Warning: NWIS qw web services are being retired. ## Please see vignette('qwdata_changes', package = 'dataRetrieval') ## for more information. ## https://cran.r-project.org/web/packages/dataRetrieval/vignettes/qwdata_changes.html eList <- mergeReport(INFO, Daily, Sample) ##  ##  Discharge Record is 12419 days long, which is 34 years ##  First day of the discharge record is 1966-10-01 and last day is 2000-09-30 ##  The water quality record has 324 samples ##  The first sample is from 1966-10-04 and the last sample is from 2000-08-30 ##  Discharge: Minimum, mean and maximum 11.9 62.6 348 ##  Concentration: Minimum, mean and maximum 320 470 630 ##  Percentage of the sample values that are censored is 0 % INFO <- eList$INFO  # we will need this later Sample <- eList$Sample  # we will need this later multiPlotDataOverview(eList, logScaleConc = FALSE) # let's also see what a little slice of the discharge record looks like plotQTimeDaily(eList, yearStart = 1975, yearEnd = 1979, qLower = 0, qUnit = 2, lwd = 1) eListRegular <- modelEstimation(eList) ##  ##  first step running estCrossVal may take about 1 minute ##  estCrossVal % complete: ## 0    1   2   3   4   5   6   7   8   9   10   ## 11   12  13  14  15  16  17  18  19  20   ## 21   22  23  24  25  26  27  28  29  30   ## 31   32  33  34  35  36  37  38  39  40   ## 41   42  43  44  45  46  47  48  49  50   ## 51   52  53  54  55  56  57  58  59  60   ## 61   62  63  64  65  66  67  68  69  70   ## 71   72  73  74  75  76  77  78  79  80   ## 81   82  83  84  85  86  87  88  89  90   ## 91   92  93  94  95  96  97  98  99   ## Next step running  estSurfaces with survival regression: ## Survival regression (% complete): ## 0    1   2   3   4   5   6   7   8   9   10   ## 11   12  13  14  15  16  17  18  19  20   ## 21   22  23  24  25  26  27  28  29  30   ## 31   32  33  34  35  36  37  38  39  40   ## 41   42  43  44  45  46  47  48  49  50   ## 51   52  53  54  55  56  57  58  59  60   ## 61   62  63  64  65  66  67  68  69  70   ## 71   72  73  74  75  76  77  78  79  80   ## 81   82  83  84  85  86  87  88  89  90   ## 91   92  93  94  95  96  97  98  99   ## Survival regression: Done fluxBiasMulti(eListRegular) # let's see how the model worked out going into and coming out of a severe drought year plotConcTimeDaily(eListRegular, yearStart = 1977.0, yearEnd = 1979.0) errorStats(eListRegular) ##  ##  Root Mean Squared Error in natural log units =  0.0738 ##  Rsquared for natural log of concentration    =  0.583 ##  Rsquared for natural log of flux             =  0.979 ##  Standard error of estimate = 7.39 % ##   RsqLogC RsqLogF   rmse sepPercent ## 1   0.583   0.979 0.0738       7.39"},{"path":"/articles/AlternativeQMethod.html","id":"bringing-in-the-upstream-discharge-data-and-computing-the-rolling-mean","dir":"Articles","previous_headings":"","what":"Bringing in the upstream discharge data and computing the rolling mean","title":"Using a WRTDS model where the discharge variable is not daily discharge","text":"Now, let’s bring data upstream site. bringing discharge data, start record 5 years prior start Daily record using Greendale site. want running averages might want consider averages run back years (since reservoir stores multiple years worth water).  Now, want try using rolling mean inflows upstream site explanatory variable place discharge Greendale. need explore couple things. One far back time want rolling mean start. Given large reservoir size average flow ’d like consider rolling means go back years. start 1-year rolling mean, step longer shorter ones later. going . take Daily data frame Greendale (downstream) site create new column called Qa (meaning Q actual) use later process actually compute fluxes. 1-year rolling mean upstream site (GreenRiver) put Daily data frame call Q, compute natural log Q put LogQ column. One thing need think need Green River data go back prior period estimating Greendale, can rolling means, clip dates Daily record Green River exactly match dates Daily record Greendale. ’s code .  , see new discharge time series much less variable original. raises interesting point. estimate WRTDS model new Q variable, doesn’t make sense use standard assumption good value windowQ variable. Normally, find windowQ = 2 works well regular discharge data sets? , reasonable expect may large value, LogQ much less variable original Q variable. , first crack problem ’m going set windowQ equal half interquartile range LogQ rolling mean discharge. (little extra stuff see assumption using half interquartile range good choice. experience tells pretty good results pretty insensitive choice.) let’s estimate model evaluate model using computeRsq function.  can see boosted Rsquared value original value 0.583 new value 0.647. getting somewhat better, selection 1-year rolling mean window just guess. Let’s try values. Let’s one half width (half year), one twice width (2 year) see either better 1-year. half year rolling mean   now 2 year rolling mean   , see half-year rolling mean didn’t us good. model got worse. 2 year improvement. Rsquared went 0.72. , question now, 3 year window. Might work better? ’m going show results , , Rsquared went slightly 2 year window (Rsquared 0.70). ’m going declare best option use 2-year rolling mean. (don’t like idea using non-integers number years rolling mean seasonality discharge variable. work simple think ).","code":"staUp <- \"09217000\" startUp <- \"1961-10-01\" DailyUp <- readNWISDaily(staUp, \"00060\", startUp, endDate) ## There are 14245 data points, and 14245 days. # we can take a look at the record here plot(DailyUp$Date, DailyUp$Q, type = \"l\", ylim = c(0, 500), yaxs = \"i\", tck = 0.02) Daily <- eListRegular$Daily Daily$Qa <- Daily$Q DailyUpTemp <- DailyUp DailyUpTemp$Q <- rollmean(DailyUp$Q,365, fill = NA, align = \"right\") # note that fill = NA means that if we are trying to compute the rolling mean and there # aren't enough prior values to do it we just put in an NA # align = \"right\" means that we associate the rolling mean with the \"right most\" (final) date DailyUpTemp <- subset(DailyUpTemp, Date >= startDate) # let's check that DailyUpTemp is exactaly as long as Daily length(DailyUpTemp$Q) ## [1] 12419 length(Daily$Q) ## [1] 12419 Daily$Q <- DailyUpTemp$Q Daily$LogQ <- log(Daily$Q) # now we create a new eList that uses this rolling mean discharge eListRoll <- mergeReport(INFO, Daily, Sample) ##  ##  Discharge Record is 12419 days long, which is 34 years ##  First day of the discharge record is 1966-10-01 and last day is 2000-09-30 ##  The water quality record has 324 samples ##  The first sample is from 1966-10-04 and the last sample is from 2000-08-30 ##  Discharge: Minimum, mean and maximum 14.7 49.4 89.3 ##  Concentration: Minimum, mean and maximum 320 470 630 ##  Percentage of the sample values that are censored is 0 % # here is the time series of the 1-year rolling mean, plotted on the same scale as before plot(eListRoll$Daily$Date, eListRoll$Daily$Q, type = \"l\", ylim = c(0, 500), yaxs = \"i\", tck = 0.02) iqr <- IQR(eListRoll$Daily$LogQ) iqr ## [1] 0.5009981 # for comparison let's look at the IQR for the original model we estimated IQR(eList$Daily$LogQ) ## [1] 0.8206605 # now let's estimate the new model using the rolling mean in place of the daily discharge eListRoll <- modelEstimation(eListRoll, windowQ = 0.5 * iqr, verbose = FALSE) # let's see how this new model does at estimating the concentration for that 1977-1978 period # that we looked at before plotConcTimeDaily(eListRoll, yearStart = 1977.0, yearEnd = 1979.0) # recall that with the original model the Rsq value was 0.583 errorStats(eListRoll) ##  ##  Root Mean Squared Error in natural log units =  0.0679 ##  Rsquared for natural log of concentration    =  0.647 ##  Rsquared for natural log of flux             =  0.961 ##  Standard error of estimate = 6.79 % ##   RsqLogC RsqLogF   rmse sepPercent ## 1   0.647   0.961 0.0679       6.79 Daily <- eList$Daily Daily$Qa <- Daily$Q DailyUpTemp <- DailyUp DailyUpTemp$Q <- rollmean(DailyUp$Q, 182, fill = NA, align = \"right\") DailyUpTemp <- subset(DailyUpTemp, Date >= startDate) # let's check that DailyUpTemp is exactaly as long as Daily length(DailyUpTemp$Q) ## [1] 12419 length(Daily$Q) ## [1] 12419 Daily$Q <- DailyUpTemp$Q Daily$LogQ <- log(Daily$Q) # now we create a new eList that uses this rolling mean discharge eListRoll <- mergeReport(INFO, Daily, Sample) ##  ##  Discharge Record is 12419 days long, which is 34 years ##  First day of the discharge record is 1966-10-01 and last day is 2000-09-30 ##  The water quality record has 324 samples ##  The first sample is from 1966-10-04 and the last sample is from 2000-08-30 ##  Discharge: Minimum, mean and maximum 7.59 49.4 154 ##  Concentration: Minimum, mean and maximum 320 470 630 ##  Percentage of the sample values that are censored is 0 % # here is the time series of the half-year rolling mean, plotted on the same scale as before plot(eListRoll$Daily$Date, eListRoll$Daily$Q, type = \"l\", ylim = c(0, 500), yaxs = \"i\", tck = 0.02) iqr <- IQR(eListRoll$Daily$LogQ) iqr ## [1] 0.8526911 # now let's estimate the new model using the rolling mean in place of the daily discharge eListRoll <- modelEstimation(eListRoll, windowQ = 0.5 * iqr, verbose = FALSE) # let's see how this new model does at estimating the concentration for that 1977-1978 period # that we looked at before plotConcTimeDaily(eListRoll, yearStart = 1977.0, yearEnd = 1979.0) # recall that with the original model the Rsq value was 0.583 errorStats(eListRoll) ##  ##  Root Mean Squared Error in natural log units =  0.0758 ##  Rsquared for natural log of concentration    =  0.56 ##  Rsquared for natural log of flux             =  0.981 ##  Standard error of estimate = 7.59 % ##   RsqLogC RsqLogF   rmse sepPercent ## 1    0.56   0.981 0.0758       7.59 Daily <- eList$Daily Daily$Qa <- Daily$Q DailyUpTemp <- DailyUp DailyUpTemp$Q <- rollmean(DailyUp$Q, 730, fill = NA, align = \"right\") DailyUpTemp <- subset(DailyUpTemp, Date >= startDate) # let's check that DailyUpTemp is exactaly as long as Daily length(DailyUpTemp$Q) ## [1] 12419 length(Daily$Q) ## [1] 12419 Daily$Q <- DailyUpTemp$Q Daily$LogQ <- log(Daily$Q) # now we create a new eList that uses this rolling mean discharge eListRoll <- mergeReport(INFO, Daily, Sample) ##  ##  Discharge Record is 12419 days long, which is 34 years ##  First day of the discharge record is 1966-10-01 and last day is 2000-09-30 ##  The water quality record has 324 samples ##  The first sample is from 1966-10-04 and the last sample is from 2000-08-30 ##  Discharge: Minimum, mean and maximum 21.1 49.7 82 ##  Concentration: Minimum, mean and maximum 320 470 630 ##  Percentage of the sample values that are censored is 0 % # here is the time series of the 2-year rolling mean, plotted on the same scale as before plot(eListRoll$Daily$Date, eListRoll$Daily$Q, type = \"l\", ylim = c(0, 500), yaxs = \"i\", tck = 0.02) iqr <- IQR(eListRoll$Daily$LogQ) iqr ## [1] 0.4638389 # now let's estimate the new model using the rolling mean in place of the daily discharge eListRoll <- modelEstimation(eListRoll, windowQ = 0.5 * iqr, verbose = FALSE) # let's see how this new model does at estimating the concentration for that 1977-1978 period # that we looked at before plotConcTimeDaily(eListRoll, yearStart = 1977.0, yearEnd = 1979.0) # recall that with the original model the Rsq value was 0.583 errorStats(eListRoll) ##  ##  Root Mean Squared Error in natural log units =  0.0602 ##  Rsquared for natural log of concentration    =  0.723 ##  Rsquared for natural log of flux             =  0.939 ##  Standard error of estimate = 6.02 % ##   RsqLogC RsqLogF   rmse sepPercent ## 1   0.723   0.939 0.0602       6.02"},{"path":"/articles/AlternativeQMethod.html","id":"how-do-we-use-the-selected-model","dir":"Articles","previous_headings":"","what":"How do we use the selected model","title":"Using a WRTDS model where the discharge variable is not daily discharge","text":"Let’s review . build WRTDS model TDS Flaming Gorge Reservoir, discharge variable used estimation daily discharge sampling site, rather two-year rolling mean discharge streamgage upstream reservoir. means explanatory variable 2-year mean discharge upstream site computed day sample collected reservoir. (gotten little complex used 2-year mean computed days sample collected, compensate travel time water dam, didn’t feel make much difference. Perhaps going published study .) Note also Daily data frame also stored actual discharge day sampling site dam, call Qa. need , go compute estimated flux estimated discharge need actual discharge sampling site 2-year rolling mean. can view concentration trend.  Now, need fix flux results reflect fact concentration values need multiplied Qa even though Q variable used model rolling mean upstream site. Fortunately, thanks Laura DeCicco, code exactly .   can look record terms extent trend using tableChange, also turn tables annual results. works usual. two things particular note . One table change interesting slopes %/yr virtually identical concentration flux. just expect coming lorge body water dissolved phase. thing note discharge values tableResults output correct. annual average rolling mean discharges upstream gage. , major drought 1977 actually show 1978. get accurate list one go way back original eList site (without upstream flow data) tableResults (using eListRegular) correct discharges appear .","code":"plotConcHist(eListRoll) # but using plotFluxHist() would be meaningless, because the Q variable is the rolling mean and not the daily Q estDailyFromSurfaces_Qa <- function(eList, localsurfaces = NA, localDaily = NA) {      if(!is.egret(eList)){     stop(\"Please check eList argument\")   }      localDaily <- getSurfaceEstimates(eList, localsurfaces=localsurfaces, localDaily = localDaily)   # Calculate \"flow-normalized\" concentration and flux:   allLogQsByDayOfYear <- bin_Qs(localDaily)      concFlux_list <- getConcFluxFromSurface(eList, allLogQsByDayOfYear, localDaily = localDaily, localsurfaces=localsurfaces)      localDaily$LogQ <- log(localDaily$Qa)      allLogQsByDayOfYear <- bin_Qs(localDaily)   allLogQsReplicated <- allLogQsByDayOfYear[localDaily$Day]      allFluxReplicated <- concFlux_list[[\"allConcReplicated\"]] * exp(as.numeric(unlist(allLogQsReplicated))) * 86.4      # Finally bin the collective results by days (the decimal year), and calculate the desired means.   localDaily$FNConc <-  as.numeric(tapply(concFlux_list[[\"allConcReplicated\"]], concFlux_list[[\"allDatesReplicated\"]], \"mean\"))   localDaily$FNFlux <-  as.numeric(tapply(allFluxReplicated, concFlux_list[[\"allDatesReplicated\"]], \"mean\"))   localDaily$FluxDay <- as.numeric(localDaily$ConcDay * localDaily$Qa * 86.4)      return(localDaily) }  DailyNew <- estDailyFromSurfaces_Qa(eListRoll) INFO <- eListRoll$INFO Sample <- eListRoll$Sample surfaces <- eListRoll$surfaces eListNew <- as.egret(INFO, DailyNew, Sample, surfaces) plotConcHist(eListNew) plotFluxHist(eListNew) tableChange(eListNew, yearPoints = c(1967, 1980, 2000)) ##  ##    GREEN RIVER NEAR GREENDALE, UT  ##    Total dissolved solids ##    Water Year  ##  ##            Concentration trends ##    time span       change     slope    change     slope ##                      mg/L   mg/L/yr        %       %/yr ##  ##  1967  to  1980       -79      -6.1       -14      -1.1 ##  1967  to  2000      -153      -4.6       -27     -0.83 ##  1980  to  2000       -75      -3.7       -15     -0.77 ##  ##  ##                  Flux Trends ##    time span          change        slope       change        slope ##                   10^6 kg/yr    10^6 kg/yr /yr      %         %/yr ##  1967  to  1980         -157          -12          -14         -1.1 ##  1967  to  2000         -300         -9.1          -27        -0.83 ##  1980  to  2000         -143         -7.1          -15        -0.76 tableResults(eListNew) ##  ##    GREEN RIVER NEAR GREENDALE, UT  ##    Total dissolved solids ##    Water Year  ##  ##    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux ##              cms            mg/L             10^6 kg/yr  ##  ##    1967      56.5       549       562      1063      1094 ##    1968      45.6       529       555      1188      1079 ##    1969      49.0       516       548      1240      1063 ##    1970      46.6       503       541       827      1049 ##    1971      46.0       500       535       635      1035 ##    1972      59.1       493       528      1177      1021 ##    1973      71.1       482       523      1242      1008 ##    1974      60.2       484       517       847       996 ##    1975      52.6       483       512      1076       989 ##    1976      55.7       485       508      1148       983 ##    1977      51.7       484       503      1168       973 ##    1978      37.4       532       496       658       959 ##    1979      41.5       504       489       840       947 ##    1980      47.6       471       484       704       937 ##    1981      43.5       481       477       619       925 ##    1982      41.4       488       473       735       916 ##    1983      57.1       446       468      1669       908 ##    1984      77.7       417       465      1306       900 ##    1985      68.9       426       462      1035       895 ##    1986      57.3       438       459      1344       891 ##    1987      65.9       423       456       843       885 ##    1988      56.7       437       452       650       876 ##    1989      28.1       494       447       460       868 ##    1990      24.0       500       444       479       861 ##    1991      30.6       482       440       531       854 ##    1992      34.5       469       437       657       847 ##    1993      30.4       475       433       559       840 ##    1994      32.3       466       430       803       834 ##    1995      34.9       457       426       637       827 ##    1996      42.5       438       423      1032       820 ##    1997      57.6       402       419      1024       814 ##    1998      63.1       390       416       986       807 ##    1999      62.7       387       412      1119       801 ##    2000      58.5       391       409       677       794"},{"path":"/articles/AlternativeQMethod.html","id":"wrtds-kalman-results","dir":"Articles","previous_headings":"","what":"WRTDS Kalman results","title":"Using a WRTDS model where the discharge variable is not daily discharge","text":"wanted come best estimates concentration flux day (month year) record (opposed trend evaluation)? can also WRTDS_K estimate results. give us accuracy. Note improve concentrations fluxes. flow normalized results output meaningful.   particular case, using WRTDS_Kalman approach makes little difference. ’s large mixing volume reservoir means concentrations change little period days weeks. chose set rho high value reflect steadiness concentration, makes little difference. little extra coding might needed everything needed look value WRTDS_Kalman approach types situations.","code":"eListK <- WRTDSKalman(eListNew, rho = 0.95, niter = 50, verbose = FALSE) # these next two lines of code are needed to get the proper discharge used in the flux estimates GenFlux <- eListK$Daily$GenConc * eListK$Daily$Qa * 86.4 eListK$Daily$GenFlux <- GenFlux plotWRTDSKalman(eListK) plotTimeSlice(eListK, start = 1982, end = 1987, conc = TRUE)"},{"path":"/articles/AlternativeQMethod.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Using a WRTDS model where the discharge variable is not daily discharge","text":"trend results want look FNConc FNFlux values eListNew. best estimates concentrations fluxes day (month year) record use GenConc GenFlux values eListK.","code":""},{"path":"/articles/EGRET.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to the EGRET package","text":"EGRET includes statistics graphics streamflow history, water quality trends, statistical modeling algorithm Weighted Regressions Time, Discharge, Season (WRTDS). Please see official EGRET User Guide Robert M. Hirsch De Cicco (2015) information EGRET package: https://doi.org/10.3133/tm4A10 information getting started R, downloading installing package, see New R section. best ways learn WRTDS approach read User Guide two journal articles. articles available, free, journals published. first relates nitrate total phosphorus data 9 rivers draining Chesapeake Bay. URL Robert M. Hirsch, Moyer, Archfield (2010): https://onlinelibrary.wiley.com/doi/full/10.1111/j.1752-1688.2010.00482.x. second application nitrate data 8 monitoring sites Mississippi River major tributaries Sprague, Hirsch, Aulenbach (2011). URL : https://pubs.acs.org/doi/abs/10.1021/es201221s vignette assumes understand concepts underlying WRTDS, reading relevant sections User Guide least first papers. use trade, firm, product names descriptive purposes imply endorsement U.S. Government.","code":""},{"path":"/articles/EGRET.html","id":"egret-workflow","dir":"Articles","previous_headings":"","what":"EGRET Workflow","title":"Introduction to the EGRET package","text":"Subsequent sections vignette discuss EGRET workflow steps greater detail. section provides handy cheat sheet diving EGRET analysis. first example flow history analysis: second workflow example water quality analysis. includes data retrieval, merging water quality streamflow data, running WRTDS estimation, various plotting functions available EGRET package.","code":"library(EGRET)  # Flow history analysis  ############################ # Gather discharge data: siteNumber <- \"01491000\" #Choptank River at Greensboro, MD startDate <- \"\" # Get earliest date endDate <- \"\" # Get latest date Daily <- readNWISDaily(siteNumber,\"00060\",startDate,endDate) # Gather site and parameter information: # Here user must input some values for # the default (interactive=TRUE) INFO <- readNWISInfo(siteNumber,\"00060\") INFO$shortName <- \"Choptank River near Greensboro, MD\" ############################  ############################ # Check flow history data: eList <- as.egret(INFO, Daily, NA, NA) plotFlowSingle(eList, istat=7,qUnit=\"thousandCfs\") plotSDLogQ(eList) plotQTimeDaily(eList, qLower=1,qUnit=3) plotFour(eList, qUnit=3) plotFourStats(eList, qUnit=3) ############################  # modify this for your own computer file structure: savePath<-\"/Users/rhirsch/Desktop/\"  saveResults(savePath, eList) library(EGRET)  ############################ # Gather discharge data: siteNumber <- \"01491000\" #Choptank River near Greensboro, MD startDate <- \"\" #Gets earliest date endDate <- \"2011-09-30\" # Gather sample data: parameter_cd<-\"00631\" #5 digit USGS code Sample <- readNWISSample(siteNumber,parameter_cd,startDate,endDate) #Gets earliest date from Sample record: #This is just one of many ways to assure the Daily record #spans the Sample record startDate <- min(as.character(Sample$Date))  # Gather discharge data: Daily <- readNWISDaily(siteNumber,\"00060\",startDate,endDate) # Gather site and parameter information:  # Here user must input some values: INFO<- readNWISInfo(siteNumber,parameter_cd) INFO$shortName <- \"Choptank River at Greensboro, MD\"  # Merge discharge with sample data: eList <- mergeReport(INFO, Daily, Sample) ############################  ############################ # Check sample data: boxConcMonth(eList) boxQTwice(eList) plotConcTime(eList) plotConcQ(eList) multiPlotDataOverview(eList) ############################  ############################ # Run WRTDS model: eList <- modelEstimation(eList) ############################  ############################ #Check model results:  #Require Sample + INFO: plotConcTimeDaily(eList) plotFluxTimeDaily(eList) plotConcPred(eList) plotFluxPred(eList) plotResidPred(eList) plotResidQ(eList) plotResidTime(eList) boxResidMonth(eList) boxConcThree(eList)  #Require Daily + INFO: plotConcHist(eList) plotFluxHist(eList)  # Multi-line plots: date1 <- \"1985-09-01\" date2 <- \"1997-09-0\" date3 <- \"2010-09-01\" qBottom<-0.2 qTop<-10 plotConcQSmooth(eList, date1, date2, date3, qBottom, qTop,                     concMax=2,legendTop = 0.8) q1 <- 2 q2 <- 10 q3 <- 20 centerDate <- \"07-01\" yearEnd <- 1980 yearStart <- 2010 plotConcTimeSmooth(eList, q1, q2, q3, centerDate, yearStart, yearEnd, legendTop = 0.7)  # Multi-plots: fluxBiasMulti(eList)  #Contour plots: clevel<-seq(0,2,0.5) maxDiff<-0.8 yearStart <- 1980 yearEnd <- 2010  plotContours(eList, yearStart,yearEnd,qBottom,qTop,               contourLevels = clevel,qUnit=2) plotDiffContours(eList, yearStart,yearEnd,                  qBottom,qTop,maxDiff,qUnit=2)  # modify this for your own computer file structure: savePath<-\"/Users/rhirsch/Desktop/\"  saveResults(savePath, eList)"},{"path":"/articles/EGRET.html","id":"data_frame","dir":"Articles","previous_headings":"","what":"EGRET Data Frames and Retrieval Options","title":"Introduction to the EGRET package","text":"EGRET package uses 3 default data frames throughout calculations, analysis, graphing. data frames Daily, Sample, INFO. data frames combined named list EGRET functions using .egret function (see Merge Report). package EGRET depends called dataRetrieval. package provides core functionality import hydrologic data USGS EPA web services. See dataRetrieval vignette information. EGRET uses entirely SI units store data, purposes output, can report results wide variety units, discussed Units section. start exploration, must install packages, open EGRET following command:","code":"library(dataRetrieval) vignette(\"dataRetrieval\") library(EGRET)"},{"path":"/articles/EGRET.html","id":"data_frame_Daily","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options","what":"Daily","title":"Introduction to the EGRET package","text":"Daily data frame can imported R either USGS web services (readNWISDaily) user-generated files (readUserDaily). run WRTDS calculations using function modelEstimation (described WRTDS section, additional columns inserted. Columns added Daily data frame running modelEstimation Notice “Day year” column can span 1 366. 366 accounts leap years. Every day consistent day year. means, February 28th always 59th day year, Feb. 29th always 60th day year, March 1st always 61st day year whether leap year.","code":""},{"path":"/articles/EGRET.html","id":"nwisDailyFile","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Daily","what":"readNWISDaily","title":"Introduction to the EGRET package","text":"readNWISDaily function retrieves daily values (discharge case) USGS web service. requires inputs siteNumber, parameterCd, startDate, endDate, interactive, convert. arguments described detail dataRetrieval vignette, however convert new argument (defaults TRUE). convert argument tells program convert values cubic feet per second (ft3/s) cubic meters per second (m3/s) shown example Daily data frame. EGRET applications NWIS Web retrieval, use argument (default TRUE), EGRET assumes discharge always stored units cubic meters per second. don’t want conversion using EGRET, set convert=FALSE function call. discharge values negative zero, code set values zero add small constant daily discharge values. constant 0.001 times mean discharge. code also report number zero negative values size constant. Use EGRET analysis number zero values small fraction total days record (say less 0.1% days), negative discharge values. Columns Q7 Q30 7 30 day running averages 7 30 days ending specific date.","code":"siteNumber <- \"01491000\" startDate <- \"2000-01-01\" endDate <- \"2013-01-01\" # This call will get NWIS (ft3/s) data , and convert it to m3/s: Daily <- readNWISDaily(siteNumber, \"00060\", startDate, endDate)"},{"path":"/articles/EGRET.html","id":"DailyFile","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Daily","what":"readUserDaily","title":"Introduction to the EGRET package","text":"readUserDaily function load user-supplied text file convert Daily data frame. file two columns, first dates, second values. dates formatted either mm/dd/yyyy yyyy-mm-dd. Using 4-digit year required. function following inputs: filePath, fileName, hasHeader (TRUE/FALSE), separator, qUnit, interactive (TRUE/FALSE). filePath character defines path file, character can either full path, path relative R working directory. input fileName character defines file name (including extension). Text files contain sort data require sort separator, example, “csv” file (comma-separated value) file uses comma separate date value column. tab delimited file use tab (\"\\t\") rather comma (\",\"). Define type separator choose use function call separator argument, default \",\". Another function input logical variable: hasHeader. default TRUE. data column names, set variable FALSE. Finally, qUnit numeric argument defines discharge units used input file. default qUnit = 1 assumes discharge cubic feet per second. discharge file already cubic meters per second set qUnit = 2. units (like liters per second acre-feet per day), user must pre-process data unit conversion changes either cubic feet per second cubic meters per second. , file called “ChoptankRiverFlow.txt” located folder called “RData” C drive (example Windows™ operating systems), file structured follows (tab-separated): call open file, convert discharge cubic meters per second, populate Daily data frame : Microsoft™ Excel files can bit tricky import R directly. simplest way get Excel data R open Excel file Excel, save .csv file (comma-separated values).","code":"date  Qdaily 10/1/1999  107 10/2/1999  85 10/3/1999  76 10/4/1999  76 10/5/1999   113 10/6/1999   98 ... fileName <- \"ChoptankRiverFlow.txt\" filePath <-  \"C:/RData/\" Daily <- readUserDaily(filePath,fileName,                     separator=\"\\t\")"},{"path":"/articles/EGRET.html","id":"data_frame_Sample","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options","what":"Sample","title":"Introduction to the EGRET package","text":"Sample data frame initially populated columns generated either readNWISSample, readWQPSample, readUserSample functions. run WRTDS calculations using modelEstimation function (described WRTDS section, additional columns inserted: Columns added Sample data frame running modelEstimation Daily data frame, “Day year” column can span 1 366. 366 accounts leap years. Every day consistent day year. means, February 28th always 59th day year, Feb. 29th always 60th day year, March 1st always 61st day year whether leap year. censored value section summing multiple constituents, including interval censoring used. Since Sample data frame structured contain one constituent, one parameter codes requested, readNWISSample function sum values constituent described .","code":""},{"path":"/articles/EGRET.html","id":"readNWISSample","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Sample","what":"readNWISSample","title":"Introduction to the EGRET package","text":"readNWISSample function retrieves USGS sample data NWIS. arguments function also siteNumber, parameterCd, startDate, endDate, interactive. inputs readNWISDaily described previous section. Information USGS parameter codes can found : https://help.waterdata.usgs.gov/codes--parameters/parameters","code":"siteNumber <- \"01491000\" parameterCd <- \"00618\" Sample <-readNWISSample(siteNumber,parameterCd,       startDate, endDate)"},{"path":"/articles/EGRET.html","id":"readWQPSample","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Sample","what":"readWQPSample","title":"Introduction to the EGRET package","text":"readWQPSample function retrieves Water Quality Portal sample data (STORET, NWIS, STEWARDS). arguments function siteNumber, characteristicName, startDate, endDate, interactive. request USGS data Water Quality Portal, siteNumber must “USGS-” pasted identification number. USGS data, characteristicName argument can either list 5-digit parameter codes, characteristic name. table describes USGS parameters relate defined characteristic name can found : https://www.waterqualitydata.us/public_srsnames","code":"site <- 'WIDNR_WQX-10032762' characteristicName <- 'Specific conductance' Sample <-readWQPSample(site,characteristicName,       startDate, endDate)"},{"path":"/articles/EGRET.html","id":"SampleFile","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Sample","what":"readUserSample","title":"Introduction to the EGRET package","text":"readUserSample function import user-generated file populate Sample data frame. difference sample data discharge data code requires third column contains remark code, either blank \"<\", tell program data “left-censored” (, detection limit sensor). Therefore, data must form: date, remark, value. example comma-delimited file : call open file, populate Sample data frame : multiple constituents summed, format can date, remark_A, value_A, remark_b, value_b, etc… tab-separated example might look like file , columns date, remark dissolved phosphate (rdp), dissolved phosphate (dp), remark particulate phosphorus (rpp), particulate phosphorus (pp), remark total phosphate (rtp), total phosphate (tp):","code":"cdate;remarkCode;Nitrate 10/7/1999,,1.4 11/4/1999,<,0.99 12/3/1999,,1.42 1/4/2000,,1.59 2/3/2000,,1.54 ... fileName <- \"ChoptankRiverNitrate.csv\" filePath <-  \"C:/RData/\" Sample <- readUserSample(filePath,fileName,                                 separator=\",\") date  rdp  dp   rpp pp  rtp tp 2003-02-15      0.020       0.500        2003-06-30  <   0.010       0.300        2004-09-15  <   0.005   <   0.200        2005-01-30                      0.430 2005-05-30                  <   0.050 2005-10-30                  <   0.020 ... fileName <- \"ChoptankPhosphorus.txt\" filePath <-  \"C:/RData/\" Sample <-readUserSample(filePath,fileName,                                 separator=\"\\t\")"},{"path":"/articles/EGRET.html","id":"cenValues","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > Sample","what":"Censored Values: Summation Explanation","title":"Introduction to the EGRET package","text":"typical case none data censored (, values reported “less-” values), ConcLow = ConcHigh = ConcAve equal reported value, Uncen = 1 values. common type censoring, value reported less reporting limit, ConcLow = NA, ConcHigh = reporting limit, ConcAve = 0.5 * reporting limit, Uncen = 0. illustrate EGRET package handles complex censoring problem, let us say 2004 earlier, computed total phosphorus (tp) sum dissolved phosphorus (dp) particulate phosphorus (pp). 2005 onward, direct measurements total phosphorus (tp). small subset fictional data provided: Example data EGRET “add ” values given row form total sample using Sample data frame. Thus, want enter data added together. want data frame multiple constituents summed, use readNWISSample, readWQPSample, readUserSample. raw data functions: getWQPdata, readNWISqw, readWQPqw, readWQPdata EGRET package sum constituents, leave individual columns. example, might know value dp 5/30/2005, don’t want put table rules data set, supposed add values 2005. every sample, EGRET package requires pair numbers define interval true value lies (ConcLow ConcHigh). simple uncensored case (reported value detection limit), ConcLow equals ConcHigh interval collapses single point. simple censored case, value might reported <0.2, ConcLow=NA ConcHigh=0.2. use NA instead 0 way elegantly handle future logarithm calculations. complex example case, let us say dp reported <0.01 pp reported 0.3. know total must least 0.3 much 0.31. Therefore, ConcLow=0.3 ConcHigh=0.31. Another case dp reported <0.005 pp reported <0.2. know case true value low zero, high 0.205. Therefore, case, ConcLow=NA ConcHigh=0.205. Sample data frame example data :","code":"Sample ##         Date ConcLow ConcHigh Uncen ConcAve Julian Month Day  DecYear MonthSeq ## 1 2003-02-15    0.52    0.520     1  0.5200  55927     2  46 2003.125     1838 ## 2 2003-06-30    0.30    0.310     0  0.3050  56062     6 182 2003.495     1842 ## 3 2004-09-15      NA    0.205     0  0.1025  56505     9 259 2004.706     1857 ## 4 2005-01-30    0.43    0.430     1  0.4300  56642     1  30 2005.081     1861 ## 5 2005-05-30      NA    0.050     0  0.0250  56762     5 151 2005.410     1865 ## 6 2005-10-30      NA    0.020     0  0.0100  56915    10 304 2005.829     1870 ##   waterYear       SinDY      CosDY ## 1      2003  0.70558361  0.7086267 ## 2      2003  0.03442161 -0.9994074 ## 3      2004 -0.96251346 -0.2712339 ## 4      2005  0.48627271  0.8738071 ## 5      2005  0.53800517 -0.8429415 ## 6      2006 -0.88001220  0.4749511"},{"path":"/articles/EGRET.html","id":"data_frame_INFO","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options","what":"INFO","title":"Introduction to the EGRET package","text":"INFO data frame stores information measurements, station name, parameter name, drainage area, forth. can many additional, optional columns, columns table required initiate EGRET analysis. run WRTDS calculations (described WRTDS section, additional columns automatically inserted INFO data frame (see EGRET User Guide complete description term): INFO data frame running modelEstimation","code":""},{"path":"/articles/EGRET.html","id":"nwisINFO","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > INFO","what":"readNWISInfo","title":"Introduction to the EGRET package","text":"function readNWISInfo combines readNWISsite readNWISpCode dataRetrieval package, producing one data frame called INFO.","code":"parameterCd <- \"00618\" siteNumber <- \"01491000\" INFO <- readNWISInfo(siteNumber,parameterCd, interactive=FALSE)"},{"path":"/articles/EGRET.html","id":"wqpINFO","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > INFO","what":"readWQPInfo","title":"Introduction to the EGRET package","text":"also possible create INFO data frame using information Water Quality Portal. readWQPSample, requested site USGS siteNumber, “USGS-” needs appended siteNumber.","code":"parameterCd <- \"00618\" INFO_WQP <- readWQPInfo(\"USGS-01491000\",parameterCd)"},{"path":"/articles/EGRET.html","id":"userINFO","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > INFO","what":"readUserInfo","title":"Introduction to the EGRET package","text":"function readUserInfo can used convert comma separated files INFO data frame. minimum, EGRET analysis uses columns: param.units, shortName, paramShortName, constitAbbrev, drainSqKm. example, following comma-separated file (csv) available file called “INFO.csv”, located folder called “RData” C drive (examples Windows™ operation system), function convert INFO data frame follows.","code":"param.units, shortName, paramShortName, constitAbbrev, drainSqKm mg/l, Choptank River, Inorganic nitrogen, N, 292.67 fileName <- \"INFO.csv\" filePath <- \"C:/RData/\"  INFO <- readUserInfo(filePath, fileName)"},{"path":"/articles/EGRET.html","id":"addINFO","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options > INFO","what":"Inserting Additional Info","title":"Introduction to the EGRET package","text":"supplemental column useful can added INFO data frame.","code":"INFO$riverInfo <- \"Major tributary of the Chesapeake Bay\" INFO$GreensboroPopulation <- 1931"},{"path":"/articles/EGRET.html","id":"eList","dir":"Articles","previous_headings":"EGRET Data Frames and Retrieval Options","what":"Merge Report: eList","title":"Introduction to the EGRET package","text":"Finally, function called mergeReport look Daily Sample data frame, populate Q LogQ columns Sample data frame. mergeReport run, Sample data frame augmented daily discharges days samples, named list data frames created. vignette, refer named list eList: list potentially 3 data frames: Daily, Sample, INFO. flow history analysis, Sample data frame can NA.can use function .egret create “EGRET” object. None water quality functions EGRET work without first run mergeReport function. Perhaps already Daily, Sample, INFO data frames, surfaces matrix (created running WRTDS modelEstimation) gone though deprecated version EGRET. can create edit EGRET object follows:","code":"siteNumber <- \"01491000\" parameterCd <- \"00631\"  # Nitrate startDate <- \"2000-01-01\" endDate <- \"2013-01-01\"  Daily <- readNWISDaily(siteNumber, \"00060\", startDate, endDate) Sample <- readNWISSample(siteNumber,parameterCd, startDate, endDate) INFO <- readNWISInfo(siteNumber, parameterCd)  eList <- mergeReport(INFO, Daily,Sample) eListNew <- as.egret(INFO, Daily, Sample, surfaces) #To pull out the INFO data frame: INFO <- getInfo(eListNew) #Edit the INFO data frame: INFO$importantNews <- \"New EGRET workflow started\" #Put new data frame in eListNew eListNew$INFO <- INFO #To pull out Daily: Daily <- getDaily(eListNew) #Edit for some reason: DailyNew <- Daily[Daily$DecYear > 1985,] #Put new Daily data frame back in eListNew: eListNew$Daily <- DailyNew #To create a whole new egret object: eList_2 <- as.egret(INFO, DailyNew, getSample(eListNew), NA)"},{"path":"/articles/EGRET.html","id":"units","dir":"Articles","previous_headings":"","what":"Units","title":"Introduction to the EGRET package","text":"EGRET uses entirely SI units store data, purposes output, can report results wide variety units. defaults mg/L concentration, cubic meters per second (m3/s) discharge, kg/day flux, km2 drainage area. discharge values imported USGS Web services, automatically converted cubic feet per second (cfs) cms unless argument convert function readNWISDaily set FALSE. can cause confusion careful. functions provide output, can define two arguments set output units: qUnit fluxUnit. qUnit fluxUnit defined either numeric code name. can call two functions can called see options: printqUnitCheatSheet printFluxUnitCheatSheet. function input argument qUnit, can define discharge units used figure table generated function index (1-4) shown . Base choice units customary intended audience, also discharge values don’t many digits right left decimal point. function input argument fluxUnit, can define flux units index (1-12) shown . Base choice units customary intended audience, also flux values don’t many digits right left decimal point. Tons always “short tons” “metric tons”. Note analysis done single month season (see discussion “Period Analysis” Flow History flux values represent rate (mass per unit time). Thus, period analysis combination April May, reported flux 1000 kg/year translates mass 1000 * 61 / 365.25 = 167 kg. Thus, general, flux reported mass per year, get mass season value multiplied number days season divided 365.25.","code":"printqUnitCheatSheet() ## The following codes apply to the qUnit list: ## 1 =  cfs  ( Cubic Feet per Second ) ## 2 =  cms  ( Cubic Meters per Second ) ## 3 =  thousandCfs  ( Thousand Cubic Feet per Second ) ## 4 =  thousandCms  ( Thousand Cubic Meters per Second ) printFluxUnitCheatSheet() ## The following codes apply to the fluxUnit list: ## 1 =  poundsDay  ( pounds/day ) ## 2 =  tonsDay  ( tons/day ) ## 3 =  kgDay  ( kg/day ) ## 4 =  thousandKgDay  ( thousands of kg/day ) ## 5 =  tonsYear  ( tons/year ) ## 6 =  thousandTonsYear  ( thousands of tons/year ) ## 7 =  millionTonsYear  ( millions of tons/year ) ## 8 =  thousandKgYear  ( thousands of kg/year ) ## 9 =  millionKgYear  ( millions of kg/year ) ## 10 =  billionKgYear  ( billions of kg/year ) ## 11 =  thousandTonsDay  ( thousands of tons/day ) ## 12 =  millionKgDay  ( millions of kg/day ) ## 13 =  kgYear  ( kg/year )"},{"path":"/articles/EGRET.html","id":"flowHistory","dir":"Articles","previous_headings":"","what":"Flow History","title":"Introduction to the EGRET package","text":"section describes functions included EGRET package provide variety table graphical outputs examining discharge statistics based time-series smoothing. functions designed studies long-term change work best daily discharge data sets 50 years longer. type analysis might useful studying issues influence land use change, water management change, climate change discharge conditions. includes potential impacts average discharges, high discharges, low discharges, annual time scales well seasonal monthly time scales. Consider example Columbia River Dalles, . first must determine period analysis use (PA). period analysis? want examine data set time series water years, period analysis October September. want examine data set calendar years period analysis January December. might want examine winter season, define December February, 3 months become period analysis. constraints definition period analysis : must defined terms whole months; must set contiguous months (like March-April-May), length less 1 month 12 months. Define PA using two arguments: paLong paStart. paLong length PA, paStart first month PA. Period Analysis Information set period running December February: set default value (water year): next step can create annual series discharge statistics. returned matrix contain statistics described . statistics based period analysis set setPA function. Index discharge statistics information","code":"siteNumber <- \"14105700\"   startDate <- \"\" endDate <- \"\"  Daily <- readNWISDaily(siteNumber,\"00060\",startDate,endDate) INFO <- readNWISInfo(siteNumber,\"\",interactive=FALSE) INFO$shortName <- \"Columbia River at The Dalles, OR\"  eList <- as.egret(INFO, Daily, NA, NA) eList <- setPA(eList,paStart=12,paLong=3) eList <- setPA(eList)"},{"path":"/articles/EGRET.html","id":"plotOptions","dir":"Articles","previous_headings":"Flow History","what":"Plotting Options","title":"Introduction to the EGRET package","text":"section shows examples available plots appropriate studying discharge history. plots use default variable input options. function, can get complete list input variables (described flow history section) help file typing ? function name R console. EGRET user guide detailed information plot type (https://pubs.usgs.gov/tm/04/a10/). Finally, see saving plots section information saving plots. simplest way look time series function plotFlowSingle. statistic index (istat) must defined user, arguments default values user isn’t required specify anything else. see list optional arguments information function, type ?plotFlowSingle R console. graphs plotFlowSingle, plotFourStats, one graphs plotFour, show individual annual values selected discharge statistic (e.g. annual mean 7-day minimum), also show curve smooth fit data. curve LOWESS (locally weighted scatterplot smooth). algorithm computing provided User Guide (https://pubs.usgs.gov/tm/04/a10/), section titled “Smoothing Method Used Flow History Analyses.” default annual values selected discharge statistics smoothed “half-window width” 20 years. smoothing window optional user-defined option. plotSDLogQ produces graphic running standard deviation log daily discharge time visualize variability daily discharge changing time. using standard deviation log discharge statistic becomes dimensionless. standard deviation plot way looking variability quite aside average values, , case system discharge might increasing period years, graphic provides way looking variability relative changing mean value. standard deviation log discharge much like coefficient variation, sample properties make smoother measure variability. People often comment things like urbanization enhanced greenhouse gases atmosphere bringing increase variability, analysis one way explore idea. plotFour, plotFourStats, plot15 designed plot several graphs functions single figure. Plots discharge statistics example looking daily mean discharge full water year looking mean daily discharge winter season Merced River Happy Isles Bridge Yosemite National Park California. First, look mean daily discharge full year (read data metadata): Merced River winter trend figures show us annual basis little indication long-term trend mean discharge, winter months pretty strong indication upward trend. well related climate warming Sierra Nevada, resulting general increase ratio rain snow winter thawing events. plotFour(eListMerced, qUnit=3) plotFourStats(eListMerced, qUnit=3) plotQTimeDaily simply time series plot discharge. , suited showing events discharge threshold. simplest case, can plot entire record, given line weight use arithmetic scale primarily provides visual focus higher values. Mississippi example illustrates long record long gap 60 years discharges 300,000 cfs, followed last followed 49 years 1965 2013 6 events threshold. plotQTimeDaily requires startYear endYear, along optional arguements (see ?plotQTimeDaily details). Mississippi River Keokuk Iowa","code":"plotFlowSingle(eList, istat=5,qUnit=\"thousandCfs\") plotSDLogQ(eList) # Merced River at Happy Isles Bridge, CA: siteNumber<-\"11264500\" Daily <-readNWISDaily(siteNumber,\"00060\",startDate=\"\",endDate=\"\") INFO <- readNWISInfo(siteNumber,\"\",interactive=FALSE) INFO$shortName <- \"Merced River at Happy Isles Bridge, CA\" eList <- as.egret(INFO, Daily, NA, NA) plotFlowSingle(eList, istat=5) # Then, we can run the same function, but first set  # the pa to start in December and only run for 3 months. eListMerced <- setPA(eList,paStart=12,paLong=3) plotFlowSingle(eListMerced,istat=5,qMax=200) plotFour(eList, qUnit=3) plotFourStats(eList, qUnit=3) #Mississippi River at Keokuk Iowa: siteNumber<-\"05474500\" Daily <-readNWISDaily(siteNumber,\"00060\",startDate=\"\",endDate=\"\") INFO <- readNWISInfo(siteNumber,\"\",interactive=FALSE) INFO$shortName <- \"Mississippi River at Keokuk Iowa\" eList <- as.egret(INFO, Daily, NA, NA) plotQTimeDaily(eList, qUnit=3,qLower=300)"},{"path":"/articles/EGRET.html","id":"tableOptions","dir":"Articles","previous_headings":"Flow History","what":"Table Options","title":"Introduction to the EGRET package","text":"Sometimes easier consider results table formats rather graphically. Similar function plotFlowSingle, printSeries print requested discharge statistics (Table \\(\\ref{table:istat}\\)), well return results data frame. small sample output printed . Another way look results consider much smoothed values change various pairs years. changes can represented four different ways. change first last year pair, expressed discharge units selected. change first last year pair, expressed percentage value first year slope first last year pair, expressed terms discharge units per year. slope first last year pair, expressed percentage change per year (percentage based value first year). Another argument can useful function: yearPoints. default case, set years compared 5 year intervals along whole data set. data set quite long can daunting number comparisons. example, 80 year record, 136 pairs. Instead, look changes 3 year points: 1890, 1950, 2010: See instructions converting R data frame table Microsoft™ software. Excel, Microsoft, PowerPoint, Windows, Word registered trademarks Microsoft Corporation United States countries.","code":"seriesResult <- printSeries(eList, istat=3, qUnit=3) Mississippi River at Keokuk Iowa  Water Year     30-day minimum     Thousand Cubic Feet per Second    year   annual   smoothed            value    value    1879     22.6     30.1    1880     31.7     28.7    1881     23.0     27.5 ...    2011     51.0     32.4    2012     34.3     32.1    2013     16.2     31.8 tableFlowChange(eList, istat=3, qUnit=3,yearPoints=c(1890,1950,2010)) ##  ##    Mississippi River at Keokuk Iowa ##    Water Year ##     30-day minimum  ##  ##              Streamflow Trends ##    time span          change        slope       change        slope ##                      10^3 cfs   10^3cfs/yr        %            %/yr ##  1890  to  1950         0.84        0.014          3.7        0.061 ##  1890  to  2010          9.5         0.08           41         0.35 ##  1950  to  2010          8.7         0.15           36         0.61"},{"path":"/articles/EGRET.html","id":"wqa","dir":"Articles","previous_headings":"","what":"Summary of Water Quality Data (without using WRTDS)","title":"Introduction to the EGRET package","text":"run WRTDS model, helpful examine measured water quality data graphically better understand behavior, identify possible data errors, visualize temporal distribution data (identify gaps). always best clear issues moving forward. examples use Choptank River Greensboro, MD. Choptank River small tributary Chesapeake Bay. Inorganic nitrogen (nitrate nitrite) measured 1979 onward. First, need load discharge nitrate data R. can graph use WRTDS analysis, must bring discharge data Sample data frame. using mergeReport function merges discharge information also provides compact report major features data set.","code":"#Choptank River at Greensboro, MD: siteNumber <- \"01491000\"  startDate <- \"1979-10-01\" endDate <- \"2011-09-30\" param<-\"00631\" Daily <- readNWISDaily(siteNumber,\"00060\",startDate,endDate) INFO<- readNWISInfo(siteNumber,param,interactive=FALSE) INFO$shortName <- \"Choptank River\"  Sample <- readNWISSample(siteNumber,param,startDate,endDate) eList <- mergeReport(INFO, Daily, Sample)"},{"path":"/articles/EGRET.html","id":"plotOptionsWQ","dir":"Articles","previous_headings":"Summary of Water Quality Data (without using WRTDS)","what":"Plotting Options","title":"Introduction to the EGRET package","text":"section shows examples available plots appropriate analyzing data prior performing WRTDS analysis. plots use default variable input options. function, can get complete list input variables help file typing ? function name R console. See Water Quality Plotting Input information available input variables plotting functions. Note plotting functions show sample data, value data set non-detect (censored), displayed graph vertical line. top line reporting limit bottom either zero, graph plotting log concentration values minimum value y-axis. line “honest” representation know observation doesn’t attempt use statistical model make estimate reporting limit. Concentration box plots Note statistics create boxplot boxQTwice performed data log-transformed. relation concentration vs time discharge interesting note change convention rounding data values occurred around 1995. relation flux vs discharge multiPlotDataOverview(eList, qUnit=1) multiPlotDataOverview function uses log scale default. change concentration axes arithmetic scale, use logScaleConc=FALSE multiPlotDataOverview function call.","code":"boxConcMonth(eList)   boxQTwice(eList,qUnit=1) plotConcTime(eList)   plotConcQ(eList, qUnit=1) plotFluxQ(eList, fluxUnit=4) multiPlotDataOverview(eList, qUnit=1)"},{"path":"/articles/EGRET.html","id":"tableOptionsWQ","dir":"Articles","previous_headings":"Summary of Water Quality Data (without using WRTDS)","what":"Table Options","title":"Introduction to the EGRET package","text":"Another useful tool checking data running WRTDS estimations flowDuration. utility function can help define discharge ranges want explore. prints key points discharge duration curve. Define points particular part year using centerDate span arguments, although points can defined entire year (default).","code":"flowDuration(eList, qUnit=1) ##  ## Flow Duration for Choptank River  ##  ## Flow duration is based on full year ##  ## Discharge units are Cubic Feet per Second ##     min      5%     10%     25%     50%     75%     90%     95%     max  ##    0.35   12.00   16.00   33.00   85.00  163.00  290.00  462.00 8700.00 flowDuration(eList, qUnit=1, centerDate=\"09-30\", span=30) ##  ## Flow Duration for Choptank River  ##  ## Flow duration period is centered on September 30  ## And spans the period from August 31  To October 30 ##  ## Discharge units are Cubic Feet per Second ##    min     5%    10%    25%    50%    75%    90%    95%    max  ##    2.5    8.8   11.0   15.0   27.0   67.0  138.0  223.0 5600.0"},{"path":"/articles/EGRET.html","id":"wrtds","dir":"Articles","previous_headings":"","what":"Weighted Regressions on Time, Discharge and Season (WRTDS)","title":"Introduction to the EGRET package","text":"WRTDS creates model behavior concentration function three components: time trend, discharge, season. can use WRTDS estimate annual seasonal mean concentrations fluxes well describe long-term trends behavior system. section, step though process required WRTDS analysis. WRTDS Results provides details available methods viewing evaluating model results. looked data using tools described Summary Water Quality Data, determined sufficient representative data, time run WRTDS model. Assuming using defaults, data frames called Daily, Sample, INFO, modelEstimation function runs WRTDS modeling algorithm: Details options available running modelEstimation can found WRTDS Estimation Input. function slow, shows progress percent complete. See references manual information. ’s important understand one function globally change Daily, Sample, INFO data frames. also creates new matrix surfaces, new data frame AnnualResults. Finally, good idea save results computational time invested producing results. workspace saved directory designate savePath file name determined abbreviations station constituent required entries readNWISInfo function used. command saving workspace : saves objects workspace. saved workspaces R versions earlier 3.0, warning appear open R 3.0 (later). Re-saving workspace using R 3.0 (later) get rid warning. Using saveResults, workspace saved INFO$staAbbrev INFO$constitAbbrev filename (separated period), extension .RData. , staAbbrev “Chop” constitAbbrev “NO3” file name “Chop.NO3.RData”. load data future session commands :","code":"eList <- modelEstimation(eList) #An example directory name savePath <- \"C:/Users/egretUser/WRTDS_Output/\"  saveResults(savePath, eList) loadPath <- \"C:/Users/egretUser/WRTDS_Output/\" staAbbrev <- \"Chop\" constitAbbrev <- \"NO3\" pathToFile <- paste0(loadPath,staAbbrev,\".\",                     constitAbbrev,\".RData\") load(pathToFile)"},{"path":"/articles/EGRET.html","id":"wrtdsResults","dir":"Articles","previous_headings":"","what":"WRTDS Results","title":"Introduction to the EGRET package","text":"point (run modelEstimation) can start considering view annual averages variables calculated. See Post-WRTDS Plotting Input common input variables functions. Additionally, check help files (R console, type ? followed function name).","code":""},{"path":"/articles/EGRET.html","id":"wrtdsPlotting","dir":"Articles","previous_headings":"WRTDS Results","what":"Plotting Options","title":"Introduction to the EGRET package","text":"Check help files manual details following functions. See Saving Plots information saving plots. examples, return looking data water year using setPA function. plotting functions use period analysis information INFO data frame determine data plotted. four graph table functions don’t allow user specify Period Analysis (PA). : plotContour, plotDiffContour, plotConcTimeSmooth, plotConcQSmooth. Concentration flux vs time Concentration flux predictions Residuals Residuals respect time Default boxConcThree(eList) Concentration flux history placement legend controlled legendLeft legendTop. set 0 (default values), legend placed near lower left corner graphic. Otherwise, value specified legendLeft places left edge legend, legendTop specifies top edge legend. units legendLeft legendTop discharge (units specified qUnit) concentration, respectively. legend can also turned printLegend=FALSE. also functions recognize period analysis INFO data frame. However, choosing centering dates appropriate half-windows, seasonal behavior can easily observed plots. Concentration vs. discharge plotConcTimeSmooth(eList) fluxBiasMulti(eList, qUnit=1) contour plot functions also recognize PA INFO data frame. represent overall results WRTDS analysis. specify contourLevels contour plots use seq function (type ?seq details). general, use seq function look like : contourLevels = seq(,,). example shown requesting contour levels run 0 2 steps 0.2. plotContours(eList) function plotDiffContours plots difference two selected years (year0 year1). can help clarify combinations seasons flow conditions showing increases decreases period covered. plotDiffContours(eList)","code":"# Return to water year: eList <- setPA(eList)  yearStart <- 2008 yearEnd <- 2010  plotConcTimeDaily(eList, yearStart, yearEnd) plotFluxTimeDaily(eList, yearStart, yearEnd) plotConcPred(eList) plotFluxPred(eList) plotResidPred(eList) plotResidQ(eList, qUnit=1) plotResidTime(eList) boxResidMonth(eList) boxConcThree(eList) plotConcHist(eList) plotFluxHist(eList) # Multi-line plots: date1 <- \"1985-09-01\" date2 <- \"1997-09-01\" date3 <- \"2010-09-01\" qBottom <- 0.2 qTop <- 10 plotConcQSmooth(eList, date1, date2, date3, qBottom, qTop,                     concMax=2,legendTop = 0.5)  plotConcQSmooth(eList, date1, date2, date3,                 qBottom, qTop, legendTop = 0.5,logScale=TRUE) q1 <- 2 q2 <- 10 q3 <- 20 centerDate <- \"07-01\" yearEnd <- 1980 yearStart <- 2010 plotConcTimeSmooth(eList, q1, q2, q3, centerDate,                     yearStart, yearEnd, legendTop = 0.4)  plotConcTimeSmooth(eList, q1, q2, q3, centerDate,                     yearStart, yearEnd,                     legendTop = 0.4,logScale=TRUE) fluxBiasMulti(eList, qUnit=1) clevel<-seq(0,2,0.2) plotContours(eList, yearStart=1980,yearEnd=2010,qBottom=0.5,qTop=20,               contourLevels = clevel) plotDiffContours(eList, year0=1990,year1=2010,                  qBottom=0.5,qTop=20,maxDiff=0.6)"},{"path":"/articles/EGRET.html","id":"wrtdsTable","dir":"Articles","previous_headings":"WRTDS Results","what":"Table Options","title":"Introduction to the EGRET package","text":"Sometimes easier consider results table form rather graphically. function `tableResults} produces simple text table contains annual values results. row output represents year includes: year, average discharge, average concentration, flow-normalized concentration, average flux, flow-normalized flux. paLong != 12 make sure take note explanation seasonal flux values discussed end Units. small sample output printed . Table created head(returnDF) table option tableChange. function provides computation changes slopes selected pairs time points. computations made flow-normalized results. detailed explaination “flow-normalized” result official EGRET user guide. Finally, tableChangeSingle operates exactly tableChange except addition argument flux. function provides either concentration results flux results, . can useful producing many output tables report entirely focused concentration one entirely focused flux. arguments identical tableChange, except final two arguments. argument flux defaults TRUE. flux=TRUE output flux, flux=FALSE output concentration. See Creating tables instructions converting R data frame table Microsoft™ software. Table created tableChangeSingle function","code":"tableResults(eList) returnDF <- tableResults(eList) Choptank River     Inorganic nitrogen (nitrate and nitrite)    Water Year      Year   Discharge    Conc    FN_Conc     Flux    FN_Flux              cms            mg/L             10^6 kg/yr     1980      4.25     0.949     1.003    0.1154     0.106    1981      2.22     1.035     0.999    0.0675     0.108 ...    2010      7.19     1.323     1.438    0.2236     0.149    2011      5.24     1.438     1.457    0.1554     0.148 tableChange(eList, yearPoints=c(2000,2005,2010)) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Water Year  ##  ##            Concentration trends ##    time span       change     slope    change     slope ##                      mg/L   mg/L/yr        %       %/yr ##  ##  2000  to  2005     0.088     0.018         7       1.4 ##  2000  to  2010      0.19     0.019        15       1.5 ##  2005  to  2010     0.098      0.02       7.3       1.5 ##  ##  ##                  Flux Trends ##    time span          change        slope       change        slope ##                   10^6 kg/yr    10^6 kg/yr /yr      %         %/yr ##  2000  to  2005       0.0065       0.0013          4.7         0.93 ##  2000  to  2010       0.0097      0.00097          6.9         0.69 ##  2005  to  2010       0.0032      0.00063          2.2         0.43 returnDF <- tableChangeSingle(eList, yearPoints=c(2000,2005,2010))"},{"path":"/articles/EGRET.html","id":"extendedPlots","dir":"Articles","previous_headings":"","what":"Extending Plots Past Defaults","title":"Introduction to the EGRET package","text":"basic plotting options shown section WRTDS Results. section demonstrates ways extend capabilities EGRET plots. EGRET plots use R’s basic plotting options. set many formatting details plotting routines R using “Graphical Parameters”. read graphical parameters see ?par. graphical functions EGRET coded, set default values many parameters chosen, can override default values. Additionally, can add features plot calling plot function. change plot margins (mar), font, graphical parameters initially assigned, set argument customPar TRUE. R’s base graphical parameters especially useful within plot functions. Useful plotting parameters adjust EGRET plotting functions. details see ?par. plot made, many functions might useful call, add text, legend, lines, etc. Useful functions add default plots. Type ? function name get help individual function. basic examples shown . Modifying text point size, shown using plotConcQ function First, margin adjusted c(8,8,8,8), requiring customPar set TRUE. margin vector represents margin spacing 4 sides plot order: bottom, left, top, right. Next, text labels adjusted, color set \"blue\", point line size increased, point type changed form solid circle(pch=20) solid diamond (pch=18). grid, legend, arrow, text added plot produced. Modified plotConcQ fonts consistent operating systems. following figure shows change Serif font, well use mtext function. see available fonts pdf output computer, type names(pdfFonts()).available fonts quite limited base R. expand font choices, useful R library, “extrafont” can help. Serif font can also extend contour plots. default y-axis determined qTop qBottom. Occasionally, may need use custom axis specifying yTicks. also nice able adjust color scheme contour plots. color schemes built base R heat.colors, topo.colors, terrain.colors, cm.colors. Alternatively, can set colors using colorRampPalette function. example, black white color scheme might required. another example, plotDiffContours might make sense go yellow white negative values, white blue positive values. Examples shown modifying contour plot modifying difference contour plot. Contour plot modified axis color scheme Difference contour plot modified color scheme also possible create custom multi-panel plots. simplest example, can use tinyPlot=TRUE option. Custom multipanel plot using tinyPlot Finally, following figure shows method create panel plots finer control. Custom multipanel plot","code":"plotConcQ(eList, cex.axis=2,cex.main=1.5,logScale=TRUE) plotConcQ(eList, cex.lab=2,cex=2,logScale=TRUE) plotConcQ(eList, logScale=TRUE) par(mar=c(8,8,8,8)) plotConcQ(eList, customPar=TRUE,col=\"blue\",cex=1.1,           cex.axis=1.4,cex.main=1.5,cex.lab=1.2,           pch=18,lwd=2,logScale=TRUE) grid(lwd=2) legend(4.5,.09,\"Choptank Nitrogen\", pch=18, col=\"blue\",bg=\"white\") arrows(3, 0.14, 1, .05,lwd=2) text(12,.14,\"Censored Value\") # Switching to serif font: par(family=\"serif\") plotFluxPred(eList, customPar=TRUE) mtext(side=3,line=-3,\"Serif font example\",cex=3) colors <- colorRampPalette(c(\"white\",\"black\")) yTicksModified <- c(.5,1,10,25) plotContours(eList, 2001,2010,0.5,50,               contourLevels = seq(0,2.5,0.5),qUnit=2,              yTicks=yTicksModified,              color.palette=colors,              flowDuration=FALSE,              tcl=0.2,tick.lwd=2.5) colors <- colorRampPalette(c(\"yellow\",\"white\",\"blue\")) maxDiff<-0.6 par(oma=c(1,1,1,1)) plotDiffContours(eList, year0=2001,year1=2010,qBottom=0.5,qTop=50,               maxDiff,lwd=2,qUnit=2,              color.palette=colors,              flowDuration=FALSE, customPar=TRUE) par(mfcol = c(2, 2), oma = c(0, 1.7, 6, 1.7))  plotFluxQ(eList, tinyPlot=TRUE,printTitle=FALSE,           fluxUnit=9,logScale=TRUE,fluxMax=1) plotConcQ(eList, tinyPlot=TRUE,printTitle=FALSE) plotFluxHist(eList, tinyPlot=TRUE,printTitle=FALSE,fluxMax=1) plotConcHist(eList, tinyPlot=TRUE,printTitle=FALSE,concMax=3) mtext(\"Custom multi-pane graph using tinyPlot=TRUE\", outer=TRUE, font=2) par(mar=c(3.5,3.5,0.2,0.2), # whitespace around the plots     oma=c(1,1,3,1), # outer margin     mgp=c(2,0.5,0), # spacing between the label numbers and plots     mfcol = c(2,2)) # rows/columns  plotFluxQ(eList, tinyPlot=TRUE,printTitle=FALSE,           fluxUnit=9,logScale=TRUE,fluxMax=1,           showXLabels=FALSE,showXAxis=FALSE,            showYLabels=TRUE,customPar=TRUE)  plotConcQ(eList, tinyPlot=TRUE,printTitle=FALSE, customPar=TRUE,           removeLastY=TRUE,removeLastX=TRUE,           showYLabels=TRUE)  plotFluxHist(eList, tinyPlot=TRUE,printTitle=FALSE,fluxMax=1,           showYLabels=FALSE,showYAxis=FALSE,           showXLabels=FALSE,showXAxis=FALSE, customPar=TRUE) plotConcHist(eList, tinyPlot=TRUE,printTitle=FALSE,concMax=3,           showYLabels=FALSE, showYAxis=FALSE, customPar=TRUE) mtext(\"Custom multi-pane graph using customPar\", outer=TRUE, font=2)"},{"path":"/articles/EGRET.html","id":"appendix1","dir":"Articles","previous_headings":"","what":"Getting Started in R","title":"Introduction to the EGRET package","text":"section describes options installing EGRET package.","code":""},{"path":"/articles/EGRET.html","id":"new-to-r","dir":"Articles","previous_headings":"Getting Started in R","what":"New to R?","title":"Introduction to the EGRET package","text":"new R, need first install latest version R, can found : https://www.r-project.org/. time, can get information function R typing question mark function’s name. opens file describes function, required arguments, provides working examples. see raw code particular function, type name function, without parentheses:","code":"?plotConcQ plotConcQ"},{"path":"/articles/EGRET.html","id":"r-user-installing-egret","dir":"Articles","previous_headings":"Getting Started in R","what":"R User: Installing EGRET","title":"Introduction to the EGRET package","text":"install EGRET packages dependencies: installing package, need open library time re-start R. done simple command:","code":"install.packages(\"EGRET\") library(EGRET)"},{"path":"/articles/EGRET.html","id":"appendixPlot","dir":"Articles","previous_headings":"","what":"Common Function Variables","title":"Introduction to the EGRET package","text":"section describes variables common variety function types.","code":""},{"path":"/articles/EGRET.html","id":"flowHistoryVariables","dir":"Articles","previous_headings":"Common Function Variables","what":"Flow History Plotting Input","title":"Introduction to the EGRET package","text":"Variables used flow history plots (plot15, plotFour, plotFourStats, plotQTimeDaily, plotSDLogQ)","code":""},{"path":"/articles/EGRET.html","id":"wqVariables","dir":"Articles","previous_headings":"Common Function Variables","what":"Water Quality Plotting Input","title":"Introduction to the EGRET package","text":"Selected variables used water quality analysis plots","code":""},{"path":"/articles/EGRET.html","id":"wrtdsInputVariables","dir":"Articles","previous_headings":"Common Function Variables","what":"WRTDS Estimation Input","title":"Introduction to the EGRET package","text":"Selected variables WRTDS","code":""},{"path":"/articles/EGRET.html","id":"wrtdsOutputVariables","dir":"Articles","previous_headings":"Common Function Variables","what":"Post-WRTDS Plotting Input","title":"Introduction to the EGRET package","text":"Selected variables used plots analysis WRTDS model results Variables used EGRET contour plots: plotContours plotDiffContours Variables used EGRET plotConcQSmooth /plotConcTimeSmooth functions","code":""},{"path":"/articles/EGRET.html","id":"createWordTable","dir":"Articles","previous_headings":"","what":"Creating tables in Microsoft™ software from an R data frame","title":"Introduction to the EGRET package","text":"steps required create table Microsoft™ software (Excel, Word, PowerPoint, etc.) R data frame. variety good methods, one detailed . example step creation table Microsoft™ Excel based data frame tableData: First, save data frame tab delimited file (don’t want use comma delimited commas data elements): save file working directory called tableData.tsv. can see working directory typing getwd() R console. Opening file general-purpose text editor, see following: Next, follow steps open file Excel: Open Excel Click File tab Click Open option Navigate working directory (shown results getwd()) Next File name text box, change dropdown type Files (.) Double click tableData.tsv text import wizard open , first window, choose Delimited radio button automatically picked, click Next. second window, click Tab delimiter automatically checked, click Finished. Use many formatting tools within Excel customize table Excel, simple copy paste tables word processing presentation software products. example using one default Excel table formats .  simple table produced Microsoft™ Excel","code":"tableData <- tableResults(eList) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Water Year  ##  ##    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux ##              cms            mg/L             10^6 kg/yr  ##  ##    1980      4.25     0.949     1.003    0.1154     0.106 ##    1981      2.22     1.035     0.999    0.0675     0.108 ##    1982      3.05     1.036     0.993    0.0985     0.110 ##    1983      4.99     1.007     0.993    0.1329     0.112 ##    1984      5.72     0.990     1.002    0.1597     0.114 ##    1985      1.52     1.057     1.017    0.0489     0.116 ##    1986      2.63     1.062     1.038    0.0903     0.119 ##    1987      3.37     1.079     1.062    0.1142     0.122 ##    1988      1.87     1.120     1.085    0.0660     0.125 ##    1989      5.61     1.055     1.105    0.1638     0.127 ##    1990      4.01     1.115     1.125    0.1349     0.129 ##    1991      2.75     1.172     1.143    0.0980     0.130 ##    1992      2.19     1.203     1.159    0.0810     0.132 ##    1993      3.73     1.215     1.173    0.1306     0.132 ##    1994      5.48     1.144     1.187    0.1634     0.133 ##    1995      2.41     1.266     1.201    0.0928     0.134 ##    1996      6.24     1.134     1.213    0.1980     0.135 ##    1997      5.83     1.180     1.221    0.1884     0.136 ##    1998      4.88     1.236     1.229    0.1593     0.137 ##    1999      2.90     1.277     1.238    0.0919     0.138 ##    2000      4.72     1.213     1.253    0.1627     0.139 ##    2001      4.88     1.251     1.268    0.1655     0.140 ##    2002      1.24     1.321     1.285    0.0483     0.141 ##    2003      8.64     1.140     1.303    0.2664     0.143 ##    2004      5.28     1.274     1.321    0.1832     0.144 ##    2005      3.81     1.360     1.341    0.1444     0.146 ##    2006      3.59     1.382     1.362    0.1409     0.147 ##    2007      4.28     1.408     1.382    0.1593     0.149 ##    2008      2.56     1.477     1.401    0.1008     0.149 ##    2009      3.68     1.409     1.419    0.1328     0.149 ##    2010      7.19     1.323     1.438    0.2236     0.149 ##    2011      5.24     1.438     1.457    0.1554     0.148 write.table(tableData, file=\"tableData.tsv\",sep=\"\\t\",              row.names = FALSE,quote=FALSE) Year  Discharge [cms]   Conc [mg/L] FN_Conc [mg/L]  Flux [10^6kg/yr]    FN_Flux [10^6kg/yr] 1980       4.25            0.949          1.003          0.1154             0.106   1981       2.22            1.035          0.999          0.0675             0.108  1982       3.05            1.036          0.993          0.0985             0.110  ..."},{"path":"/articles/EGRET.html","id":"savingPlots","dir":"Articles","previous_headings":"","what":"Saving Plots","title":"Introduction to the EGRET package","text":"Plots can saved R JPG, PNG, PDF, Postscript files. JPG PNG easy use number programs (Microsoft™ Word PowerPoint, example), images resized later. PDF Postscript images easily re-sizable. three steps saving plots. first open “device” (declare output type file name). second step execute function just plotting screen, output appear. third step turn device. also possible put many plots within pdf. simple examples demonstrate easily: many additional options devices. See R help files information. One useful option larger fluxBiasMulti graph adjust height width output. output fluxBiasMulti larger default pdf postscript devices. Therefore, specifying height width eliminates R re-size graphic:","code":"jpeg(\"plotFlowSingle.jpg\") plotFlowSingle(eList, 1) dev.off()  png(\"plotFlowSingle.png\") plotFlowSingle(eList,1) dev.off()  pdf(\"plotFlowSingle.pdf\") plotFlowSingle(eList,1) dev.off()  postscript(\"plotFlowSingle.ps\") plotFlowSingle(eList,1) dev.off()  #Many plots saved to one pdf: pdf(\"manyPlots.pdf\") plotFlowSingle(eList,1) plotFlowSingle(eList,2) plotFlowSingle(eList,3) plotFlowSingle(eList,4) dev.off() postscript(\"fluxBiasMulti.ps\", height=10,width=8) fluxBiasMulti(eList) dev.off()"},{"path":"/articles/EGRET.html","id":"disclaimer","dir":"Articles","previous_headings":"","what":"Disclaimer","title":"Introduction to the EGRET package","text":"software approved release U.S. Geological Survey (USGS). Although software subjected rigorous review, USGS reserves right update software needed pursuant analysis review. warranty, expressed implied, made USGS U.S. Government functionality software related material shall fact release constitute warranty. Furthermore, software released condition neither USGS U.S. Government shall held liable damages resulting authorized unauthorized use.","code":""},{"path":[]},{"path":"/articles/Enhancements.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Guide to EGRET 3.0 enhancements","text":"vignette documents set enhancements EGRET software package. EGRET stands “Exploration Graphics RivEr Trend” developed Robert M. Hirsch Laura DeCicco U.S. Geological Survey. EGRET package implements WRTDS “Weighted Regressions Time, Discharge, Season” set related exploratory tools data sets river discharge river water quality. Version 2.0 originally published October, 2010. document, 3.0 enhancements assumes reader already good understanding WRTDS EGRET implementation method. Closely connected EGRET package package called EGRETci (refers confidence intervals) developed Hirsch DeCicco. EGRETci package adds variety uncertainty analyses WRTDS method contained EGRET. Accompanying release EGRET 3.0 release EGRETci 2.0 carries various types uncertainty analyses associated new methods presented EGRET 3.0. two releases tightly linked terms naming conventions sharing various objects . Reference made EGRETci functions course describing EGRET enhancements. release EGRET 3.0 adds new flexibility WRTDS method. flexibility new version provides two kinds. One ability partition sample data two periods, one one , change happened watershed believe important, sudden, lasting impact water quality. ability relax assumption stationarity streamflow flow normalization process. shorthand refer first enhancements “wall”, second “Generalized Flow Normalization”. document discusses motivations general concepts behind enhancements, moves instructions implementation. assumed reader already good working knowledge WRTDS EGRET. Basic reference material already familiar method software include: Hirsch, Moyer Archfield, 2010 (https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1752-1688.2010.00482.x) Hirsch DeCicco, 2015 (https://pubs.usgs.gov/tm/04/a10/) “Introduction EGRET package” included EGRET package. thorough discussion generalized flow normalization method implemented EGRET enhancements, see paper: “Tracking changes nutrient delivery western Lake Erie: Approaches compensate variability trends streamflow” (https://www.sciencedirect.com/science/article/pii/S0380133018302235).","code":""},{"path":"/articles/Enhancements.html","id":"the-wall","dir":"Articles","previous_headings":"","what":"The “wall”","title":"Guide to EGRET 3.0 enhancements","text":"idea “wall” appropriately handle events believe may result sharp discontinuity way concentrations behave function discharge, year, season. WRTDS designed working assumption changes concentration-discharge relationship (typically depicted EGRET contour plots) gradual, responding changes behavior many actors watershed. use statistical smoothing time, central WRTDS, predicated idea changes system gradual. gradual changes driven changes population (hence wasteloads), changes land use land use practices many landowners, many changes point source controls implemented many dischargers. know can situations depart assumption gradual change. obvious ones : upgrades single dominant point source discharge, large infrastructure changes storm-water management (e.g. tunnel projects big cities significantly curtail combined sewer overflows), construction removal major dam (causing pollutant interest mix large volume water reservoir significantly changing concentration-discharge relationship extreme cases virtually eliminating relationship concentration discharge). another category abrupt change also considered, “reset” river conditions may result extreme flood extreme drought. hypothesis behavior water quality changed result extreme event change short term thing (.e. duration event) rather something persists number years. new “wall” concept can provide effective way perform hypothesis test event question brought lasting change, approach allows us describe nature change took place. Operationally wall idea . refer moment time think change happened “wall.” purposes need define specific day, even though might stretch period weeks months. code, day called sample1EndDate next calendar day becomes sample2StartDate computed automatically code based sample1EndDate. code split Sample data frame two non-overlapping data frames: Sample1 Sample2. Sample1 samples collected wall Sample2 samples collected . estimate surfaces object (describes concentration function time, discharge, season) want characterization part surface wall use data Sample1 data Sample2. similarly, characterize part surface wall want use data Sample2 data Sample1. code within ability estimate two segments surface separately “stitch” together single continuous surface. workflows described document allow user specify want use wall must specify sample1EndDate. code argument called wall logical variable. default functions wall = FALSE wall specified, user sets wall = TRUE.","code":""},{"path":"/articles/Enhancements.html","id":"generalized-flow-normalization-gfn","dir":"Articles","previous_headings":"","what":"Generalized Flow Normalization (GFN)","title":"Guide to EGRET 3.0 enhancements","text":"original implementations WRTDS, idea flow normalization create records summary statistics (e.g. annual means concentration flux) influenced year--year random variations discharge. However, one problem approach flow normalization can end removing effect random variations discharge can also remove effect long-term trends discharge, trends exist period study. original WRTDS flow-normalization approach based assumption probability distribution discharge stationary. seasonal component distribution doesn’t change year year. original paper WRTDS (published 2010) (https://onlinelibrary.wiley.com/doi/full/10.1111/j.1752-1688.2010.00482.x) identified limitation method indicated method enhanced future deal cases , time frame analysis, discharges substantially non-stationary. issue becomes serious either time period analyzed fairly long (say two decades) /trends strong. new technique (GFN) enhancement called 2010. original method flow normalization becomes special case GFN, specify probability distribution discharge stationary (respect years). can call special case, stationary flow normalization (SFN). Using GFN, overall trend water quality (either concentration flux) can characterized two components. first components result changes concentration versus discharge relationship. WRTDS may substantial differences amount change relationship function season function discharge, can integrate changes seasons probability distribution discharge order get integrated measure “Concentration versus Discharge Trend Component” abbreviate CQTC. second component trend water quality result changes probability distribution discharge. call “Discharge Trend Component” QTC. details calculated provided (manuscript Choquette, Hirsch, Murphy, Johnson Confessor related nutrient loadings western basin Lake Erie, manuscript currently review). two ways might envision change probability distribution discharge taking place: abrupt gradual.","code":""},{"path":"/articles/Enhancements.html","id":"abrupt-change-in-the-discharge-distribution","dir":"Articles","previous_headings":"Generalized Flow Normalization (GFN)","what":"Abrupt change in the discharge distribution","title":"Guide to EGRET 3.0 enhancements","text":"situation singular engineered action results change probability distribution streamflow. new code allows us treat discharge stationary within two periods record, allows distribution first period different second period. obvious examples completion dam upstream monitoring site. needs dam clear impact discharges monitoring site (e.g. decreasing peak discharges high flow /increasing low flows). changes include: removal dam, institution new operating policy dam (e.g. greatly increasing size minimum flows support habitat), major new diversions water watershed. well-defined criteria magnitude change trigger use GFN except say big enough comparisons flow duration curves show easily discernible difference. code argument called flowBreak logical variable. believe abrupt shift set flowBreak = FALSE. believe shift set flowBreak = TRUE. state flowBreak = TRUE must define exact day change happens. call last day change Q1EndDate. reality might able specify exact date change modeling approach demands pick single day. case new dam, may better set change date initial period reservoir filling, rather day dam construction completed. new code allows single abrupt change. Note flowBreak wall different ideas. cases one might true false, might true. cases timing kinds abrupt changes , need . flowBreak appropriate reason believe flow behavior changed, wall appropriate conditions affecting relationship streamflow water quality abruptly changed. abrupt change flow behavior typically related changes way water stored, diverted watershed. abrupt changes relationship streamflow water quality typically related substantial changes wastewater treatment (including treatment stormwater) introduction major new point sources, also related changes water storage diversions.","code":""},{"path":"/articles/Enhancements.html","id":"gradual-change-in-the-discharge-distribution","dir":"Articles","previous_headings":"Generalized Flow Normalization (GFN)","what":"Gradual change in the discharge distribution","title":"Guide to EGRET 3.0 enhancements","text":"used situation distribution discharges appears changed gradual fashion period record. Unlike abrupt change approach described , treat distribution potentially changing one year next way record. continuous change might arise changes climate, changes water use (increased consumptive use increased groundwater pumping), changes water imports exports, changes artificial drainage (e.g. tile drains restoration destruction wetlands). may driven several factors. don’t really know causes changes us use GFN approach. implement gradual change approach using moving window select set years considered relevant estimation distribution given year. defining argument called windowSide. given year middle part record window used characterize probability distribution discharge set years centered year making WRTDS calculations, plus windowSide number years either side . example windowSide equal 7, year evaluated WRTDS 2007, whole window runs 15 years: 2000 2010. Contrast approach SFN approach used original implementation WRTDS. Let’s say evaluating 2007 discharge data using runs 1980 2016. SFN approach discharge data set used estimating FN values 2007 runs 1980 2016, GFN approach windowSide = 7 discharge record used 2007 2000-2010. year evaluated close start end period record, window centered year evaluated. Rather run duration (2 * windowSide) + 1 either start end record. , year interest 2011, windowSide = 7, record ended 2016, period covered 2002 2016. can illustrate looks like real example. Daily discharge data data set runs 1981-08-06 2016-01-14. want compute flow normalized concentrations fluxes water years 1995 - 2015, using windowSide = 7.  figure, vertical blue lines indicate start end discharge record Daily data frame. horizontal red bars indicate water year want compute estimates. left right red bars gray bar indicates temporal extent set days used provide discharge record used flow normalization calculations one water year. Note red bars approach end available record flow normalization period become asymmetrical around red bar, cases total length flow normalization period always 15 years.","code":""},{"path":"/articles/Enhancements.html","id":"combining-gradual-and-abrupt-change-in-discharge","dir":"Articles","previous_headings":"Generalized Flow Normalization (GFN)","what":"Combining gradual and abrupt change in discharge","title":"Guide to EGRET 3.0 enhancements","text":"code allows abrupt gradual approaches combined. example, say long discharge record believe gradual long-term trends flow record driven climate water use, also abrupt change year due construction large dam. case, can specify abrupt change, either side abrupt change gradual change characterize moving window. means window moves, doesn’t cross line abrupt change. , arguments needed specify might look like following flowBreak = TRUE, Q1EndDate = “1990-07-31”, windowSide = 7.","code":""},{"path":"/articles/Enhancements.html","id":"the-windowside-argument","dir":"Articles","previous_headings":"Generalized Flow Normalization (GFN)","what":"The windowSide argument","title":"Guide to EGRET 3.0 enhancements","text":"One final note selection windowSide. know theory-based method picking right value windowSide. can explore impact results looking plots flow normalize annual values versus time (like plotConcHist, plotFluxHist). small value windowSide result somewhat jagged flow normalized curve fluctuations purely result adding deleting flow normalizing years window slides forward. contrast, windowSide gets large, approaches half length entire discharge record Daily data frame flow normalized record approach stationary flow normalized record really fail account non-stationarity discharge. compare results GFN method SFN approach approach available EGRET version 2.6, use exactly starting ending dates Daily data frame, get exactly results set windowSide large number (always covers entire time span Daily data frame). Setting windowSide = 0 also produce results equivalent SFN.","code":""},{"path":"/articles/Enhancements.html","id":"problem-set-up","dir":"Articles","previous_headings":"","what":"Problem set up","title":"Guide to EGRET 3.0 enhancements","text":"three distinct types problem set-ups possible new formulation distinct workflow outputs. known Pairs, Series, Groups. terms mean ?","code":""},{"path":"/articles/Enhancements.html","id":"pairs","dir":"Articles","previous_headings":"Problem set up","what":"Pairs","title":"Guide to EGRET 3.0 enhancements","text":"situation question : GFN estimates differ one specific year another specific year. may beginning end period record, may years selected based overall study design (e.g. report water quality change 1985 - 2015 many sites). function situation called runPairs. outputs GFN concentration flux two years, apportioning change CQTC QTC parts. associated bootstrap estimate uncertainty overall change. accomplished runPairsBoot function EGRETci. pairs analysis can done without wall concentration record analyzed. results can also summarized using tableChange earlier versions EGRET.","code":""},{"path":"/articles/Enhancements.html","id":"series","dir":"Articles","previous_headings":"Problem set up","what":"Series","title":"Guide to EGRET 3.0 enhancements","text":"situation want produce graphic table shows water quality change time. might graph annual mean concentration FN annual mean concentration, graph showing annual flux FN annual flux. type analysis performed runSeries function EGRET. estimated time histories can viewed plotConcHist plotFluxHist functions users already familiar . can also table outputs time series using tableResults. also bootstrap analysis called runSeriesBoot EGRETci computes 90% confidence interval (percent interval) FN concentration FN flux around annual values. analysis done without wall concentration records analyzed.","code":""},{"path":"/articles/Enhancements.html","id":"groups","dir":"Articles","previous_headings":"Problem set up","what":"Groups","title":"Guide to EGRET 3.0 enhancements","text":"situation might want answer questions : average flow-normalized flux period 1997 - 2017 compare average flow-normalized flux period 1980 - 1996. approach operates like Pairs approach except case rather comparing two specific years, compares two groups years. function runs analysis called runGroups like runPairs computes change two groups years, also apportions change CQTC QTC components. also associated uncertainty analysis can conducted function runGroupsBoot EGRETci package. motivation type analysis might water quality goals may set indicating average later period less 75 percent average earlier period. wall may used analyses, one might argue fair analysis change might suitable use approach things happened earlier period influence estimates later period, vice versa. case, wall might used, natural engineered event watershed, political regulatory decision. two groups years can contiguous , might gap . gap might appropriate major investment pollution control took several years start implementation end (say combined sewer overflow control system many components) question posed : might impact major upgrade.","code":""},{"path":"/articles/Enhancements.html","id":"other-general-comments","dir":"Articles","previous_headings":"","what":"Other general comments","title":"Guide to EGRET 3.0 enhancements","text":"Note idea wall idea generalized flow normalization quite different . wall generally deals event suddenly directly influenced water quality generalized flow normalization deals something influences probability distribution discharge. cases, event pivotal . One example completion removal dam, need related , time boundaries may quite different. can analysis wall use generalized flow normalization, can generalized flow normalization wall, can , can neither. latter case , original simpler EGRET workflows provide analyses needed. others need use new workflows new functions EGRET 3.0. Users aware even though pre-existing functions used implement new capabilities EGRET 3.0, workflow specific commands carry analyses done prior versions unchanged. Also note general rule, new flexible approaches appropriate cases period studied longer 15 years. trend periods 10 years, often great interest resource managers, approaches specified older code ones used. analyses introduced may advantage discharge data set Daily data frame extend substantially beyond period water quality record considered. contrast guidance given earlier EGRET releases, encourage user limit Daily record slightly longer (< 1 year longer) extent water quality record Sample data frame. user needs decide far take , windowSide approach used, point extending Daily data frame windowSide years beyond range Sample data frame. Note using large value windowSide setting zero, lead results slightly different computed using SFN set years Daily record different. However, Daily record used windowSide large value zero, results identical SFN results. problem types, analysis must start standard EGRET eList (containing least INFO, Daily, Sample data frames). type problem (Pairs, Series, Group) one basic function name like runPairs data processing (without bootstrap uncertainty analysis). designed run batch mode, call function containing list parameters desired (e.g. lastDaySample1, paStart paLong) many defaults. output function create object contains results calculation, also contains needed metadata problem set . example runPairs creates object named pairResults contains salient results also set attributes crucial proper documentation results. , EGRETci 2.0 related function bootstrap analysis, example runPairsBoot. One arguments function object pairResults. use attributes object used set bootstrap implementation (arguments relate specifically bootstrap). output bootstrap results name like pairBootOut also contain full list parameters used running original analysis bootstrap analysis. remainder document describe work flows outputs three types analyses: Pairs, Series, Groups.","code":""},{"path":"/articles/Enhancements.html","id":"pairs-analysis","dir":"Articles","previous_headings":"","what":"Pairs analysis","title":"Guide to EGRET 3.0 enhancements","text":"First going run function runPairs. data set use example nitrate plus nitrite data included package Choptank River. sample data cover period 1979-10-24 2011-09-29. example going compare two years 1985 2010. called year1 year2 respectively. designate calendar year period interest ends (like water years). paStart = 10 paLong = 12, year1 = 1985, looking results 1984-10-01 1985-09-30. paStart = 3 paLong = 4, year1 = 1985, looking results 1985-03-01 1985-06-30. first example use wall flowBreak either, use moving window flow normalization results. can use windowSide argument value integer greater 1 designate want window automatically set, window flow normalization width (2 * windowSide) + 1. suggested value windowSide 7 must specify value want. default. first example specify year1 1985 year2 2010 wall, use automatic flow window designation, windowSide value 7. Let’s take look output. information Sample1 Sample2 can visually check size Sample data set make sure default settings minNumObs minNumUncen reasonable. case Sample1 Sample2 , wall different want make sure neither small (e.g. less 100 samples). Next see output pretty self-explanatory. express change concentration first concentration units percentage change, case + 39 %. see line tells us part change due change Concentration versus Discharge Trend Component (CQTC). case 42 %. means change probability distribution discharge concentration trend 42 %. see Discharge Trend Component (QTC) -3.1 %. amount trend Concentration versus Discharge relationships hadn’t changed period, probability distribution discharge changed. see exact kind results flux expressed millions kg / year. case much larger percentage change see concentration changes concentration pronounced high discharge good deal positive trend upper end distribution discharge. couple things note. often case QTC relatively small concentration trend can quite large flux trend. stands reason since discharge important aspect flux. , also note entirely possible CQTC QTC opposite signs, cases virtually cancel . relationships important interpretations. example, case CQTC negative meaning dilute water QTC positive meaning water net effect near zero trend flux. last part output matrix consisting 2 rows 7 columns. actually object called pairResults runPairs returns (difference printed fewer significant figures). Everything first row concentration (mg/L). Everything second row flux (million kg/year). ’s columns represent, take order . Let’s interpret mean case used example: get percent changes described , use information provided attribute “”. 2 vectors, one concentration, one flux: can provide nice looking table results follows (specified number significant digits): One final note output can also express flux information yields, dividing drainage area. can handy looking many watersheds. nice see flux trends compare unit area basis. get yields can matrix multiplication end new object still concentrations first row yields second row. example want yield kg/km^2/year. . First can create another data frame called pairResultsYield, print table.","code":"library(EGRET)  eList <- Choptank_eList  pairResults <- runPairs(eList,                          year1 = 1985, year2 = 2010,                         windowSide = 7) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Water Year  ##  ##  Change estimates  2010  minus  1985  ##  ##  For concentration: total change is  0.397 mg/L ##  expressed as Percent Change is  39 % ##  ##  Concentration v. Q Trend Component  42 % ##        Q Trend Component             -3.1 %  ##  ##  ##  For flux: total change is  0.0543 million kg/year ##  expressed as Percent Change is  51 % ##  ##  Concentration v. Q Trend Component  32 % ##        Q Trend Component             19 %  ##  ##      TotalChange  CQTC    QTC  x10  x11  x20  x22 ## Conc       0.397 0.429 -0.032 1.01 1.03 1.44 1.43 ## Flux       0.054 0.034  0.020 0.12 0.11 0.15 0.16 concPercents <- attr(pairResults, \"Other\")[[\"PercentChangeConc\"]] concPercents ## Total Percent Change         CQTC Percent          QTC Percent  ##            38.564699            41.697092            -3.132393 fluxPercents <- attr(pairResults, \"Other\")[[\"PercentChangeFlux\"]] fluxPercents ## Total Percent Change         CQTC Percent          QTC Percent  ##             50.68378             31.94442             18.73936 knitr::kable(pairResults, digits = 4) # note that you don't have to use the kable function from knitr to  # see the results, you can just give the command pairResults # and you will get the output, it just won't look as nice as this pairResultsYield <- pairResults * c(1, 1000000 / eList$INFO$drainSqKm ) knitr::kable(pairResultsYield, digits = 4)"},{"path":"/articles/Enhancements.html","id":"attributes-of-pairresults","dir":"Articles","previous_headings":"Pairs analysis","what":"Attributes of pairResults","title":"Guide to EGRET 3.0 enhancements","text":"new feature EGRET 3.0 code set attributes objects pairResults make sure full documentation arguments used define analysis produced object. four attributes associated pairResults provide documentation. .","code":"attr(pairResults, \"yearPair\") ## paStart  paLong   year1   year2  ##      10      12    1985    2010 attr(pairResults, \"dateInfo\") ##   flowNormStart flowNormEnd  flowStart    flowEnd ## 1    1979-10-01  1994-09-30 1984-10-01 1985-09-30 ## 2    1996-10-01  2011-09-30 2009-10-01 2010-09-30 attr(pairResults, \"SampleBlocks\") ## sample1StartDate   sample1EndDate sample2StartDate   sample2EndDate  ##     \"1979-10-24\"     \"2011-09-29\"     \"1979-10-24\"     \"2011-09-29\" attr(pairResults, \"Other\") ## $minNumObs ## [1] 100 ##  ## $minNumUncen ## [1] 50 ##  ## $windowY ## [1] 7 ##  ## $windowQ ## [1] 2 ##  ## $windowS ## [1] 0.5 ##  ## $wall ## [1] FALSE ##  ## $edgeAdjust ## [1] TRUE ##  ## $QStartDate ## [1] \"1979-10-01\" ##  ## $QEndDate ## [1] \"2011-09-30\" ##  ## $PercentChangeConc ## Total Percent Change         CQTC Percent          QTC Percent  ##            38.564699            41.697092            -3.132393  ##  ## $PercentChangeFlux ## Total Percent Change         CQTC Percent          QTC Percent  ##             50.68378             31.94442             18.73936"},{"path":"/articles/Enhancements.html","id":"doing-uncertainty-analysis-on-the-runpairs-results","dir":"Articles","previous_headings":"Pairs analysis","what":"Doing uncertainty analysis on the runPairs results","title":"Guide to EGRET 3.0 enhancements","text":"uncertainty analysis results created runPairs done function runPairsBoot EGRETci. arguments used create runPairs analysis imported bootstrap analysis runPairsBoot obtains attributes pairResults object. documentation runPairsBoot see vignette EGRETci 2.0 enhancements.","code":""},{"path":"/articles/Enhancements.html","id":"a-note-about-minnumobs","dir":"Articles","previous_headings":"Pairs analysis","what":"A note about minNumObs","title":"Guide to EGRET 3.0 enhancements","text":"Note may sure going analysis, many samples segment need make adjustment minNumObs minNumUncen. function tell many samples segment adjust parameters necessary, examining output may conclude one segments simply samples (e.g. fewer 50) may want another run adjusting placement wall perhaps eliminating sample size either subsample greater 50. way runPairs adjusts minimum sample sizes uses argument fractMin reduce minNumObs account small sample size. default value fractMin 0.75. Suppose nObs sample size (smaller two sample sizes wall) minNumObs adjusted 0.75 * nObs. However, user may want minNumObs reduced , case set fractMin = 1 (values fractMin also allowed). One note minNumObs experience shown large data sets used (thousands observations) may helpful stability WRTDS model set minNumObs larger value, 400. particularly important bootstrap calculations described documentation EGRETci. decision increase minNumObs must set runPairs bootstrap code simply inherit argument runPairs.","code":""},{"path":"/articles/Enhancements.html","id":"a-more-complex-pairs-example","dir":"Articles","previous_headings":"Pairs analysis","what":"A more complex pairs example","title":"Guide to EGRET 3.0 enhancements","text":"Let’s say dam built year 1995 (say 1995-06-01) flow distribution changed time, might anticipate concentration versus discharge relationship also changed time. Let’s start looking range dates data covers (discharge data water quality data). Let’s say want analysis include discharge data water years 1980 - 2010. set QStartDate = “1979-10-01” QEndDate = “2010-09-30”. dam likely changed discharge distribution want put flowBreak time dam construction need specify: flowBreak = TRUE Q1EndDate = “1995-05-31”. , let’s say concerned may also trends flow distribution pre-dam period post-dam period. let’s set windowSide = 7. also think existence dam result change concentration versus discharge relationship (dam creates large mixing volume post-dam concentrations much less influenced discharge case dam built). want wall = TRUE sample1EndDate = “1995-05-31” Finally, like restrict analysis period April - August year pair comparison years 1985 2010. Thus: paStart = 4, paLong = 5, year1 = 1985, year2 = 2010. arguments left default values. results extreme previous ones, analysis isolates later period higher concentrations higher flows earlier period much lower concentrations somewhat lower flows.","code":"summary(eList$Daily$Date) ##         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.  ## \"1979-10-01\" \"1987-09-30\" \"1995-09-30\" \"1995-09-30\" \"2003-09-30\" \"2011-09-30\" summary(eList$Sample$Date) ##         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.  ## \"1979-10-24\" \"1989-01-06\" \"1994-11-27\" \"1995-10-30\" \"2002-11-28\" \"2011-09-29\" pairResults2 <- runPairs(eList, year1 = 1985, year2 = 2010,                           windowSide = 7, flowBreak = TRUE,                           Q1EndDate = \"1995-05-31\", wall = TRUE,                          sample1EndDate = \"1995-05-31\",                           QStartDate = \"1979-10-01\",                           QEndDate = \"2010-09-30\",                           paStart = 4, paLong = 5) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Season Consisting of Apr May Jun Jul Aug  ##  ##  Sample data set was partitioned with a wall right after  1995-05-31  ##  ##  Change estimates  2010  minus  1985  ##  ##  For concentration: total change is  0.412 mg/L ##  expressed as Percent Change is  45 % ##  ##  Concentration v. Q Trend Component  47 % ##        Q Trend Component             -2.4 %  ##  ##  ##  For flux: total change is  0.0456 million kg/year ##  expressed as Percent Change is  51 % ##  ##  Concentration v. Q Trend Component  37 % ##        Q Trend Component             14 %  ##  ##      TotalChange  CQTC    QTC   x10   x11  x20  x22 ## Conc       0.412 0.435 -0.022 0.915 0.923 1.35 1.34 ## Flux       0.046 0.033  0.012 0.092 0.089 0.13 0.13 attr(pairResults2, \"yearPair\") ## paStart  paLong   year1   year2  ##       4       5    1985    2010 attr(pairResults2, \"dateInfo\") ##   flowNormStart flowNormEnd  flowStart    flowEnd ## 1    1979-10-01  1994-09-30 1985-04-01 1985-08-30 ## 2    1995-10-01  2010-09-30 2010-04-01 2010-08-30 attr(pairResults2, \"SampleBlocks\") ## sample1StartDate   sample1EndDate sample2StartDate   sample2EndDate  ##     \"1979-10-24\"     \"1995-05-31\"     \"1995-06-01\"     \"2011-09-29\" attr(pairResults2, \"Other\") ## $minNumObs ## [1] 100 ##  ## $minNumUncen ## [1] 50 ##  ## $windowY ## [1] 7 ##  ## $windowQ ## [1] 2 ##  ## $windowS ## [1] 0.5 ##  ## $wall ## [1] TRUE ##  ## $edgeAdjust ## [1] TRUE ##  ## $QStartDate ## [1] \"1979-10-01\" ##  ## $QEndDate ## [1] \"2010-09-30\" ##  ## $PercentChangeConc ## Total Percent Change         CQTC Percent          QTC Percent  ##            44.674825            47.106474            -2.431649  ##  ## $PercentChangeFlux ## Total Percent Change         CQTC Percent          QTC Percent  ##             51.38175             37.36370             14.01805"},{"path":"/articles/Enhancements.html","id":"series-analysis","dir":"Articles","previous_headings":"","what":"Series Analysis","title":"Guide to EGRET 3.0 enhancements","text":"purpose Series analysis create time series flow-normalized concentrations flow-normalized flux values. function runSeries EGRET package. arguments function nearly identical used runPairs. function call look like , showing arguments. see two arguments default value. first eList generally just eList data set working . second windowSide. user wants use set years discharge data flow-normalize every year record specify windowSide = 0. user wants window years used flow normalization slide forward time year analyzed windowSide set equal positive integer (7 suggested value, cases may prudent increase , return question later). arguments surfaceStart surfaceEnd can generally left call function, sometimes can useful. define time period want calculate flow-normalized results. date variables written “yyyy-mm-dd”. Left default values period analyzed run slightly first sample date slightly last sample date. working water years start first water year data end last water year data. using period analysis adjusted correspond period analysis. times may wish run analysis shorter period design multisite study low sample density early later period although may want use data periods comfortable trying make annual estimates times low sampling density. , example, working water years, handful data 1980-06-01 1981-09-30 sampling starts earnest October 1981, may want set surfaceStart = “1981-10-01”. One argument note oldSurface. logical variable. situation use . old analysis created EGRET 2.6 earlier code exact data set already created object surfaces using modelEstimation. can avoid computations just accept old surfaces object proceed computations. wall work, modelEstimation allow . Note modelEstimation hasn’t run, possible look diagnostic graphics look quality model (fluxBiasMulti, involving plotting predictions residuals plotConcPred plotResidQ). types plots desired best thing first run modelEstimation runSeries, oldSurfaces = TRUE. wall used, way create kinds diagnostic plots split Sample data set two separate parts (wall), create eLists , run modelEstimation make various plots evaluate quality two different models. can also set last argument verbose FALSE want avoid printing percentage progress indicators console. Let’s analysis set used first example. look standard outputs might want consider. comply CRAN requirements long takes build vignette, ’ll leave example run user. might uncomfortable slightly jagged nature flow-normalized flux line may prefer use higher value windowSide. Let’s see happens increase windowSide = 9 . see minor differences slope trends, particularly flow normalized flux, none differences change fundamental sense happened two decade period. increase concentration 130% increase flux something range 230% 250%. choice windowSide argument fundamentally subjective. “small” results fluctuate somewhat moving time particularly wet year (dry year) moves flow normalization window moves . , make “large” approaching assumption stationarity discharge may believe inappropriate.","code":"eListOut <- runSeries(eList, windowSide,                        surfaceStart = NA, surfaceEnd = NA,                       flowBreak = FALSE, Q1EndDate = NA,                       QStartDate = NA, QEndDate = NA,                       wall = FALSE, oldSurface = FALSE,                       sample1EndDate = NA,                       sampleStartDate = NA, sampleEndDate = NA,                       paStart = 10, paLong = 12,                       minNumObs = 100, minNumUncen = 50,                        windowY = 7, windowQ = 2,                       windowS = 0.5, edgeAdjust = TRUE,                        verbose = TRUE) eListOut <- runSeries(eList, windowSide = 7, verbose = FALSE) tableResults(eListOut) plotConcHist(eListOut) plotFluxHist(eListOut) tableChange(eListOut, yearPoints = c(1985, 1995, 2010)) eListOut <- runSeries(eList, windowSide = 9, verbose = FALSE) plotConcHist(eListOut) plotFluxHist(eListOut) tableChange(eListOut, yearPoints = c(1985, 1995, 2010))"},{"path":"/articles/Enhancements.html","id":"the-bootstrap-uncertainty-analysis-for-runseries","dir":"Articles","previous_headings":"Series Analysis","what":"The bootstrap uncertainty analysis for runSeries","title":"Guide to EGRET 3.0 enhancements","text":"case runSeries can uncertainty analysis provides us confidence intervals around flow normalized time series estimated running runSeries function. case actually use functions used EGRETci 1.0.3, modified accommodate flexible features runSeries. bootstrap computations associated runSeris described EGRETci 2.0 enhancements vignette.","code":""},{"path":"/articles/Enhancements.html","id":"an-example-of-a-complex-long-record-analysis","dir":"Articles","previous_headings":"Series Analysis","what":"An example of a complex long record analysis","title":"Guide to EGRET 3.0 enhancements","text":"run analysis long record requires use several important features EGRET 3.0 EGRETci 2.0. record USGS streamgage 09234500, Green River near Greendale, UT constituent chloride (parameter code 00940). streamgage located less kilometer downstream Flaming Gorge Dam, 150 meters tall stores 4.7 km^3 equivalent little twice long-term annual discharge river. large dam comparison discharge river. closure dam around 1962-1963 , somewhat arbitrarily place 1963-03-31. discharge record work runs 1950-10-01 2018-04-01. chloride record consists 601 observations running 1956-10-04 2018-02-01. However, large gap chloride record 2000-08-03 2012-08-09 51 observations gap.   Now, one first things take account fact gap August 2000 August 2012 chloride data. can use blankTime function just way older versions EGRET.   gives us realistic picture, recognizing really know nothing happening period data collection. figures telling us? see concentrations rising steeply around time closure dam generally declining since . reasonable hypothesis long period chloride decline dam closure filled reservoir water came contact lowland soils rocks high levels available chloride (high desert landscape) time newly submerged landscape moved towards equilibrium reservoir water, highly available chloride removed.  particularly interesting look around time closure dam figure zeros period.  see total reversal concentration versus discharge relationship. closure dam, winter-time concentrations increased function discharge summer-time concentrations decreased increasing discharge (probably representing idea large snow-melt events produced dilute water). dam closed low discharges resulted highest concentrations high values peaked summer rather winter. Next can look period 20 years closure dam see system evolved reservoir grew size wetted larger larger areas previously dry landscape.  see gradual decline chloride concentration get past 1972, almost total vanishing relationship discharge concentration vanishing relationship season concentration. makes sense, since now large volume stored water chloride concentration outflow just represents average concentration reservoir changes slightly time. Now, might want consider results different run data set wall. anticipate transition time dam closure smeared rather changing abruptly. Let’s run case: difference without wall transition contour plot gradual doesn’t reflect abrupt nature change. comply CRAN requirements long takes build vignette, ’ll leave example run user.","code":"siteID <- \"09234500\"  parameter_cd<-\"00940\" #5 digit USGS code Sample <- readNWISSample(siteID,parameter_cd,\"1956-10-04\",\"2018-02-01\") Daily <- readNWISDaily(siteID,\"00060\",\"1950-10-01\",\"2018-04-01\") INFO<- readNWISInfo(siteID,parameter_cd, interactive = FALSE) INFO$shortName <- \"Green River near Greendale, UT\" eList_Green <- mergeReport(INFO, Daily, Sample) eListOut <- runSeries(eList_Green, windowSide = 12,                       flowBreak = TRUE, Q1EndDate = \"1963-03-31\",                       wall = TRUE,  sample1EndDate = \"1963-03-01\",                       verbose = FALSE) plotConcHist(eListOut) plotFluxHist(eListOut) tableResults(eListOut) ##  ##    Green River near Greendale, UT  ##    Chloride ##    Water Year *  ##  ##    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux ##              cms            mg/L             10^6 kg/yr  ##  ##    1957     75.81      17.3      17.7     31.89      28.1 ##    1958     54.08      18.6      18.3     26.85      28.6 ##    1959     44.61      18.8      18.9     22.21      29.1 ##    1960     38.93      19.9      19.6     23.54      29.6 ##    1961     29.23      20.7      20.3     17.54      30.2 ##    1962     82.65      21.0      21.0     45.39      30.8 ##    1963      6.55      28.1      25.0      5.44      33.7 ##    1964     32.69      23.3      23.2     24.17      45.7 ##    1965     63.06      23.7      22.7     43.84      44.7 ##    1966     46.26      22.4      22.2     32.53      43.6 ##    1967     61.24      21.4      21.7     41.21      42.5 ##    1968     71.55      20.7      21.1     46.20      41.4 ##    1969     76.25      20.1      20.5     47.99      40.2 ##    1970     52.30      20.0      19.9     32.71      39.0 ##    1971     40.09      19.6      19.3     24.54      37.9 ##    1972     75.61      18.4      18.8     43.55      36.7 ##    1973     82.40      17.8      18.6     45.65      35.8 ##    1974     55.52      18.2      18.1     31.09      35.1 ##    1975     70.63      17.6      17.7     38.44      34.6 ##    1976     75.09      17.2      17.5     40.18      34.8 ##    1977     76.69      16.9      17.4     40.54      34.5 ##    1978     39.25      17.7      17.2     21.73      33.5 ##    1979     52.40      17.0      17.0     27.80      32.8 ##    1980     47.13      16.9      16.7     25.03      32.0 ##    1981     40.75      16.8      16.5     21.58      31.0 ##    1982     47.75      16.5      16.4     24.67      30.4 ##    1983    120.92      15.7      16.2     58.71      30.0 ##    1984     98.91      15.8      16.1     49.11      30.5 ##    1985     76.81      16.0      16.2     38.70      30.8 ##    1986     97.82      16.4      16.5     49.82      31.3 ##    1987     62.85      16.7      16.8     32.91      32.9 ##    1988     47.36      17.2      17.3     25.63      33.6 ##    1989     29.56      17.6      17.6     16.39      33.3 ##    1990     30.40      17.9      17.7     17.15      32.2 ##    1991     35.02      18.0      17.7     19.80      31.7 ##    1992     44.20      17.9      17.7     24.75      30.7 ##    1993     37.54      17.9      17.5     20.87      30.5 ##    1994     54.53      17.1      17.2     29.20      30.1 ##    1995     44.74      16.9      16.7     23.68      29.3 ##    1996     74.43      16.1      16.3     38.18      26.9 ##    1997     81.13      15.8      15.9     40.80      25.1 ##    1998     80.26      15.2      15.5     38.64      23.8 ##    1999     92.11      14.9      14.9     43.61      22.6 ##    2000     54.97      14.9      15.1     25.83      22.6 ##    2001     31.09      15.2      14.9     14.93      22.1 ##    2002     26.50      15.7      15.1     13.08      22.6 ##    2003     28.47      15.9      15.5     14.30      23.6 ##    2004     31.07      15.4      15.3     15.15      24.3 ##    2005     42.32      15.2      15.1     20.54      25.6 ##    2006     40.32      14.9      14.9     19.17      25.7 ##    2007     30.99      14.8      14.9     14.58      25.5 ##    2008     36.84      14.9      15.0     17.36      25.5 ##    2009     41.90      14.9      15.0     19.73      25.5 ##    2010     45.98      14.9      15.0     21.70      25.5 ##    2011     78.91      15.2      15.0     38.00      25.5 ##    2012     56.11      15.1      15.0     26.82      25.6 ##    2013     32.68      15.0      15.1     15.45      25.6 ##    2014     41.65      15.0      15.1     19.82      25.6 ##    2015     55.52      15.1      15.1     26.62      25.7 ##    2016     65.52      15.2      15.1     31.55      25.7 ##    2017    110.77      15.4      15.2     54.20      25.7 tableChange(eListOut, yearPoints = c(1957, 1963, 1983, 2017)) ##  ##    Green River near Greendale, UT  ##    Chloride ##    Water Year *  ##  ##            Concentration trends ##    time span       change     slope    change     slope ##                      mg/L   mg/L/yr        %       %/yr ##  ##  1957  to  1963       7.3       1.2        41       6.8 ##  1957  to  1983      -1.5    -0.057      -8.4     -0.32 ##  1957  to  2017      -2.5    -0.042       -14     -0.24 ##  1963  to  1983      -8.8     -0.44       -35      -1.8 ##  1963  to  2017      -9.8     -0.18       -39     -0.73 ##  1983  to  2017        -1     -0.03      -6.4     -0.19 ##  ##  ##                  Flux Trends ##    time span          change        slope       change        slope ##                   10^6 kg/yr    10^6 kg/yr /yr      %         %/yr ##  1957  to  1963          5.7         0.95           20          3.4 ##  1957  to  1983          1.9        0.072          6.7         0.26 ##  1957  to  2017         -2.3       -0.039         -8.4        -0.14 ##  1963  to  1983         -3.8        -0.19          -11        -0.56 ##  1963  to  2017           -8        -0.15          -24        -0.44 ##  1983  to  2017         -4.2        -0.12          -14        -0.42 eListOut <- blankTime(eListOut,                        startBlank = \"2000-10-01\",                        endBlank = \"2012-09-30\") plotConcHist(eListOut) plotFluxHist(eListOut) plotContours(eListOut, 1957, 2017, 10, 100,               contourLevels = seq(0,55,5), flowDuration = FALSE) plotContours(eListOut, 1961, 1966, 10, 100,               contourLevels = seq(0,55,5), flowDuration = FALSE) plotContours(eListOut, 1964, 1984, 10, 100,               contourLevels = seq(0,55,5), flowDuration = FALSE) eListOutNoWall <- runSeries(eList_Green, windowSide = 12,   flowBreak = TRUE, Q1EndDate = \"1963-03-31\",   wall = FALSE, verbose = FALSE)  plotContours(eListOutNoWall, 1961, 1966, 10, 100,               contourLevels = seq(0,55,5), flowDuration = FALSE)"},{"path":"/articles/Enhancements.html","id":"group-analysis","dir":"Articles","previous_headings":"","what":"Group analysis","title":"Guide to EGRET 3.0 enhancements","text":"concept group analysis wish compare just two different years runPairs rather, compare one group years another. example, may strategy nutrient reduction calls decreases average concentrations, average fluxes, period strategy went effect compared time went effect. , perhaps want evaluate consequences large investment pollution control went effect fairly abruptly point time want “” analysis. function serves purpose runGroups functions much like runPairs except considers two groups contiguous years rather considering simply two years. call function, arguments . arguments look familiar runPairs runSeries functions. new four new arguments : group1firstYear, group1lastYear, group2firstYear, group2lastYear. four required (defaults). one numeric value four-digit year. Let’s say working water years want analysis compare water years 1995 - 2004 water years 2005 - 2010. four arguments 1995, 2004, 2005, 2010 respectively. years designated always represent year specific period ends. Thus wanted designate group1 started November 1, 1989 ended March 31, 2000, wanted consider November March averages, set paLong = 5, paStart = 11, group1firstYear = 1990, group1lastYear = 2000. example, suppose sudden change point source nitrate watershed (using Choptank watershed example data), went effect end water year 2005 (2004-09-30), wanted evaluate impact months March April. , furthermore like make clean separation early data fit early-period model later data fit late-period model. can placing wall 2004-09-30. Finally, want use GFN, windowSide = 7. get. statement results output fairly self-explanatory, similar outputs runPairs. completeness, explanation outputs given . last part output matrix consisting 2 rows 7 columns. actually object called groupResults runGroups returns (difference printed limited number significant figures). Everything first row concentration (mg/L). Everything second row flux (million kg/year). ’s columns represent, take order : analysis uncertainty results done runGroupsBoot function EGRETci package. information sets problem passed function via groupResults object. argument values used runGroups attributes groupResults. see just requires using following commands.","code":"groupResults <- runGroups(eList, windowSide,                            group1firstYear, group1lastYear,                            group2firstYear, group2lastYear,                           surfaceStart = NA, surfaceEnd = NA,                            flowBreak = FALSE, Q1EndDate = NA,                           QStartDate = NA, QEndDate = NA,                           wall = FALSE, oldSurface = FALSE,                           fractMin = 0.75, sample1EndDate = NA,                            sampleStartDate = NA, sampleEndDate = NA,                            paStart = 10, paLong = 12,                            minNumObs = 100, minNumUncen = 50,                           windowY = 7, windowQ = 2, windowS = 0.5,                            edgeAdjust = TRUE, verbose = TRUE) groupResults <- runGroups(eList,                            group1firstYear = 1995, group1lastYear = 2004,                            group2firstYear = 2005, group2lastYear = 2010,                           windowSide = 7, wall = TRUE,                            sample1EndDate = \"2004-10-30\",                            paStart = 4, paLong = 2, verbose = FALSE) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Season Consisting of Apr May  ##  ##  Sample data set was partitioned with a wall right after  2004-10-30  ##  ##  Change estimates for ##  average of 2005  through 2010  minus average of 1995  through 2004  ##  ##  For concentration: total change is  0.153 mg/L ##  expressed as Percent Change is  14 % ##  ##  Concentration v. Q Trend Component  13 % ##        Q Trend Component             0.95 %  ##  ##  ##  For flux: total change is  0.00931 million kg/year ##  expressed as Percent Change is  5.2 % ##  ##  Concentration v. Q Trend Component  9.1 % ##        Q Trend Component             -3.9 %  ##  ##      TotalChange  CQTC     QTC  x10  x11  x20  x22 ## Conc      0.1529 0.142  0.0106 1.12 1.12 1.26 1.27 ## Flux      0.0093 0.016 -0.0069 0.18 0.18 0.19 0.19 attr(groupResults, \"groupInfo\") attr(groupResults, \"dateInfo\") attr(groupResults, \"SampleBlocks\") attr(groupResults, \"Other\")"},{"path":"/articles/Enhancements.html","id":"final-thoughts","dir":"Articles","previous_headings":"","what":"Final thoughts","title":"Guide to EGRET 3.0 enhancements","text":"think enhancements improve usefulness WRTDS. certainly useful one conditions met: 1) abrupt change drivers concentration versus discharge relationship, 2) substantial trend discharge (even change part flow duration curve), 3) water quality record long (say greater 20 years) giving us reasonable chance identifying meaningful trends discharge. many situations use enhancements EGRET lead results substantially different arise using earlier versions code. cases enhancements can prove crucial making meaningful interpretations water quality data sets.","code":""},{"path":"/articles/Overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"EGRET Overview and Update","text":"Evaluating long-term changes river conditions (water quality discharge) important use hydrologic data. carry evaluations, hydrologist needs tools facilitate several key steps process: acquiring data records variety sources, structuring ways facilitate analysis, processing data routines extract information changes may happening, displaying findings graphical techniques. R package called EGRET (Exploration Graphics RivEr Trends) developed carrying steps integrated manner. analysis water quality data used EGRET statistical method called Weighted Regressions Time, Discharge, Season (WRTDS). EGRET Update Overview intended guide users, pointing particular capabilities may want use meet data analysis goals. detailed description EGRET package WRTDS method contained EGRET User Guide. However, several major enhancements extensions method made since User Guide published 2015. EGRET Update Overview designed help user decide EGRET’s capabilities want apply, point relevant documents describe detail. include various journal articles explain motivations enhancements, provide mathematical formulations , show examples application. also includes references various supporting vignettes explain apply enhancements EGRET package. also several special applications R scripts written depend EGRET package, EGRET Overview Update describe point scripts. additional R package users EGRET aware , called EGRETci (stands confidence intervals). EGRETci package designed provide variety approaches uncertainty analysis related water quality trend results computed EGRET. EGRETci tightly linked EGRET, output dataframes objects produced EGRET serve inputs functions EGRETci. Throughout EGRET Update Overview make mention relevant functions EGRETci. home page EGRETci. end document brief description recent changes made EGRETci.","code":""},{"path":"/articles/Overview.html","id":"general-introduction-to-the-egret-package","dir":"Articles","previous_headings":"","what":"General Introduction to the EGRET package","title":"EGRET Overview and Update","text":"EGRET includes statistics graphics streamflow history, water quality trends, statistical modeling algorithm Weighted Regressions Time, Discharge, Season (WRTDS). entirely focused two data types. record daily mean discharge single streamgage. record must complete record, missing values allowed. also designed deal streams perennial, although adjustment made days zero negative discharge, intended used situations number zero negative discharge small (e.g. less 0.1% days). record water quality observations (near) streamgage discharge data available. water quality observations single analyte. requirements maximum minimum frequency data, requirement frequency consistent time. can multiple samples given day can many days samples. time day information stored sample data. means EGRET software appropriate working data believed experience substantial diurnal variations, unless samples always collected time day. data can censored uncensored. censored value one reported value either: less reporting limit, greater reporting limit. analyses EGRET work discharge data (call Flow History) analyses others work water quality data, water quality analyses depend discharge data covering entire time period analyzed.","code":""},{"path":[]},{"path":"/articles/Overview.html","id":"egret-overview-and-data-entry","dir":"Articles","previous_headings":"","what":"1. EGRET overview and data entry","title":"EGRET Overview and Update","text":"topics covered extensively Introduction EGRET package detail EGRET User Guide.","code":""},{"path":"/articles/Overview.html","id":"exploration-of-trends-in-discharge","dir":"Articles","previous_headings":"","what":"2. Exploration of trends in discharge","title":"EGRET Overview and Update","text":"EGRET many tabular graphical approaches exploring trends discharge. described Flow History component (pages 15 - 28) EGRET User Guide(pages 15 – 28) section 5 Introduction EGRET package. addition, script available new capabilities. called Daily Streamflow Trend Analysis. script includes graphical technique exploring trends across entire frequency distribution: “Quantile Kendall Plot”. technique described Choquette et al., 2019. One new function, called cumQdate( ) added EGRET package, designed describe trends timing annual runoff. Examples application Annual Hydrograph Timing.","code":""},{"path":"/articles/Overview.html","id":"describing-water-quality-without-using-the-wrtds-model-","dir":"Articles","previous_headings":"","what":"3. Describing water quality without using the WRTDS model.","title":"EGRET Overview and Update","text":"situations, analyst may want simply display set water quality data without use models modeling assumptions. can useful addition showing results derived WRTDS statistical model. described section 6 Introduction EGRET package well pages 29 -37 EGRET User Guide.","code":""},{"path":"/articles/Overview.html","id":"improved-graphical-treatment-of-censored-data-","dir":"Articles","previous_headings":"3. Describing water quality without using the WRTDS model.","what":"Improved graphical treatment of censored data.","title":"EGRET Overview and Update","text":"enhancement EGRET packages provides additional way graph data censored values data set (typically values reported “less ” laboratory reporting limit). standard way EGRET depicts less-values showing vertical line extends reporting limit value way bottom graph. visually effective way showing data even though honest approach simply representing plotting reporting limit. vertical lines tend draw great amount attention less-values. enhancement now EGRET package called Random Residuals. done take censored value data set randomly select value lies reporting limit zero show various plots open circle (opposed actual measured values, shown closed circle). function accomplishes called makeAugmentedSample( ). random values used computing WRTDS results (trends, mean concentrations fluxes) used graphical representations. valuable visual presentation drawbacks : 1) unique “correct” representation data. Multiple implementations result different random values. 2) graphs data longer free influence statistical model, computation random values depends assumption distribution true value reporting limit, based assumptions fitted WRTDS model. said , recognize purpose many graphs data present general idea data behave (function time discharge) approach provide appropriate impression data. Many graphical functions EGRET argument called randomCensored set TRUE feature implemented.","code":""},{"path":"/articles/Overview.html","id":"making-the-best-possible-estimates-of-concentration-or-flux-for-some-specific-day-month-or-year-","dir":"Articles","previous_headings":"","what":"4. Making the best possible estimates of concentration or flux for some specific day, month, or year.","title":"EGRET Overview and Update","text":"Although primary purpose development WRTDS method EGRET software evaluate long term trends, can also used different purpose: creating best possible estimate conditions specific day, month, season, year. trend analysis (discussed item 5 ) objective remove confounding influence year--year variations discharge order see clearly underlying trend water quality. results WRTDS method used trend analysis purpose “Flow-Normalized” values. considering different kind purpose. , question focused something like: “’s best estimate flux total phosphorus lake month May 2020?” “’s best estimate chloride concentration February 2, 2019?” kinds estimates can use new method called “WRTDS Kalman” WRTDS_K. addition two publications describe concept mathematics. Lee, Hirsch Crawford, 2019 Zhang Hirsch, 2019. WRTDS_K based simple idea. given sampled day, measured concentration almost certainly differ value WRTDS predict. measured value always better value use day WRTDS estimate day. Furthermore, days surrounding day measurement likely values different sampled day. given day, WRTDS_K method uses mixture WRTDS model’s estimated value measured value nearest sampled day prior nearest sampled day given day create optimal estimate day. mathematics method uses auto-regressive, lag-one day, stochastic model make estimates concentration (hence flux) day record. new functions EGRET used process WRTDSKalman( ), plotWRTDSKalman( ), plotTimeSlice( ). EGRETci package also new capabilities estimate uncertainty WRTDS_K estimates. See Graphics Prediction Intervals.","code":""},{"path":"/articles/Overview.html","id":"analysis-of-water-quality-trends-using-wrtds-","dir":"Articles","previous_headings":"","what":"5. Analysis of water quality trends using WRTDS.","title":"EGRET Overview and Update","text":"topic discussed extensively EGRET User Guide (pages 38-78) “WRTDS results” section Introduction EGRET package. descriptions WRTDS flow normalization method built assumption given day year, probability distribution discharge stationary years considered. means assume probability distribution discharge , example, March 5, 1985 probability distribution , example, March 5, 2021. doesn’t mean actually know distribution exactly dates, rather means assume unchanged one year another year. words, willing assume discharge free long-term trend. recognize real world assumption never perfectly correct. know many factors may influencing probability distribution discharge. include example: land-use change (urban development land drainage), groundwater depletion (influencing base flow stream), climate change (influencing precipitation amount type well temperature), changes storage diversion water upstream. probability distribution discharge can also respond quasi-periodic oscillations regional climate causing region experience decadal longer periods persistently dry persistently wet conditions. oscillations can difficult distinguish long-term trends. applications WRTDS 2019 built assumption discharge stationarity. Starting 2019, publication Choquette et al., 2019, different approach considered flow normalization. known Generalized Flow Normalization (GFN) contrast Stationary Flow Normalization (SFN) original assumption.","code":""},{"path":"/articles/Overview.html","id":"a--trends-based-on-stationary-flow-normalization-sfn-","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS.","what":"5a. Trends based on Stationary Flow Normalization (SFN).","title":"EGRET Overview and Update","text":"concepts functions earlier versions EGRET software remain new version . primary function analyses continues modelEstimation( ) functions viewing trend results continue plotConcHist( ), plotFluxHist( ), tableChange( ), tableResulsts( ), plotContours( ), plotDiffContours( ). water quality data set shorter 20 years SFN approach really viable approach. time period short just simply amenable characterizing magnitude nature discharge trend. Also, data sets longer 20 years evaluation discharge record reveal substantial monotonic trend record, Stationary Flow Normalization approach preferred approach. Trends discharge range 10% change period water quality record use SFN. EGRET contains tools can quantify streamflow trends. new functionality added trend analysis added EGRET can provide flexibility undertake Generalized Flow Normalization (addressed section 5b. ) can also enable analyst ask specific questions trend. three new functions following:","code":""},{"path":"/articles/Overview.html","id":"ai--runpairs","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS. > 5a. Trends based on Stationary Flow Normalization (SFN).","what":"5ai. runPairs( )","title":"EGRET Overview and Update","text":"runPairs( ) designed address specific question much flow-normalized concentration flow-normalized flux changed selected starting year selected ending year. exact information can gleaned modelEstimation( ) tableChange( ). advantage runPairs( ) analysis can take significantly less computer time, attempting statistically model years starting ending year. output runPairs( ) can used input runPairsBoot( ) EGRETci package evaluate uncertainty trend.","code":""},{"path":"/articles/Overview.html","id":"aii--rungroups","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS. > 5a. Trends based on Stationary Flow Normalization (SFN).","what":"5aii. runGroups( )","title":"EGRET Overview and Update","text":"concept group analysis wish compare just two different years runPairs( ) rather, compare one group years another group years. example, may strategy nutrient reduction calls decreases average concentrations, average fluxes, period strategy went effect compared time went effect. perhaps want evaluate consequences large investment pollution control went effect fairly abruptly point time want “” analysis. evaluations trends kinds analyses can’t gleaned modelEstimation( ) runPairs( ). See runGroups( ) details function. Also, outputs runGroups( ) can used input runGroupsBoot( ) EGRETci package evaluate uncertainty trend.","code":""},{"path":"/articles/Overview.html","id":"aiii--runseries","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS. > 5a. Trends based on Stationary Flow Normalization (SFN).","what":"5aiii. runSeries( )","title":"EGRET Overview and Update","text":"function produces annual flow-normalized concentrations fluxes entire period analyzed. function produces type output modelEstimation( ). simply options available modelEstimation( ). See runSeries( ) details function. outputs runSeries( ) can used conjunction ciCalculations( ) plotConcHistBoot( ), plotFluxHistBoot( ) EGRETci package show confidence intervals annual flow-normalized values.","code":""},{"path":"/articles/Overview.html","id":"b--trends-based-on-generalized-flow-normalization-gfn","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS.","what":"5b. Trends based on Generalized Flow Normalization (GFN)","title":"EGRET Overview and Update","text":"discussed , GFN designed account role trends discharge analysis trends concentration flux. See GFN approach details implemented. discussion motivations mathematics Choquette, et al. (2019). GFN used, trends reported partitioned two components. One concentration versus discharge trend component (CQTC). discharge trend component (QTC). two components additive, sum total trend. case SFN QTC defined equal zero thus entire trend can considered QCTC. One particular thing note implementing GFN preparing data use analysis valuable make use daily discharge many years period water quality data, extent possible. different data prepared SFN, suggested daily discharge record extend year first water quality sample year last water quality sample. functions used GFN three functions mentioned : runPairs( ), runGroups( ), runSeries( ). functions contains arguments used implement GFN. Uncertainty analysis functions can found EGRETci functions runPairsBoot( ), runGroupsBoot( ), ciCalculations( ).","code":""},{"path":"/articles/Overview.html","id":"c--generalized-flow-normalization-with-a-flow-break-","dir":"Articles","previous_headings":"5. Analysis of water quality trends using WRTDS.","what":"5c. Generalized flow normalization with a flow break.","title":"EGRET Overview and Update","text":"used situation singular engineered action results change probability distribution streamflow particular time. new EGRET code allows us treat discharge stationary within two periods record allows distribution first period different second period. call flow break. obvious examples completion dam upstream monitoring site. needs dam clear impact discharges monitoring site (e.g. decreasing peak discharges high flow /increasing low flows). changes include: removal dam, institution new operating policy dam (e.g. increasing size minimum flows support habitat), major new diversions water watershed. well-defined criteria magnitude change trigger use flow break except say big enough comparisons flow duration curves show easily discernible difference. use technique change can clearly seen data based known human action. Even large dam diversion, affects flows less half watershed area, probably good reason use feature. abrupt change streamflow conditions clear human driver basis using approach. three trend functions mentioned (runPairs( ), runGroups( ), runSeries( ) ) arguments make possible include flow break analysis.","code":""},{"path":"/articles/Overview.html","id":"abrupt-change-in-water-quality-","dir":"Articles","previous_headings":"","what":"6. Abrupt change in water quality.","title":"EGRET Overview and Update","text":"refer wall. idea wall appropriately handle events believe result sharp discontinuity way concentrations behave function discharge, year, season. WRTDS designed working assumption changes concentration-discharge relationship gradual, responding changes behavior many actors watershed. use statistical smoothing time, central WRTDS, predicated idea changes system gradual. gradual changes driven changes population (hence wasteloads), changes land use land use practices many landowners, many changes point source controls implemented many dischargers. know can situations depart assumption gradual change. obvious ones : upgrades single dominant point source discharge, large infrastructure changes storm-water management (e.g. tunnel projects cities significantly curtail combined sewer overflows), construction removal major dam (causing pollutant interest mix large volume water reservoir significantly changing concentration-discharge relationship extreme cases virtually eliminating relationship concentration discharge). another category abrupt change also considered, “reset” river conditions may result extreme flood extreme drought. hypothesis behavior water quality changed result extreme event change short-term thing (.e. duration event) rather something persists number years. new “wall” concept can provide effective way perform hypothesis test event question brought lasting change, approach allows us describe nature change took place. Conceptually approach simple, analyst specifies date change takes place, smoothing process involved estimating WRTDS model places “wall” specific time. means estimates concentration time, discharge season, lies prior time wall, estimated data collected wall. Conversely estimates wall based data collected wall. result process contour surface seen plotContours( ) can sharp break vertical line wall located. idea using way testing specific action brought statistically significant change water quality can accomplished using runGroups( ) function letting two groups distinguished either wall. confidence level uncertainty difference can determined using runGroupsBoot( ) EGRETci package. wall can also implemented runPairs( ) runSeries( ) functions well.","code":""},{"path":"/articles/Overview.html","id":"seasonal-analysis-of-trends","dir":"Articles","previous_headings":"","what":"7. Seasonal analysis of trends","title":"EGRET Overview and Update","text":"Sometimes interest understand may trends water quality seasons seasons, even trends opposite directions different seasons. scripts can used evaluate water quality trends different seasons show graph months displaying seasonal pattern fluxes month change several years monthly fluxes.","code":""},{"path":"/articles/Overview.html","id":"parallel-computing","dir":"Articles","previous_headings":"","what":"8. Parallel computing","title":"EGRET Overview and Update","text":"EGRET can computationally intensive, EGRETci even intensive, set techniques provided run EGRET processes parallel thus greatly compress amount time required complete large analysis covers many sites many analytes. EGRET EGRETci allow parallel computing. techniques can executed single computer several cores, can executed across large array connected computers.","code":""},{"path":"/articles/Overview.html","id":"errorstats-to-describe-the-overall-accuracy-of-a-wrtds-model","dir":"Articles","previous_headings":"","what":"9. errorStats( ) to describe the overall accuracy of a WRTDS model","title":"EGRET Overview and Update","text":"Sometimes useful statistics describe magnitude errors WRTDS model, way multiple linear regression. function called errorStats( ) added EGRET package. computes equivalent R-squared value (like multiple regression). R-squared computed log concentration well log flux. also provides root mean squared error standard error prediction percent. can provide useful tool comparison similar water quality statistical models, comparing different settings three window parameters WRTDS model (windowY, windowS, windowQ).","code":""},{"path":"/articles/Overview.html","id":"dealing-with-problems-of-model-convergence","dir":"Articles","previous_headings":"","what":"10. Dealing with problems of model convergence","title":"EGRET Overview and Update","text":"rare occasions WRTDS estimation process fails converge numerically, results highly unreasonable results (e.g. estimated concentrations far beyond limits observed record). problems rare EGRET, can little common EGRETci, odd properties bootstrap samples can . fix rare cases developed EGRET package, also used EGRETci package. problems sometimes related multicollinearity Sample data, idea add “jitter” (small amounts random noise) time discharge data. often solves numerical problems. used clear problem results. function used called jitterSam( ). use primarily functions EGRETci package.","code":""},{"path":"/articles/Overview.html","id":"alternative-discharge-variables-in-the-wrtds-model","dir":"Articles","previous_headings":"","what":"11. Alternative discharge variables in the WRTDS model","title":"EGRET Overview and Update","text":"Sometimes usual formulation WRTDS ideal believe daily discharge sampling day good explanatory variable idea better variable might use. Dams reservoirs create situations may issue. may turn better explanatory variable model WRTDS model might rolling-mean discharges period many days (including) sampled day instead daily discharge sampling day. article describing concept script making analysis using alternative Q variable.","code":""},{"path":"/articles/Overview.html","id":"enhancements-of-egretci","dir":"Articles","previous_headings":"","what":"Enhancements of EGRETci","title":"EGRET Overview and Update","text":"mentioned EGRETci R package, closely related EGRET. runs variety analyses can provide information uncertainty trend results run EGRET. outputs include p-values can used hypothesis tests, confidence intervals magnitude annual flow-normalized values, also likelihood measures can provide indication confident sign estimated change actually correct sign (e.g. estimate trend said upward, ’s chance might actually downward?). techniques, evaluating trend results described detail Guide EGRETci 2.0 enhancements. addition, now set functions EGRETci allow one quantify uncertainty individual values (flow-normalized) average concentration average flux. ’s example results might used. colleague deterministic model particular lake predicts summertime chlorophyl concentration based nutrient input recent months well air temperature, sunlight, precipitation variables relevant processes involved. colleague asks estimates actual time series N P inputs lake monthly time step period several years. provide colleague time series WRTDSKalman estimates flux months. say “Thanks, can quantify uncertainty values. Can place confidence intervals around values. 90% confidence interval order +/- 5%, like 20% even worse 50%?” techniques designed provide answers kinds questions. designed calculate prediction intervals daily, monthly, annual averages concentration flux. methods described detail Graphics Prediction Intervals. also provide means graphically depict proability concentration values exceeding regulatory threshold value.","code":""},{"path":"/articles/References_WRTDS.html","id":"wrtds-references","dir":"Articles","previous_headings":"","what":"WRTDS References","title":"WRTDS Bibliography","text":"bibliography published works develop use Weighted Regressions Time, Discharge, Season (WRTDS). current April 1, 2020. includes papers scientific journals government agency reports theses dissertations published drafts government reports. publications included develop use WRTDS. Publications reference WRTDS-related papers, don’t use method included. bibliography organized three sections: WRTDS Method: papers define explain aspects WRTDS methods written members team developed method related EGRET R-package (Exploration Graphics RivEr Trends). cover 10-year period (2010-2019) development enhancements method. methods described included either EGRET EGRETci packages additional R scripts can found “Articles” menu EGRET home page (https://rconnect.usgs.gov/EGRET/). Extending Evaluating WRTDS: papers extensions made basic WRTDS methods bring types information provide types outputs. list also includes papers make comparisons WRTDS statistical methods commonly used river water quality data. Regional Studies Using WRTDS: papers apply WRTDS evaluation conditions collection monitoring sites. cases just single sites based group sites covering region even entire United States.","code":""},{"path":"/articles/References_WRTDS.html","id":"the-wrtds-method","dir":"Articles","previous_headings":"WRTDS References","what":"The WRTDS Method","title":"WRTDS Bibliography","text":"Choquette, Anne F, Robert M Hirsch, Jennifer C Murphy, LT Johnson, RB Confesor Jr. 2019. “Tracking Changes Nutrient Delivery Western Lake Erie: Approaches Compensate Variability Trends Streamflow.” Journal Great Lakes Research 45 (1): 21–39. Hirsch, Robert M, Stacey Archfield, Laura De Cicco. 2015. “Bootstrap Method Estimating Uncertainty Water Quality Trends.” Environmental Modelling & Software 73: 148–66. Hirsch, Robert M, Laura De Cicco. 2015. “User Guide Exploration Graphics RivEr Trends (EGRET) dataRetrieval: R Packages Hydrologic Data.” US Geological Survey, Techniques Methods, . 4-A10, 93 p. Hirsch, Robert M., Douglas L. Moyer, Stacey . Archfield. 2010. “Weighted Regressions Time, Discharge, Season (WRTDS), Application Chesapeake Bay River Inputs1.” JAWRA Journal American Water Resources Association 46 (5): 857–80. Sprague, Lori ., Robert M. Hirsch, Brent T. Aulenbach. 2011. “Nitrate Mississippi River Tributaries, 1980 2008: Making Progress?” Environmental Science & Technology 45 (17): 7209–16. Zhang, Qian, Robert M. Hirsch. 2019. “River water‐quality concentration flux estimation can improved accounting serial correlation autoregressive model.” Water Resources Research 55, . 11: 9705-9723.","code":""},{"path":"/articles/References_WRTDS.html","id":"extending-and-evaluating-wrtds","dir":"Articles","previous_headings":"WRTDS References","what":"Extending and Evaluating WRTDS","title":"WRTDS Bibliography","text":"Appling, Alison P, Miguel C Leon, William H McDowell. 2015. “Reducing Bias Quantifying Uncertainty Watershed Flux Estimates: R Package Loadflex.” Ecosphere 6 (12): 1–25. Ator, Scott W., Ana Maria García, Gregory E. Schwarz, Joel D. Blomquist, Andrew J. Sekellick. 2019. “Toward explaining nitrogen phosphorus trends Chesapeake Bay tributaries, 1992–2012.” JAWRA Journal American Water Resources Association 55, . 5: 1149-1168. Beck, Marcus W, James D Hagy. 2015. “Adaptation Weighted Regression Approach Evaluate Water Quality Trends Estuary.” Environmental Modeling & Assessment 20 (6): 637–55. Beck, Marcus W, James D Hagy, Michael C Murrell. 2015. “Improving Estimates Ecosystem Metabolism Reducing Effects Tidal Advection Dissolved Oxygen Time Series.” Limnology Oceanography: Methods 13 (12): 731–45. Beck, Marcus W, Rebecca R Murphy. 2017. “Numerical Qualitative Contrasts Two Statistical Models Water Quality Change Tidal Waters.” JAWRA Journal American Water Resources Association 53 (1): 197–219. Chanat, Jeffrey G, Douglas L Moyer, Joel D Blomquist, Kenneth E Hyer, Michael J Langland. 2016. “Application Weighted Regression Model Reporting Nutrient Sediment Concentrations, Fluxes, Trends Concentration Flux Chesapeake Bay Nontidal Water-Quality Monitoring Network, Results Water Year 2012.” US Geological Survey Scientific Investigations Report 2015-5133, 74 p.. Chanat, Jeffrey G, Guoxiang Yang. 2018. “Exploring Drivers Regional Water‐Quality Change Using Differential Spatially Referenced Regression—Pilot Study Chesapeake Bay Watershed.” Water Resources Research 54 (10): 8120–45. Fanelli, Rosemary M, Joel D Blomquist, Robert M Hirsch. 2019. “Point Sources Agricultural Practices Control Spatial-Temporal Patterns Orthophosphate Tributaries Chesapeake Bay.” Science Total Environment 652: 422–33. Hirsch, Robert M. 2014. “Large Biases Regression‐based Constituent Flux Estimates: Causes Diagnostic Tools.” JAWRA Journal American Water Resources Association 50 (6): 1401–24. Kandel, Rajesh. 2018. “Comparative Analysis Nitrate Load Estimation Techniques Watersheds Different Land-Use Characteristics.” Kandel, Rajesh, Rabin Bhattarai. 2018. “Comparison Various Estimation Techniques Predict Nitrate Load Maumee River.” , 1. American Society Agricultural; Biological Engineers. Kumar, Saurav, Adil Godrej, Harold Post, Karl Berger. “Value Intensive Sampling—Comparison Fluvial Loads.” 2019. Water Resources Management 33, . 12: 4303-4318. Lee, Casey J, Robert M Hirsch, Gregory E Schwarz, David J Holtschlag, Stephen D Preston, Charles G Crawford, Aldo V Vecchia. 2016. “Evaluation Methods Estimating Decadal Stream Loads.” Journal Hydrology 542: 185–203. Libera, Dominic , Sankarasubramanian, Ashish Sharma, Brian J Reich. 2018. “Non-Parametric Bootstrapping Framework Embedded Toolkit Assessing Water Quality Model Performance.” Environmental Modelling & Software 107: 25–33. Maestre, Alexander, Derek Williamson, Eman El-Sheikh, Amelia Ward. 2014. “Machine Learning Tool Weighted Regressions Time, Discharge, Season.” Inter J Adv Comp Sci App 5 (3): 99–106. Markus, Momcilo, Misganaw Demissie, Matthew B Short, Siddhartha Verma, Richard Cooke. 2013. “Sensitivity Analysis Annual Nitrate Loads Corresponding Trends Lower Illinois River.” Journal Hydrologic Engineering 19 (3): 533–43. Murphy, Jennifer C, Robert M Hirsch, Lori Sprague. 2014. “Antecedent Flow Conditions Nitrate Concentrations Mississippi River Basin.” Hydrology Earth System Sciences 18 (3): 967–79. Murphy, Jennifer, Lori Sprague. 2019. “Water-Quality Trends US Rivers: Exploring Effects Streamflow Trends Changes Watershed Management.” Science Total Environment 656: 645–58. Parr, Thomas B., Shreeram P. Inamdar, Matthew J. Miller. 2019. “Overlapping Anthropogenic Effects Hydrologic Seasonal Trends DOC Surface Water Dependent Water Utility.” Water Research 148: 407–15. Reisinger, Alexander J, Ellen Woytowitz, Emily Majcher, Emma J Rosi, Kenneth T Belt, Jonathan M Duncan, Sujay S Kaushal, Peter M Groffman. 2019. “Changes Long‐term Water Quality Baltimore Streams Associated Gray Green Infrastructure.” Limnology Oceanography 64 (S1): S60–S76. Scavia, Donald, Serghei . Bocaniov, Awoke Dagnew, Colleen Long, Yu-Chen Wang. 2019. “St. Clair-Detroit River system: Phosphorus mass balance implications Lake Erie load reduction, monitoring, climate change.” Journal Great Lakes Research 45, . 1: 40-49. Strickling, HL, DR Obenour. 2018. “Leveraging Spatial Temporal Variability Probabilistically Characterize Nutrient Sources Export Rates Developing Watershed.” Water Resources Research 54 (7): 5143–62. Warrick, Jonathan . 2015. “Trend Analyses River Sediment Rating Curves.” Hydrological Processes 29 (6): 936–49. Zhang, Qian. 2018. “Synthesis Nutrient Sediment Export Patterns Chesapeake Bay Watershed: Complex Non-Stationary Concentration-Discharge Relationships.” Science Total Environment 618: 1268–83. Zhang, Qian, William P Ball. 2017. “Improving Riverine Constituent Concentration Flux Estimation Accounting Antecedent Discharge Conditions.” Journal Hydrology 547: 387–402. Zhang, Qian, Damian C Brady, Walter R Boynton, William P Ball. 2015. “Long‐Term Trends Nutrients Sediment Nontidal Chesapeake Watershed: Assessment Progress River Season.” JAWRA Journal American Water Resources Association 51 (6): 1534–55. Zhang, Qian, Ciaran J Harman, William P Ball. 2016. “Improved Method Interpretation Riverine Concentration‐discharge Relationships Indicates Long‐term Shifts Reservoir Sediment Trapping.” Geophysical Research Letters 43 (19): 10–215. Zhang, Qian, Ciaran J Harman, James W Kirchner. 2018. “Evaluation Statistical Methods Quantifying Fractal Scaling Water-Quality Time Series Irregular Sampling.” Hydrology Earth System Sciences 22 (2): 1175–92.","code":""},{"path":"/articles/References_WRTDS.html","id":"regional-studies-using-wrtds","dir":"Articles","previous_headings":"WRTDS References","what":"Regional Studies Using WRTDS","title":"WRTDS Bibliography","text":"Abbott, Benjamin W, Gérard Gruau, Jay P Zarnetske, Florentina Moatar, Lou Barbe, Zahra Thomas, Ophélie Fovet, Tamara Kolbe, Sen Gu, Anne‐Catherine Pierson‐Wickmann. 2018. “Unexpected Spatial Stability Water Chemistry Headwater Stream Networks.” Ecology Letters 21 (2): 296–308. Ator, Scott W, Judith M Denver. 2015. Understanding Nutrients Chesapeake Bay Watershed Implications Management Restoration: Eastern Shore. US Geological Survey Circular 1406, 72 p. Beck, Marcus W, Thomas W Jabusch, Philip R Trowbridge, David B Senn. 2018. “Four Decades Water Quality Change Upper San Francisco Estuary.” Estuarine, Coastal Shelf Science 212: 11–22. Ballard, Tristan C., Eva Sinha, Anna M. Michalak. 2019. “Long-term changes precipitation temperature already impacted nitrogen loading.” Environmental science & technology 53, . 9: 5080-5090. Bettez, Neil D., Jonathan M. Duncan, Peter M. Groffman, Lawrence E. Band, Jarlath O’Neil-Dunne, Sujay S. Kaushal, Kenneth T. Belt, Neely Law. 2015. “Climate variation overwhelms efforts reduce nitrogen delivery coastal waters.” Ecosystems 18, . 8: 1319-1331. Bird, Darcy L, Peter M Groffman, Christopher J Salice, Joel Moore. 2018. “Steady-State Land Cover Non-Steady-State Major Ion Chemistry Urban Streams.” Environmental Science & Technology 52 (22): 13015–26. Bowen, Zachary H, Gretchen P Oelsner, Brian S Cade, Tanya J Gallegos, Aida M Farag, David N Mott, Christopher J Potter, Peter J Cinotto, Melanie L Clark, William M Kappel. 2015. “Assessment Surface Water Chloride Conductivity Trends Areas Unconventional Oil Gas Development—Existing National Data Sets Tell Us Like Know.” Water Resources Research 51 (1): 704–15. Corsi, Steven R, Laura De Cicco, Michelle Lutz, Robert M Hirsch. 2015. “River Chloride Trends Snow-Affected Urban Watersheds: Increasing Concentrations Outpace Urban Growth Rate Common Among Seasons.” Science Total Environment 508: 488–97. Cosh, M. H., D. D. Bosch, . Coffin, T. J. Jackson, . Colliander, S. Chan, R. Bindlish, W. Crow, S. Yueh. 2019. “SOIL MOISTURE SCALING FUNCTION DEVELOPMENT LITTLE RIVER EXPERIMENTAL WATERSHED.” Working Watersheds Coastal Systems: Research Management: 91. Crawford, John T., Edward G. Stets, Lori . Sprague. 2019. “Network Controls Mean Variance Nitrate Loads Mississippi River Gulf Mexico.” Journal Environmental Quality 48, . 6: 1789-1799. Crawford, John T., Eve-Lyn S. Hinckley, M. Iggy Litaor, Janice Brahney, Jason C. Neff. 2019. “Evidence accelerated weathering sulfate export high alpine environments.” Environmental Research Letters 14, . 12: 124092. Deemer, Bridget R., Edward G. Stets, Charles B. Yackulic. 2020. “Calcite precipitation Lake Powell reduces alkalinity total salt loading Lower Colorado River Basin.” Limnology Oceanography. Duncan, Jonathan M, Lawrence E Band, Peter M Groffman, Emily S Bernhardt. 2015. “Mechanisms Driving Seasonality Catchment Scale Nitrate Export: Evidence Riparian Ecohydrologic Controls.” Water Resources Research 51 (6): 3982–97. Ehrhardt, Sophie, Rohini Kumar, Jan H. Fleckenstein, Sabine Attinger, Andreas Musolff. 2019. “Trajectories nitrate input output three nested catchments along land use gradient.” Hydrology & Earth System Sciences 23, . 9. Eshleman, Keith N, Robert D Sabo, Kathleen M Kline. 2013. “Surface Water Quality Improving Due Declining Atmospheric N Deposition.” Environmental Science & Technology 47 (21): 12193–12200. Fanelli, Rosemary M., Joel D. Blomquist, Robert M. Hirsch. 2019. “Point sources agricultural practices control spatial-temporal patterns orthophosphate tributaries Chesapeake Bay.” Science Total Environment 652: 422-433. Getahun, Elias, Laura Keefer, Sangeetha Chandrasekaran, Atticus Zavelle. 2019. “Water Quality Trend Analysis Fox River Watershed: Stratton Dam Illinois River.” Illinois State Water Survey CR 2019-04. Gloege, Lucas, Galen . McKinley, Robert J. Mooney, J. David Allan, Matthew W. Diebel, Peter B. McIntyre. 2020. “Lake hydrodynamics intensify potential impact watershed pollutants coastal ecosystem services.” Environmental Research Letters. Green, Christopher T, Barbara Bekins, Stephen J Kalkhoff, Robert M Hirsch, Lixia Liao, Kimberlee K Barnes. 2014. “Decadal Surface Water Quality Trends Variable Climate, Land Use, Hydrogeochemical Setting Iowa, USA.” Water Resources Research 50 (3): 2425–43. Gurbisz, Cassie, W. Michael Kemp. 2014. “Unexpected resurgence large submersed plant bed Chesapeake Bay: Analysis time series data.” Limnology Oceanography 59, . 2: 482-494. Ha, Di, Hengchen Wei, Qian Zhang, William P Ball. n.d. “Nitrogen Source Input Non-Tidal Chesapeake Bay Watershed Output Major Rivers: Evaluation Changes Based Long-Term Data.” Hickman, R. Edward, Robert M. Hirsch. 2017. “Trends Quality Water New Jersey Streams, Water Years 1971–2011: US Geological Survey Scientific Investigations Report 2016-5176.” Hirsch, Robert M. 2012. Flux Nitrogen, Phosphorus, Suspended Sediment Susquehanna River Basin Chesapeake Bay Tropical Storm Lee, September 2011, Indicator Effects Reservoir Sedimentation Water Quality. US Geological Survey Scientific Investigations Report, 2012-5185, 17 p. Ilampooranan, Idhayachandhiran, Kimberly J. Van Meter, Nandita B. Basu. 2019. “race time: modeling time lags watershed response.” Water Resources Research 55, . 5: 3941-3959. Isles, Peter DF, Courtney D. Giles, Trevor . Gearhart, Yaoyang Xu, Greg K. Druschel, Andrew W. Schroth. 2015. “Dynamic internal drivers historically severe cyanobacteria bloom Lake Champlain revealed comprehensive monitoring.” Journal Great Lakes Research 41, . 3: 818-829. Kalkhoff, Stephen J, Laura E Hubbard, Mark D Tomer, DE James. 2016. “Effect Variable Annual Precipitation Nutrient Input Nitrogen Phosphorus Transport Two Midwestern Agricultural Watersheds.” Science Total Environment 559: 53–62. Kelly, Valerie, Edward G. Stets, Charles G. Crawford. 2015. “Long-Term Changes Nitrate Conditions 20th Century Two Midwestern Corn Belt Streams.” Journal Hydrology 525: 559–71. Kleinman, Peter JA, Rosemary M. Fanelli, Robert M. Hirsch, Anthony R. Buda, Zachary M. Easton, Lisa . Wainger, Chris Brosch, Martin Lowenfish, Amy S. Collick, Adel Shirmohammadi, Kathy Boomer, Jason . Hubbart, Ray B. Bryant, Gary W. Shenk. 2019. “Phosphorus Chesapeake Bay: Lingering issues emerging concerns agriculture.” Journal environmental quality 48, . 5: 1191-1203. Kreiling, Rebecca M, Jeffrey N Houser. 2016. “Long-Term Decreases Phosphorus Suspended Solids, Nitrogen, Six Upper Mississippi River Tributaries, 1991–2014.” Environmental Monitoring Assessment 188 (8): 454. Medalie, Laura. 2013. Concentration, Flux, Analysis Trends Total Dissolved Phosphorus, Total Nitrogen, Chloride 18 Tributaries Lake Champlain, Vermont New York, 1990-2011. US Geological Survey Scientific Investigations Report 2013-502, 29 p. Medalie, Laura, Robert M. Hirsch, Stacey . Archfield. 2012. “Use Flow-Normalization Evaluate Nutrient Concentration Flux Changes Lake Champlain Tributaries, 1990–2009.” Lake Champlain 2010 38, Supplement 1 (0): 58–67. Mize, Scott V, Jennifer C Murphy, Timothy H Diehl, Dennis K Demcheck. 2018. “Suspended-Sediment Concentrations Loads Lower Mississippi Atchafalaya Rivers Decreased Half 1980 2015.” Journal Hydrology 564: 1–11. Moatar, Florentina, Benjamin W Abbott, Camille Minaudo, Florence Curie, Gilles Pinay. 2017. “Elemental Properties, Hydrology, Biology Interact Shape Concentration‐discharge Curves Carbon, Nutrients, Sediment, Major Ions.” Water Resources Research 53 (2): 1270–87. Morway, Eric D, Carl E Thodal, Mark Marvin-DiPasquale. 2017. “Long-Term Trends Surface-Water Mercury Methylmercury Concentrations Downstream Historic Mining Within Carson River Watershed.” Environmental Pollution 229: 1006–18. Mullaney, John R. 2016. “Nutrient, Organic Carbon, Chloride Concentrations Loads Selected Long Island Sound Tributaries—Four Decades Change Following Passage Federal Clean Water Act.”. US Geological Survey Scientific Investigations Report 2015-5189, 47 p. Murphy, Jennifer C., Robert M Hirsch, Lori . Sprague. 2013. Nitrate Mississippi River Tributaries, 1980-2010: Update. US Geological Survey, Scientific Investigations Report 2013-5169, 31 p. Murphy, Jennifer C., Lori . Sprague. 2019. “Water-quality trends US rivers: Exploring effects streamflow trends changes watershed management.” Science Total Environment 656: 645-658. Murphy, Jennifer C. 2019. “Declining suspended sediment United States rivers streams: Linking sediment trends changes land use/cover, hydrology climate.” Hydrology Earth System Sciences Discussions: 1-37. Najjar, Raymond G., Maria Herrmann, Sebastián M. Cintrón Del Valle, Jaclyn R. Friedman, Marjorie Friedrichs, Lora . Harris, Elizabeth H. Shadwick, Edward G. Stets, Ryan J. Woodland. 2020. “Alkalinity Tidal Tributaries Chesapeake Bay.” Journal Geophysical Research: Oceans 125, . 1: e2019JC015597. National Research Council. 2011. Achieving Nutrient Sediment Reduction Goals Chesapeake Bay: Evaluation Program Strategies Implementation. National Academies Press. Oelsner, Gretchen P, Lori Sprague, Jennifer C Murphy, Robert E Zuellig, Henry M Johnson, Karen R Ryberg, James Falcone, Edward G Stets, Aldo V Vecchia, Melissa L Riskin. 2017. “Water-Quality Trends Nation’s Rivers Streams, 1972–2012—Data Preparation, Statistical Methods, Trend Results”, US Geological Survey Scientific Investigations Report 2017-5006, 136 p. Oelsner, Gretchen P, Edward G Stets. 2019. “Recent Trends Nutrient Sediment Loading Coastal Areas Conterminous US: Insights Global Context.” Science Total Environment 654: 1225–40. Paerl, Hans W., Joseph R. Crosswell, Bryce Van Dam, Nathan S. Hall, Karen L. Rossignol, Christopher L. Osburn, Alexandria G. Hounshell, Randolph S. Sloup, Lawrence W. Harding. 2018. “Two decades tropical cyclone impacts North Carolina’s estuarine carbon, nutrient phytoplankton dynamics: implications biogeochemical cycling water quality stormier world.” Biogeochemistry 141, . 3: 307-332. Paerl, Hans W., Nathan S. Hall, Alexandria G. Hounshell, Richard . Luettich, Karen L. Rossignol, Christopher L. Osburn, Jerad Bales. “Recent increase catastrophic tropical cyclone flooding coastal North Carolina, USA: Long-term observations suggest regime shift.” 2019. Scientific reports 9, . 1: 1-9. Parr, Thomas B., Shreeram P. Inamdar, Matthew J. Miller. 2019. “Overlapping anthropogenic effects hydrologic seasonal trends DOC surface water dependent water utility.” Water research 148: 407-415. Pellerin, Brian ., Brian . Bergamaschi, Robert J. Gilliom, Charles G. Crawford, JohnFranco Saraceno, C. Paul Frederick, Bryan D. Downing, Jennifer C. Murphy. 2014. “Mississippi River nitrate loads high frequency sensor measurements regression-based load estimation.” Environmental science & technology 48, . 21: 12612-12619. Rankinen, K., G. Gao, K. Granlund, J. Grönroos, L. Vesikko. 2015. “Comparison impacts human activities climate change water quantity quality Finnish agricultural catchments.” Landscape ecology 30, . 3: 415-428. Rankinen, Katri, Hanna Keinänen, José Enrique Cano Bernal. 2016. “Influence climate land use changes nutrient fluxes Finnish rivers Baltic Sea.” Agriculture, Ecosystems & Environment 216: 100-115. Rosenberg, Braden D, Andrew W Schroth. 2017. “Coupling Reactive Riverine Phosphorus Iron Species Hot Transport Moments: Impacts Land Cover Seasonality.” Biogeochemistry 132 (1-2): 103–22. Rumsey, Christine , Matthew P Miller, Gregory E Schwarz, Robert M Hirsch, David D Susong. 2017. “Role Baseflow Dissolved Solids Delivery Streams Upper Colorado River Basin.” Hydrological Processes 31 (26): 4705–18. Ryberg, Karen R. 2017. “Structural Equation Model Total Phosphorus Loads Red River North Basin, USA Canada.” Journal Environmental Quality 46 (5): 1072–80. Ryberg, Karen R, F Adnan Akyüz, Wei Lin. 2006. “Changes Total Phosphorus Concentration Red River North Basin, 1970-2012.” , 1. American Society Agricultural; Biological Engineers. Ryberg, Karen R, Joel D Blomquist, Lori Sprague, Andrew J Sekellick, Jennifer Keisman. 2018. “Modeling Drivers Phosphorus Loads Chesapeake Bay Tributaries Inferences Long-Term Change.” Science Total Environment 616: 1423–30. Sanford, Ward E, Jason P Pope. 2013. “Quantifying Groundwater’s Role Delaying Improvements Chesapeake Bay Water Quality.” Environmental Science & Technology 47 (23): 13330–8. Savoie, Jennifer G, John R Mullaney, Gardner C Bent. 2017. Analysis Trends Water Quality Streamflow Blackstone, Branch, Pawtuxet, Pawcatuck Rivers, Massachusetts Rhode Island, 1979 2015. US Geological Survey Scientific Investigations Report 2016-5178, 43 p.. Scavia, Donald, Serghei Bocaniov, Awoke Dagnew, Colleen Long, Yu-Chen Wang. 2019. “St. Clair-Detroit River System: Phosphorus Mass Balance Implications Lake Erie Load Reduction, Monitoring, Climate Change.” Journal Great Lakes Research 45 (1): 40–49. Schilling, KE, CS Jones, CF Wolter, X Liang, Y-K Zhang, Seeman, T Isenhart, D Schnoebelen, M Skopec. 2017. “Variability Nitrate-Nitrogen Load Estimation Results Make Quantifying Load Reduction Strategies Difficult Iowa.” Journal Soil Water Conservation 72 (4): 317–25. Schramm, Michael, Tyson Broad, Tom Arsuffi. 2018. “Escherichia Coli Dissolved Oxygen Trends Upper Llano River Watershed, Texas (2001-2016).” Shoda, Megan E, Lori Sprague, Jennifer C Murphy, Melissa L Riskin. 2019. “Water-Quality Trends US Rivers, 2002 2012: Relations Levels Concern.” Science Total Environment 650: 2314–24. Sinha, Eva, Anna M. Michalak. 2016. “Precipitation dominates interannual variability riverine nitrogen loading across continental United States.” Environmental science & technology 50, . 23: 12874-12884. Smith, AJ, BT Duffy, Onion, DL Heitzman, JL Lojpersberger, EA Mosher, MA Novak. 2018. “Long‐term Trends Biological Indicators Water Quality Rivers Streams N Ew Y Ork S Tate (1972–2012).” River Research Applications 34 (5): 442–50. Sprague, Lori ., Robert M. Hirsch, Brent T. Aulenbach. 2011. “Nitrate Mississippi River Tributaries, 1980 2008: Making Progress?” Environmental Science & Technology 45 (17): 7209–16. https://doi.org/10.1021/es201221s. Sprague, Lori ., Richard M. Mitchell, Amina . Pollard, James . Falcone. 2019. “Assessing water-quality changes US rivers multiple geographic scales using results probabilistic targeted monitoring.” Environmental monitoring assessment 191, . 6: 348. Stackpoole, Sarah M, Edward G Stets, David W Clow, Douglas Burns, George R Aiken, Brent T Aulenbach, Irena F Creed, Robert M Hirsch, Hjalmar Laudon, Brian Pellerin. 2017. “Spatial Temporal Patterns Dissolved Organic Matter Quantity Quality Mississippi River Basin, 1997–2013.” Hydrological Processes 31 (4): 902–15. Stackpoole, Sarah M., Edward G. Stets, Lori . Sprague. 2019. “Variable impacts contemporary versus legacy agricultural phosphorus US river water quality.” Proceedings National Academy Sciences 116, . 41: 20562-20567. Stelzer, Robert S., Thomas B. Parr, Mamadou Coulibaly. 2020. “ten year record nitrate retention solute trends Wisconsin sand plains stream: temporal variation multiple scales.” Biogeochemistry 147, . 2: 125-147. Stets, Edward G., Lori . Sprague, Gretchen P. Oelsner, Hank M. Johnson, Jennifer C. Murphy, Karen Ryberg, Aldo V. Vecchia, Robert E. Zuellig, James . Falcone, Melissa L. Riskin. “Landscape Drivers Dynamic Change Water Quality US Rivers.” 2020. Environmental Science & Technology. Stets, Edward G, Casey J Lee, Darren Lytle, Michael R Schock. 2018. “Increasing Chloride Rivers Conterminous US Linkages Potential Corrosivity Lead Action Level Exceedances Drinking Water.” Science Total Environment 613: 1498–1509. Testa, Jeremy M, Rebecca R Murphy, Damian C Brady, William M Kemp. 2018. “Nutrient-Climate-Induced Shifts Phenology Linked Biogeochemical Cycles Temperate Estuary.” Frontiers Marine Science 5: 114. Testa, Jeremy M., Vyacheslav Lyubchich, Qian Zhang. 2019. “Patterns Trends Secchi Disk Depth Three Decades Chesapeake Bay Estuarine Complex.” Estuaries Coasts 42, . 4: 927-943. Van Meter, KJ, NB Basu, Philippe Van Cappellen. 2017. “Two Centuries Nitrogen Dynamics: Legacy Sources Sinks Mississippi Susquehanna River Basins.” Global Biogeochemical Cycles 31 (1): 2–23. Van Meter, Kim J., N. B. Basu. 2017. “Time lags watershed-scale nutrient transport: exploration dominant controls.” Environmental Research Letters 12, . 8: 084017. Van Meter, Kim J., Shadman Chowdhury, Danyka K. Byrnes, Nandita B. Basu. 2019. “Biogeochemical asynchrony: Ecosystem drivers seasonal concentration regimes across Great Lakes Basin.” Limnology Oceanography. Verma, Siddhartha, Alena Bartosova, Momcilo Markus, Richard Cooke, Myoung-Jin Um, Daeryong Park. 2018. “Quantifying Role Large Floods Riverine Nutrient Loadings Using Linear Regression Analysis Covariance.” Sustainability 10 (8): 2876. Vidon, Philippe, Diana L Karwan, Scott Andres, Shreeram Inamdar, Sujay Kaushal, Jonathan Morrison, John Mullaney, Donald S Ross, Andrew W Schroth, James B Shanley. 2018. “Path Hurricane: Impact Hurricane Irene Tropical Storm Lee Watershed Hydrology Biogeochemistry North Carolina Maine, USA.” Biogeochemistry 141 (3): 351–64. Vrzel, Janja, Nives Ogrinc. 2015. “Nutrient Variations Sava River Basin.” Journal Soils Sediments 15 (12): 2380–6. Wilkison, Donald H, Daniel J Armstrong. 2016. “Water‐Quality Assessment Lower Grand River Basin, Missouri Iowa, USA, Support Integrated Conservation Practices.” River Research Applications 32 (4): 583–96. Zhang, Q., D.C. Brady, W.P. Ball. 2013. “Long-Term Seasonal Trends Nitrogen, Phosphorus, Suspended Sediment Load Non-Tidal Susquehanna River Basin Chesapeake Bay.” Science Total Environment 452–453 (0): 208–21. https://doi.org/10.1016/j.scitotenv.2013.02.012. Zhang, Qian, William P Ball, Douglas L Moyer. 2016. “Decadal-Scale Export Nitrogen, Phosphorus, Sediment Susquehanna River Basin, USA: Analysis Synthesis Temporal Spatial Patterns.” Science Total Environment 563: 1016–29. Zhang, Qian, Joel D Blomquist. 2018. “Watershed Export Fine Sediment, Organic Carbon, Chlorophyll-Chesapeake Bay: Spatial Temporal Patterns 1984–2016.” Science Total Environment 619: 1066–78. Zhang, Qian, Damian C Brady, Walter R Boynton, William P Ball. 2015a. “Long‐Term Trends Nutrients Sediment Nontidal Chesapeake Watershed: Assessment Progress River Season.” JAWRA Journal American Water Resources Association 51 (6): 1534–55. Zhang, Qian, Robert M Hirsch, William P Ball. 2016. “Long-Term Changes Sediment Nutrient Delivery Conowingo Dam Chesapeake Bay: Effects Reservoir Sedimentation.” Environmental Science & Technology 50 (4): 1877–86.","code":""},{"path":"/articles/SeasonalFraction.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Seasonal Analysis in EGRET","text":"document describes obtain seasonal information R package EGRET. example, might want know fraction load takes place winter season (say December, January, February). can look seasonal information single year, averages several years, terms flow normalized fluxes.","code":""},{"path":"/articles/SeasonalFraction.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Seasonal Analysis in EGRET","text":"First, need installed loaded EGRET package. , ’ll need need create eList object. See EGRET vignette user guide information use water quality data EGRET. eList object created, run modelEstimation function create WRTDS model. post, use Choptank River, measuring Inorganic nitrogen (nitrate nitrite) example. start lets look results calculated complete water years. Looking last column results see , example, flow normalized flux water year 2010 estimated 0.149 106 kg/year. Now, let’s say particular interest winter season define months December, January, February. next step establish season interested looking . functions EGRET can done “water year” (Oct-Sept), calendar year (Jan-Dec), set sequential months. define period analysis (PA) use, function setPA. setPA function two arguments: paStart number calendar month start season. paLong length season months (can number 1 12). example let’s say want consider winter, defined December February, starting month (paStart) 12, length (paLong) 3: Now lets view results focusing winter season. Note now estimated flow normalized flux 0.215 106 kg/year. Let’s take moment think relation previous result. saying flux (mass per unit time) greater three month period average flux entire water year. makes sense, seasons higher average fluxes seasons lower average fluxes. Now, might want think results, terms flux terms mass alone. first result (water year) mass year 0.149 106 kg. winter season compute mass 0.215 * 90 / 365 give us result 0.053 106 kg. get result took annual rate (0.215) divided number days year (365) get rate mass per day multiplied number days season (90) sum length three months simply get total mass. taken pains run calculation users sometimes confused, wondering flux part year can greater flux whole year. Depending ultimate objective analysis one might want present seasonal results either ways (mass mass per unit time). Next look descriptions change.","code":"library(EGRET) library(dplyr) eList <- Choptank_eList water_year <- tableResults(eList) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Water Year  ##  ##    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux ##              cms            mg/L             10^6 kg/yr  ##  ##    1980      4.25     0.949     1.003    0.1154     0.106 ##    1981      2.22     1.035     0.999    0.0675     0.108 ##    1982      3.05     1.036     0.993    0.0985     0.110 ##    1983      4.99     1.007     0.993    0.1329     0.112 ##    1984      5.72     0.990     1.002    0.1597     0.114 ##    1985      1.52     1.057     1.017    0.0489     0.116 ##    1986      2.63     1.062     1.038    0.0903     0.119 ##    1987      3.37     1.079     1.062    0.1142     0.122 ##    1988      1.87     1.120     1.085    0.0660     0.125 ##    1989      5.61     1.055     1.105    0.1638     0.127 ##    1990      4.01     1.115     1.125    0.1349     0.129 ##    1991      2.75     1.172     1.143    0.0980     0.130 ##    1992      2.19     1.203     1.159    0.0810     0.132 ##    1993      3.73     1.215     1.173    0.1306     0.132 ##    1994      5.48     1.144     1.187    0.1634     0.133 ##    1995      2.41     1.266     1.201    0.0928     0.134 ##    1996      6.24     1.134     1.213    0.1980     0.135 ##    1997      5.83     1.180     1.221    0.1884     0.136 ##    1998      4.88     1.236     1.229    0.1593     0.137 ##    1999      2.90     1.277     1.238    0.0919     0.138 ##    2000      4.72     1.213     1.253    0.1627     0.139 ##    2001      4.88     1.251     1.268    0.1655     0.140 ##    2002      1.24     1.321     1.285    0.0483     0.141 ##    2003      8.64     1.140     1.303    0.2664     0.143 ##    2004      5.28     1.274     1.321    0.1832     0.144 ##    2005      3.81     1.360     1.341    0.1444     0.146 ##    2006      3.59     1.382     1.362    0.1409     0.147 ##    2007      4.28     1.408     1.382    0.1593     0.149 ##    2008      2.56     1.477     1.401    0.1008     0.149 ##    2009      3.68     1.409     1.419    0.1328     0.149 ##    2010      7.19     1.323     1.438    0.2236     0.149 ##    2011      5.24     1.438     1.457    0.1554     0.148 water_year_2010_flux <- water_year$`FN Flux [10^6kg/yr]`[water_year$Year == 2010] eList <- setPA(eList, paStart = 12, paLong = 3) winter <- tableResults(eList) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Season Consisting of Dec Jan Feb  ##  ##    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux ##              cms            mg/L             10^6 kg/yr  ##  ##    1980     4.220      1.10      1.11    0.1403     0.156 ##    1981     1.960      1.20      1.13    0.0735     0.161 ##    1982     5.057      1.16      1.15    0.1764     0.165 ##    1983     3.504      1.21      1.16    0.1310     0.169 ##    1984     8.437      1.12      1.18    0.2624     0.173 ##    1985     2.249      1.24      1.21    0.0884     0.177 ##    1986     5.087      1.25      1.24    0.1902     0.182 ##    1987     7.730      1.23      1.27    0.2707     0.187 ##    1988     2.590      1.29      1.29    0.1039     0.191 ##    1989     3.327      1.36      1.31    0.1400     0.193 ##    1990     4.609      1.35      1.33    0.1928     0.195 ##    1991     3.883      1.36      1.33    0.1559     0.196 ##    1992     2.303      1.40      1.33    0.1015     0.195 ##    1993     4.421      1.36      1.32    0.1877     0.194 ##    1994     5.849      1.31      1.31    0.2072     0.193 ##    1995     3.693      1.37      1.31    0.1543     0.192 ##    1996     7.151      1.29      1.31    0.2618     0.193 ##    1997    11.786      1.18      1.32    0.3718     0.193 ##    1998     9.308      1.27      1.32    0.2979     0.194 ##    1999     2.526      1.32      1.33    0.1091     0.196 ##    2000     4.785      1.39      1.35    0.1995     0.198 ##    2001     5.392      1.39      1.37    0.2194     0.200 ##    2002     0.824      1.29      1.39    0.0336     0.202 ##    2003     9.213      1.33      1.41    0.3186     0.204 ##    2004     8.653      1.35      1.44    0.3126     0.207 ##    2005     4.196      1.54      1.47    0.1978     0.211 ##    2006     5.843      1.51      1.51    0.2675     0.214 ##    2007     5.417      1.55      1.53    0.2419     0.216 ##    2008     2.436      1.62      1.55    0.1217     0.217 ##    2009     2.711      1.66      1.56    0.1396     0.216 ##    2010    13.779      1.26      1.57    0.4161     0.215 ##    2011     3.369      1.66      1.57    0.1669     0.215 winter_2010_flux <- winter$`FN Flux [10^6kg/yr]`[winter$Year == 2010]  filter_setPA <- function(Daily, paStart, paLong){      monthsToUse <- seq(from = paStart,                       by = 1,                      length.out = paLong)   monthsToUse[monthsToUse > 12] <- monthsToUse[monthsToUse > 12] - 12       Daily_filtered <- Daily %>%      filter(Month %in% monthsToUse) %>%      mutate(YearIndex = trunc(DecYear))      crossesYear <- paLong + (paStart - 1) > 12      if(crossesYear){     Daily_filtered$YearIndex[Daily_filtered$Month >= paStart] <-       Daily_filtered$YearIndex[Daily_filtered$Month >= paStart] + 1   }      get_years <- Daily_filtered %>%      group_by(YearIndex) %>%      mutate(Year = trunc(mean(DecYear))) %>%      ungroup()          return(get_years)    }  number_of_days <- eList$Daily %>%    filter_setPA(paStart = eList$INFO$paStart,                paLong = eList$INFO$paLong) %>%    group_by(Year) %>%    summarise(n_days = sum(!is.na(Q)))  number_of_days_2010 <- number_of_days$n_days[number_of_days$Year == 2010]"},{"path":"/articles/SeasonalFraction.html","id":"seasonal-changes","dir":"Articles","previous_headings":"","what":"Seasonal Changes","title":"Seasonal Analysis in EGRET","text":"Let’s use tableChange function explore change 1990 2010. first full water year winter season. see fairly large difference concentration trends winter compared whole year (concentration rose steeply winter year average). going focus trend flux. first thing note change 1990 2010 identical winter season year whole. , change flow normalized flux full water year 0.02 106 kg/year (went 0.129 0.149) , look winter season change also 0.02 106 kg/yr (0.195 0.215). change season 20 year period essentially change entire water year. words, results tell us although change flux (mass per unit time) winter full year, change mass winter season 25% change full year (winter consists 25% days year). Thus, can conclude winter change atypical changes parts year. results shown also express change slope (either 0.00099 0.001 virtually identical ) simply change results divided number years. next entry tableChange output change expressed %. see big difference winter whole year. whole year shows increase 15 % 20 years, winter season shows increase 10 %. amount increase 0.02 106 kg / year compared smaller number (1990 flow normalized annual flux 0.129 106 kg/year) first table compared larger number (seasonal flux 0.195 106 kg/year) second table. , even though change focused equally winter non-winter months, percentage change winter smaller percentage change whole year.","code":"eList <- setPA(eList, paStart = 12, paLong = 12) change_annual_flux <- tableChangeSingle(eList, flux = TRUE,                                    yearPoints = c(1990,2010)) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Year Starting With December  ##  ##  ##  ##                  Flux Trends ##    time span          change        slope       change        slope ##                  10^6 kg/yr   10^6 kg/yr/yr      %         %/yr ##  ##  1990  to  2010         0.02      0.00099           15         0.77 change_annual_conc <- tableChangeSingle(eList, flux = FALSE,                                    yearPoints = c(1990,2010)) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Year Starting With December  ##  ##            Concentration trends ##    time span       change     slope    change     slope ##                      mg/L   mg/L/yr        %       %/yr ##  ##  1990  to  2010      0.32     0.016        28       1.4 eList <- setPA(eList, paStart = 12, paLong = 3) change_season_flux <- tableChangeSingle(eList, flux = TRUE,                                    yearPoints = c(1990,2010)) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Season Consisting of Dec Jan Feb  ##  ##  ##  ##                  Flux Trends ##    time span          change        slope       change        slope ##                  10^6 kg/yr   10^6 kg/yr/yr      %         %/yr ##  ##  1990  to  2010         0.02        0.001           10         0.51 change_season_conc <- tableChangeSingle(eList, flux = FALSE,                                    yearPoints = c(1990,2010)) ##  ##    Choptank River  ##    Inorganic nitrogen (nitrate and nitrite) ##    Season Consisting of Dec Jan Feb  ##  ##            Concentration trends ##    time span       change     slope    change     slope ##                      mg/L   mg/L/yr        %       %/yr ##  ##  1990  to  2010      0.24     0.012        18      0.89"},{"path":"/articles/SeasonalFraction.html","id":"seasonal-load-fraction","dir":"Articles","previous_headings":"","what":"Seasonal Load Fraction","title":"Seasonal Analysis in EGRET","text":"Next, can think seasonal load fraction. need read two new functions called setupSeasons setupYearsPlus designed purpose. can copy paste workspace (single copy paste) can create .R file source time want use . functions use package dplyr, package useful general data exploration manipulation. Simply use loaded eList calculate seasonal load fractions. Let’s go back winter season (Dec-Feb):","code":"setupSeasons <- function(eList){      Daily <- eList$Daily      paLong <- eList$INFO$paLong   paStart <- eList$INFO$paStart      Daily_season <- filter_setPA(Daily,                                paStart = paStart,                                paLong = paLong)   Daily_annual <- filter_setPA(Daily,                                paStart = paStart,                                paLong = 12)    #Cleanup units:   divideBy <- 1000000   divideBy <- 1    # Convert flux to kg/year   unit_scale <- fluxConst[[9]]@unitFactor / divideBy      SeasonResults <- Daily_season %>%        group_by(Year) %>%        summarize(DecYear = mean(DecYear),                 Counts = sum(!is.na(ConcDay)),                 Flux = mean(FluxDay) * unit_scale,                 FNFlux = mean(FNFlux) * unit_scale)      AnnualResults <- Daily_annual %>%     group_by(Year) %>%      summarize(AnnualCounts = sum(!is.na(ConcDay)),               AnnualFlux = mean(FluxDay) * unit_scale,               AnnualFNFlux = mean(FNFlux) * unit_scale) %>%     filter(AnnualCounts >= 365)         seasonPctResults <- SeasonResults %>%     select(DecYear, Year, Flux, FNFlux, Counts) %>%      left_join(select(AnnualResults,                      Year, AnnualCounts,                      AnnualFlux, AnnualFNFlux), by=\"Year\") %>%       filter(!is.na(AnnualFlux)) %>%     mutate(pctFlux = 100*Flux*Counts/(AnnualFlux*AnnualCounts),            pctFNFlux = 100*FNFlux*Counts/(AnnualFNFlux*AnnualCounts)) %>%     rename(SeasonFlux = Flux,            SeasonFNFlux = FNFlux)      return(seasonPctResults) } eList <- setPA(eList, paStart = 12, paLong = 3) seasonPctResults <- setupSeasons(eList)"},{"path":"/articles/SeasonalFraction.html","id":"looking-at-your-results","dir":"Articles","previous_headings":"","what":"Looking at your results","title":"Seasonal Analysis in EGRET","text":"now data frame called seasonPctResults. columns contains following:","code":""},{"path":"/articles/SeasonalFraction.html","id":"plotting-the-time-series","dir":"Articles","previous_headings":"","what":"Plotting the time series","title":"Seasonal Analysis in EGRET","text":"can make graph showing percentage flux (estimated annual flow normalized). Note, workflow uses base R plotting functions. also use EGRET function genericEGRETDotPlot automatically pick plotting styles consistent EGRET plots. Seasonal flux percentage annual flux. can interpret example graph follows. winter flux Inorganic nitrogen (nitrate nitrite) fluctuates good deal year year. low around 10% high around 60% mean percentage hasn’t changed much years. around 35% annual total flux.","code":"plotTitle = paste(\"Seasonal Flux as a Percent of Annual Flux\\n\",                   eList$INFO$shortName, eList$INFO$paramShortName,                   \"\\nSolid line is percentage of flow normalized flux\")  par(mar=c(5,6,4,2) + 0.1,mgp=c(3,1,0)) plot(seasonPctResults$DecYear, seasonPctResults$pctFlux,pch=20,      yaxs=\"i\",ylim = c(0,100),las=1,tck=.01,      xlab=\"Year\",ylab=\"Percentage of Annual Flux\",      main=plotTitle,cex=1.5) lines(seasonPctResults$DecYear,seasonPctResults$pctFNFlux,col=\"green\",lwd=2) axis(3, labels = FALSE,tck=.01) axis(4, labels = FALSE,tck=.01)"},{"path":"/articles/SeasonalFraction.html","id":"computing-averages-over-a-period-of-years","dir":"Articles","previous_headings":"","what":"Computing averages over a period of years","title":"Seasonal Analysis in EGRET","text":"Let’s say wanted answer question, percentage annual total flux moved winter season years 2000 2010. can answer question simple set calculations. Keep mind, way defining “year” year ending year period anaylsis fell. , analysis, full 2010 “year” Dec. 2009 end November 2010. Filter data frame seasonPctResults years 2000 - 2010. Now can compute sum annual fluxes years sum seasonal fluxes years, get answer taking ratio multiplying 100. total flux years period interest millions kg sumYears = 1.73. total seasonal flux years period interest millions kg sumSeasons = 0.61. percentage total flux years 2000 2010 transported winter months avePct = 35.3. can determined set years simply changing Year values dplyr::filter function. , years 1990-1999:","code":"years00_10 <- filter(seasonPctResults, Year >= 2000, Year <= 2010)  sumYears <- sum(years00_10$AnnualFlux)   sumSeasons <- sum(years00_10$SeasonFlux * years00_10$Counts /                     years00_10$AnnualCounts)  avePct <- 100 * sumSeasons / sumYears years90_99 <- filter(seasonPctResults, Year >= 1990, Year <= 1999)  c(\"sumYears\" = sum(years90_99$AnnualFlux), \"sumSeasons\" = sum(years90_99$SeasonFlux * years90_99$Counts / years90_99$AnnualCounts), \"avePct\" = 100 * sumSeasons / sumYears) ##   sumYears sumSeasons     avePct  ##  1.3327152  0.5037539 35.2611821"},{"path":"/articles/TrendsByMonth.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Trends by month","text":"vignette producing single type figure. designed examine trends pair years (using runPairs EGRET terminology) see size trend twelve months year. used make Figure 8 Choquette et al., 2019. helpful trying see trend specific certain part year (even opposite different parts year) versus fairly similar across months. EGRET version 3.0.7.2 (CRAN version 3.0.8), output runPairs includes information trends per individual month. output attached via attribute called “byMonth”. see tabular output results, use “byMonthly” attribute runPairs result. show months output: Next, let’s plot results using custom function :  might want make changes look figure, example:  also look concentration:","code":"library(EGRET) load(\"Conowingo.PO4.RData\") # source(\"runPairsMonths.R\") # source(\"plotOne.R\") pairResults <- runPairs(eList, windowSide = 0,                         paStart = 1, paLong = 12,                         year1 = 2006, year2 = 2017) ##  ##    SUSQUEHANNA RIVER AT CONOWINGO, MD  ##    00671 ##    Calendar Year  ##  ##  Change estimates  2017  minus  2006  ##  ##  For concentration: total change is  0.000904 mg/L ##  expressed as Percent Change is  10 % ##  ##  Concentration v. Q Trend Component  10 % ##        Q Trend Component             0 %  ##  ##  ##  For flux: total change is  0.116 million kg/year ##  expressed as Percent Change is  31 % ##  ##  Concentration v. Q Trend Component  31 % ##        Q Trend Component             0 %  ##  ##      TotalChange   CQTC QTC    x10    x11    x20    x22 ## Conc      0.0009 0.0009   0 0.0088 0.0088 0.0097 0.0097 ## Flux      0.1164 0.1164   0 0.3698 0.3698 0.4862 0.4862 monthly <-  attr(pairResults, \"byMonth\")  knitr::kable(monthly, digits = 2) plotMonthTrend(pairResults) plotMonthTrend(pairResults,                yMax = 1.2,                 arrowFactor = 0.6) plotMonthTrend(pairResults,                 arrowFactor = 1.2,                flux = FALSE)"},{"path":"/articles/TrendsByMonth.html","id":"reference-cited","dir":"Articles","previous_headings":"","what":"Reference cited","title":"Trends by month","text":"Choquette, .F., Hirsch, R.M., Murphy, J.C., Johnson, L.T. Confesor Jr, R.B., 2019. Tracking changes nutrient delivery western Lake Erie: Approaches compensate variability trends streamflow. Journal Great Lakes Research, 45(1), pp.21-39.","code":""},{"path":"/articles/WRTDSK.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"WRTDS Kalman","text":"document provides basic set instructions calculating WRTDSKalman estimates concentration flux (“load”). now two published papers lay motivation using approach (called “WRTDS_K”” papers), describe mathematics, show results compared methods. two publications can found : https://pubs.er.usgs.gov/publication/sir20195084 https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019WR025338 .","code":""},{"path":"/articles/WRTDSK.html","id":"why-would-one-use-wrtdskalman","dir":"Articles","previous_headings":"","what":"Why would one use WRTDSKalman?","title":"WRTDS Kalman","text":"important thing know intended use providing best possible estimates actual fluxes day, month, season, year record. (discussion emphasize use estimating fluxes, thing can said concentration record.) shown papers mentioned provide accurate estimates flux provided flux values original WRTDS model. intended use evaluating trends, using flow-normalized flux values. examples WRTDSKalman estimates appropriate. Say model (statistical deterministic) describes receiving water body (reservoir, lake estuary) responds inputs water, nutrients, well air temperature, wind, etc. response might chlorophyl concentrations dissolved oxygen receiving water body. running model evaluate performance want use WRTDSKalman estimates. Say interested mass balance material lake reservoir want make computations daily time step change storage material. accumulating sum inputs minus sum outputs. record represent change storage. assumption records produced WRTDS models (upstream downstream points) concept can work outputs estimated means. (aside know WRTDS model can provide poor estimates outflows reservoir discharge really representation state system really decision variable. work underway 2020 deals issue). Say concerns harmful effects constituent river wish know mean concentration period days weeks. WRTDSKalman values appropriate use describe levels organisims river exposed . producing “Nowcasts” inputs receiving water body. using assist water resources managers make decisions releases diversions levels treatment may needed expected quality water currently next days. may also want matter public information environmental awareness. working towards reducing nutrient loads river may want report things stand function current flow conditions put number, e.g. “today’s estimated load phosphorus watershed 2 metric tons” “estimate last month’s load nitrogen 50 metric tons”. estimates produced using --date sample data available --date discharge data (typically less 24-hours old) estimate WRTDS model compute WRTDSKalman estimates. important estimates made clear numbers subject substantial revision data points added data set. None related detection assessment trends concentration flux. purposes flow normalized concentration flow normalized flux remain preferred output consider remove noise due interannual variations discharge. one drawback WRTDSKalman estimates fact running computations given set data produce slightly different results time run. due fact computations involve use random number generator. Using large number iterations result small variations results. default number iterations 200 can take minute two computer time result minimal variations results. names variable used code “GenFlux” “GenConc” use prefix “Gen” reminder computation involves use random number generator. summary Use WRTDSKalman want best estimates given day, month, season, year. Use Flow Normalized values want describe trends.","code":""},{"path":"/articles/WRTDSK.html","id":"what-one-needs-in-order-to-run-this-are-the-following-items","dir":"Articles","previous_headings":"","what":"What one needs, in order to run this are the following items:","title":"WRTDS Kalman","text":"Install development version EGRET via remotes package (see ). data set must already form EGRET workspace containing eList four components eList (INFO, Daily, Sample, surfaces). , must data WRTDS model based data already estimated. data set must form “.RData” file contains eList, Nothing else needs file stuff, ’s ok. data set can contain multiple concentration values given day can also contain censored data (“less values”). two papers referenced consider either special situations, software package able properly handle data sets either properties. way issues handled described section end document. object created new eList, modified Daily data frame. looks just like original Daily two extra columns added. extra columns? GenFlux WRTDSKalman estimate flux day (kg/day) GenConc WRTDSKalman estimate concentration day (mg/L)","code":"library(EGRET)  load(\"ChainBridge.TP.RData\")  # now we will run the WRTDSKalman estimation (using the defaults for now) eList_K <- WRTDSKalman(eList, niter = 200) ## % complete: ## 0    1   2   3   4   5   6   7   8   9   10   ## 11   12  13  14  15  16  17  18  19  20   ## 21   22  23  24  25  26  27  28  29  30   ## 31   32  33  34  35  36  37  38  39  40   ## 41   42  43  44  45  46  47  48  49  50   ## 51   52  53  54  55  56  57  58  59  60   ## 61   62  63  64  65  66  67  68  69  70   ## 71   72  73  74  75  76  77  78  79  80   ## 81   82  83  84  85  86  87  88  89  90   ## 91   92  93  94  95  96  97  98  99 print(summary(eList_K$Daily)) ##       Date                  Q                Julian          Month        ##  Min.   :1984-10-01   Min.   :   4.927   Min.   :49216   Min.   : 1.000   ##  1st Qu.:1993-04-01   1st Qu.:  84.951   1st Qu.:52320   1st Qu.: 4.000   ##  Median :2001-10-01   Median : 194.820   Median :55425   Median : 7.000   ##  Mean   :2001-10-01   Mean   : 340.233   Mean   :55425   Mean   : 6.523   ##  3rd Qu.:2010-04-01   3rd Qu.: 395.020   3rd Qu.:58530   3rd Qu.:10.000   ##  Max.   :2018-10-01   Max.   :9231.292   Max.   :61634   Max.   :12.000   ##                                                                           ##       Day           DecYear        MonthSeq      waterYear          i         ##  Min.   :  1.0   Min.   :1985   Min.   :1618   Min.   :1985   Min.   :    1   ##  1st Qu.: 93.0   1st Qu.:1993   1st Qu.:1720   1st Qu.:1993   1st Qu.: 3106   ##  Median :184.0   Median :2002   Median :1822   Median :2002   Median : 6210   ##  Mean   :183.8   Mean   :2002   Mean   :1822   Mean   :2002   Mean   : 6210   ##  3rd Qu.:275.0   3rd Qu.:2010   3rd Qu.:1924   3rd Qu.:2010   3rd Qu.: 9314   ##  Max.   :366.0   Max.   :2019   Max.   :2026   Max.   :2019   Max.   :12419   ##                                                                               ##       LogQ             Q7                Q30               yHat         ##  Min.   :1.595   Min.   :   8.572   Min.   :  12.14   Min.   :-5.0036   ##  1st Qu.:4.442   1st Qu.:  89.400   1st Qu.: 104.93   1st Qu.:-3.3098   ##  Median :5.272   Median : 208.088   Median : 241.08   Median :-2.9232   ##  Mean   :5.255   Mean   : 339.743   Mean   : 338.98   Mean   :-2.9099   ##  3rd Qu.:5.979   3rd Qu.: 420.707   3rd Qu.: 471.02   3rd Qu.:-2.5544   ##  Max.   :9.130   Max.   :3868.890   Max.   :2079.02   Max.   : 0.5305   ##                  NA's   :6          NA's   :29                          ##        SE            ConcDay            FluxDay              FNConc        ##  Min.   :0.2959   Min.   :0.007268   Min.   :     21.5   Min.   :0.02874   ##  1st Qu.:0.4583   1st Qu.:0.042617   1st Qu.:    343.1   1st Qu.:0.06433   ##  Median :0.5447   Median :0.063900   Median :    925.8   Median :0.07963   ##  Mean   :0.5356   Mean   :0.080152   Mean   :   4831.6   Mean   :0.08105   ##  3rd Qu.:0.6091   3rd Qu.:0.092054   3rd Qu.:   2726.8   3rd Qu.:0.09553   ##  Max.   :0.7217   Max.   :1.882430   Max.   :1349413.9   Max.   :0.19000   ##                                                                            ##      FNFlux           GenFlux             GenConc         ##  Min.   :  255.9   Min.   :     11.1   Min.   :0.005916   ##  1st Qu.: 2018.7   1st Qu.:    301.7   1st Qu.:0.033763   ##  Median : 3743.6   Median :    795.9   Median :0.054052   ##  Mean   : 4979.2   Mean   :   4127.1   Mean   :0.071700   ##  3rd Qu.: 6372.4   3rd Qu.:   2301.9   3rd Qu.:0.086602   ##  Max.   :43441.1   Max.   :1577062.6   Max.   :2.200000   ##"},{"path":"/articles/WRTDSK.html","id":"summarizing-results-at-an-annual-time-step","dir":"Articles","previous_headings":"","what":"Summarizing results at an annual time step","title":"WRTDS Kalman","text":"Now can take results eList_K compute annual flux values. regular WRTDS WRTDSKalman. can also computations period analysis water year, now, just show water year computations. function used called setupYears produces data frame called AnnualResults.  Units cubic meters per second, milligrams per Liter, metric tons per year content AnnualResults fairly obvious. DecYear mean day year period analysis, example, water year 2007 mean day 2007.247 (end March 2007). Q mean discharge m^3/s. Conc mean value concentration year regular WRTDS model, mg/L. GenConc mean value concentration year WRTDSKalman model, mg/L. Flux mean daily flux values regular WRTDS model, units metric tons per year (10^3 kg / yr). GenFlux mean daily flux values WRTDSKalman model, units metric tons per year (10^3 kg / yr). first graph compares time series two flux records: WRTDS red WRTDSKalman green. graph fairly typical seen number studies far. number years two estimates practically identical (e.g. 2014, 2015, 2016, 2017) cases diverge significantly (e.g. 1996, 1998, 2006, 2018). example, cases WRTDSKalman estimate substantially lower WRTDS estimate. second graph just another way look results, scatter plot results two methods. see tendency fair number years plot close 1:1 line four substantially line (meaning WRTDSKalman estimates lower WRTDS estimates). Seeing , ’d like dig bit see ’s going .","code":"AnnualResults <- setupYears(eList_K$Daily) plotWRTDSKalman(eList_K) prettyAnnual <- AnnualResults[,c(\"DecYear\", \"Q\",                   \"Conc\", \"GenConc\", \"Flux\", \"GenFlux\")] kable(prettyAnnual, digits = c(0, 0, 3, 3, 0, 0), caption = \"Units are cubic meters per second, milligrams per Liter, and metric tons per year\")"},{"path":"/articles/WRTDSK.html","id":"looking-at-parts-of-the-record-to-see-how-wrtds-and-wrtdskalman-are-working","dir":"Articles","previous_headings":"","what":"Looking at parts of the record to see how WRTDS and WRTDSKalman are working","title":"WRTDS Kalman","text":"function produces graphics show, time series, daily true values (days samples), WRTDS estimates every day, WRTDSKalman estimates every day. plot whole record, ups downs curves tight really couldn’t see ’s going . , let user pick time slice look . produces two plots, first concentration (typically easier see happening estimation concentration graphs) second flux (discharge plays big role propagation error concentrations gets somewhat obscured, flux , , interested ). look two examples , case looking half year. first case (first half 2016) period good agreement estimates, second one (second half 1996) year large difference methods. Let’s see results look like.     can learn figures? first, first half 2016, start concentration graph. see 14 observed values (red dots). first observation 2016 fairly small negative residual, meaning true value slightly WRTDS estimate (black line). second observation shown (slightly less one month later) almost exactly correct. result , WRTDSKalman estimates period 14 days first observation slightly less WRTDS estimate, approach second observation two types estimates become virtually identical. case largest error (positive residual middle period shown graph) see residuals either side negative. case WRTDSKalman curve tends approach WRTDS curve midway periods observations. errors throughout period small don’t show tendency persist long string positive values negative values. ratio mean value WRTDSKalman estimates WRTDS estimates time period 0.99. words, similar average. look next graph, showing two flux estimates wee much pattern differences look limited simply large variations flux result variation discharge. ratio two estimates somewhat farther 1.0 (0.96) still differences minor. upshot residuals information doesn’t make much difference half year WRTDSKalman results really don’t change estimate much. Now, contrast result second half 1996. high values shown around 1996.7 come flood, 20-year recurrence interval event. WRTDS model three observations near peak event agree quite well. , move forward next months observations tend much lower WRTDS model predict. consequence WRTDSKalman estimates dramatically lower WRTDS estimates (much order magnitude). results surprizing. relatively accurate result time high discharge related fact observations overall dataset high discharges, observations good job guiding WRTDS highly accurate model. , high flow event likely consequence depleting watershed highly available phosphorus, typical discharges concentrations good deal lower model expects (moderate discharge range observations many years besides flood year). WRTDSKalman estimates period much lower regualr WRTDS estimates (ratio 0.64). graph flux looks generally similar ratio somewhat better (0.71) two methods relatively close high flow (hence high flux) days. generalization can say WRTDSKalman result large adjustments flux least one two things happen: 1) strong persistence residuals (long runs positives long runs negatives), 2) samples collected close days maximum flux show large absolute residuals. One final note graphs. title says: “Ratio means xx”. ratio WRTDSKalman estimates WRTDS estimates specific time slice shown plot (whole record estimated).","code":"plotTimeSlice(eList_K, start = 2016, end = 2016.5, conc = TRUE) plotTimeSlice(eList_K, start = 2016, end = 2016.5, conc = FALSE) plotTimeSlice(eList_K, start = 1996.5, end = 1997, conc = TRUE) plotTimeSlice(eList_K, start = 1996.5, end = 1997, conc = FALSE)"},{"path":"/articles/WRTDSK.html","id":"two-options-available-setting-rho-and-setting-niter","dir":"Articles","previous_headings":"","what":"Two options available (setting rho and setting niter)","title":"WRTDS Kalman","text":"One things user must select rho value. don’t strong theoretical basis selecting right value rho, although research shown results highly sensitive . paper published Zhang Hirsch (2019) (see second URL near start document) make generalizations selection rho. found nitrate slightly higher rho value (0.95) may better constitutents TP, OrthoP, Suspended Sediment, Chloride values like 0.85 0.9 may better. somewhat different behavior nitrate explained fact many sites factors probably related denitrification discharge seasonal terms great amount explanatory power WRTDS model. , placing reliance results samples close time appropriate. One can experiment different values rho argument WRTDSKalman function. can re-run analysis rho 0.85 see much difference makes. table shown lists percent difference annual values results. Percent difference change rho 0.90 0.85 see change rho 0.9 0.85 makes less 10% difference almost years 5% years. Setting number iterations 200 (default) seems sufficient. can set different random number seed see much difference makes results. Percent difference using different random number seed table shows us , worst individual annual fluxes differ 2% differ less 1% successive runs different seeds. annual concentrations never differ 2%. suggests 200 sufficient number iterations run obtain stable result. final calculations publication one might want specify niter = 500 niter = 1000 call WRTDSKalman, idea perfection, rather make reasonable adjustment flux record account serial correlation residuals.","code":"eList_2 <- WRTDSKalman(eList, rho = 0.85, niter = 200) ## % complete: ## 0    1   2   3   4   5   6   7   8   9   10   ## 11   12  13  14  15  16  17  18  19  20   ## 21   22  23  24  25  26  27  28  29  30   ## 31   32  33  34  35  36  37  38  39  40   ## 41   42  43  44  45  46  47  48  49  50   ## 51   52  53  54  55  56  57  58  59  60   ## 61   62  63  64  65  66  67  68  69  70   ## 71   72  73  74  75  76  77  78  79  80   ## 81   82  83  84  85  86  87  88  89  90   ## 91   92  93  94  95  96  97  98  99 print(attr(eList_2$Daily,\"rho\")) ## [1] 0.85 print(attr(eList_2$Daily,\"niter\")) ## [1] 200 AnnualResults2 <- setupYears(eList_2$Daily) AnnualResults2 <- AnnualResults2[,c(\"GenConc\", \"GenFlux\")] Ratios <- (AnnualResults2 - AnnualResults[, c(\"GenConc\", \"GenFlux\")]) / AnnualResults[, c(\"GenConc\", \"GenFlux\")] row.names(Ratios) <- round(AnnualResults$DecYear, 0) kable(Ratios*100, digits = 1, caption = \"Percent difference with a change in rho from 0.90 to 0.85\") eList3 <- WRTDSKalman(eList, niter = 200, seed = 1) ## % complete: ## 0    1   2   3   4   5   6   7   8   9   10   ## 11   12  13  14  15  16  17  18  19  20   ## 21   22  23  24  25  26  27  28  29  30   ## 31   32  33  34  35  36  37  38  39  40   ## 41   42  43  44  45  46  47  48  49  50   ## 51   52  53  54  55  56  57  58  59  60   ## 61   62  63  64  65  66  67  68  69  70   ## 71   72  73  74  75  76  77  78  79  80   ## 81   82  83  84  85  86  87  88  89  90   ## 91   92  93  94  95  96  97  98  99 AnnualResults3 <- setupYears(eList3$Daily) AnnualResults3 <- AnnualResults3[,c( \"GenConc\", \"GenFlux\")] Ratios <- (AnnualResults3 - AnnualResults[, c(\"GenConc\", \"GenFlux\")]) / AnnualResults[, c(\"GenConc\", \"GenFlux\")] row.names(Ratios) <- round(AnnualResults$DecYear, 0) kable(Ratios*100, digits = 1, caption = \"Percent difference with using a different random number seed\")"},{"path":"/articles/WRTDSK.html","id":"what-about-putting-these-results-into-the-plotconchist-or-plotfluxhist-graphs","dir":"Articles","previous_headings":"","what":"What about putting these results into the plotConcHist or plotFluxHist graphs","title":"WRTDS Kalman","text":"Typically type trend study may want create graphic outputs showing Flow Normalized values (connected line) estimated annual values (dots). may want put WRTDSKalman values graphs can now done plotConcHist plotFluxHist functions. used.","code":"plotConcHist(eList_K, plotAnnual = FALSE, plotGenConc = TRUE) plotFluxHist(eList_K, plotAnnual = FALSE, plotGenFlux = TRUE, fluxUnit = 8)"},{"path":"/articles/WRTDSK.html","id":"computing-monthly-results","dir":"Articles","previous_headings":"","what":"Computing monthly results","title":"WRTDS Kalman","text":"monthly results, rather annual results desired can computed function calculateMonthlyResults. doesn’t arguments selecting units flux, always expressed monthly rate units kg/day. example preparing simpler file pass results application produce graph.","code":"monthlyResults <- calculateMonthlyResults(eList_K) plot(monthlyResults$DecYear, monthlyResults$GenFlux/1000, type = \"l\", xaxs = \"i\", xlim = c(1980,2020), yaxs = \"i\", ylim = c(0,90), las = 1, tck = 0.02, xlab = \"\", ylab = \"Flux, in metric tons per day\", main = \"Potomac River at Chain Bridge, Washington, DC\\nTotal Phosphorus Flux, by Month\") Month <- monthlyResults$Month Year <- monthlyResults$Year DecYear <- monthlyResults$DecYear GenFlux <- monthlyResults$GenFlux/1000 monthFluxOut <- data.frame(Month, Year, DecYear, GenFlux) head(monthFluxOut) ##   Month Year  DecYear   GenFlux ## 1    10 1984 1984.790 0.7916501 ## 2    11 1984 1984.874 1.6574112 ## 3    12 1984 1984.957 3.7723969 ## 4     1 1985 1985.042 1.4358647 ## 5     2 1985 1985.123 7.5488542 ## 6     3 1985 1985.204 2.6642166"},{"path":"/articles/WRTDSK.html","id":"operationalizing-this-in-a-batch-job","dir":"Articles","previous_headings":"","what":"Operationalizing this in a batch job","title":"WRTDS Kalman","text":"process installing development version EGRET. load workspace site give command eList <- WRTDSKalman(eList) give command AnnualResults <- setupYears(eList) save object AnnualResults plot results plotWRTDSKalman(eList) tables graphs probably want can made content Annual Results, meta data INFO object eList interest one season year modify call setupYears adding paStart paLong arguments season interested . note data frame AnnualResults two attributes tell paStart paLong, can always tell used period analysis","code":""},{"path":"/articles/WRTDSK.html","id":"how-the-code-handles-two-kinds-of-special-situations","dir":"Articles","previous_headings":"","what":"How the code handles two kinds of special situations","title":"WRTDS Kalman","text":"description two publications mentioned accurately describes computations work situation days record one observed value censored data exist record. following section describes code handles data sets violate one constraints. don’t really understand use software, completeness describing situations handled code.","code":""},{"path":"/articles/WRTDSK.html","id":"censored-data-less-than-values","dir":"Articles","previous_headings":"How the code handles two kinds of special situations","what":"Censored data (less than values)","title":"WRTDS Kalman","text":"order fill estimates days samples, must known value sampled days. use known value compute residual sampled day. known residuals either side data gap initialize AR(1) process fills missing values residuals gap. incorrect set censored values reporting limit (ConcHigh) also incorrect set censored values half reporting limit (ConcAve). solution . Since estimating entire time series residuals using Monte Carlo simulation can also use Monte Carlo methods create appropriate value sampled day. replicate whole time series generate random values censored sample days. already function allows us generate random realizations censored day concentration. function EGRET called makeAugmentedSample. day censored value defines truncated log normal distribution takes random sample distribution represent unknown true value day. truncated lognormal distribution defined WRTDS model day. uses estimates conditional mean log concentration conditional standard deviation log concentration assumes conditional distribution logs normal. distribution whole normal distribution, rather made left hand tail distribution. truncation point log reporting limit data value. means censored day, can create Monte Carlo sample value log concentration sampling truncated normal distribution (specific conditions day). Note random observation values generated used estimate WRTDS model; done usual fashion using censored sample information. now data generation scheme done two phases iteration: First fill values censored days , combined uncensored values constitute sample data set work . use AR(1) process fill missing days sampled days. move next iteration start estimating censored days fill gaps, etc. plot data sets using plotTimeSlice, censored values plot blue color located randomly value less equal reporting limit (rObserved value computed makeAugmentedSample). green line go points way red points, WRTDSKalman estimates based multiple realizations rObserved values.","code":""},{"path":"/articles/WRTDSK.html","id":"multiple-observations-on-a-day","dir":"Articles","previous_headings":"How the code handles two kinds of special situations","what":"Multiple observations on a day","title":"WRTDS Kalman","text":"day one observation (.e. one sample value) approach use much used censored value situation. need order generate full WRTDSKalman record set unique values sampled days. , day two samples randomly pick one use end point adjacent gap periods. pick generate values sampled days regardless whether sample value used unique value day randomly selected multiple values observed day. next iteration randomly select values multiply sampled days proceed AR(1) process fill sampled days. plot produced plotTimeSlice observations shown red dots. Thus multiple sample values given day plot along vertical line situated day. green line run average multiple sample values day.","code":""},{"path":"/articles/WRTDSK.html","id":"whats-happening-next","dir":"Articles","previous_headings":"","what":"What’s happening next","title":"WRTDS Kalman","text":"aim release new version EGRET end summer 2020. Work now (July 2020) underway estimates uncertainty WRTDSKalman estimates concentrations loads. method developed still needs undergo testing. method verified disseminate via EGRETci package.","code":""},{"path":"/articles/WRTDSK.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"WRTDS Kalman","text":"Lee, C.J., Hirsch, R.M., Crawford, C.G., 2019, evaluation methods computing annual water-quality loads: U.S. Geological Survey Scientific Investigations Report 2019–5084, 59 p., https://doi.org/10.3133/sir20195084. Zhang, Q. Hirsch, R.M., 2019. River water‐quality concentration flux estimation can improved accounting serial correlation autoregressive model. Water Resources Research. https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1029/2019WR025338","code":""},{"path":"/articles/parallel.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Running WRTDS in parallel","text":"EGRET version 2.6.1, ’ve added dependency foreach, can allow modelEstimation function run parallel. Depending available cores, significantly speed WRTDS calculations. default, code still run serially (ie…parallel). directions vignette show take advantage multiple cores single computer. concept can extended cluster computing (example: HTConder, SLURM (USGS YETI), Alces Flight,…), specific directions systems covered vignette. WRTDS routine modelEstimation function major process improved parallel processing EGRET package. Confidence intervals trend calculations EGRETci package also updated parallel capabilities via foreach package. See vignette “Running EGRETci Parallel” EGRETci details.","code":""},{"path":"/articles/parallel.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Running WRTDS in parallel","text":"order run WRTDS parallel get computationally efficient advantage, first need computer multiple cores. newer computers multi-core. check many cores computer , use detectCores() function parallel packages (shipped base R installation): overhead involved going serial parallel computing, expect 1:1 speed-. computer 2 cores, might see improvements efficiency.","code":"library(parallel) detectCores() ## [1] 2"},{"path":"/articles/parallel.html","id":"registering-your-cores","dir":"Articles","previous_headings":"Setup","what":"Registering your cores","title":"Running WRTDS in parallel","text":"’ve checked computer multiple cores, need register many cores want use. ways . depend operating system general workflow exactly best way . currently 3 main packages can use parallelize modelEstimation function: doParallel, doSNOW, doMC. doParallel package recommend new users works best three major operating systems (Windows, Mac, Linux). However, doMC can efficient Linux. Therefore, recommend doParallel, show workflows packages. recommended use detectCores(logical = FALSE) - 1 cores calculations. leaves one core available computer processes. modern CPU’s can handle registering cores computer without issue. fact, register cores physically computer, inefficient. using function detectCores, recommend specifying logical = FALSE find number physical cores computer. logical=TRUE includes multithreading, found generally improve efficiency calculations. Note: packages doParallel doMC suggested EGRET. means automatically installed EGRET installation. need install separately package choice. Important workflows, processing completed, need stop cluster registration stopCluster function. now show 3 examples using “Choptank River” example data:","code":"library(EGRET) library(parallel)  eList <- Choptank_eList nCores <- detectCores(logical = FALSE) - 1"},{"path":"/articles/parallel.html","id":"doparellel","dir":"Articles","previous_headings":"Setup > Registering your cores","what":"doParellel","title":"Running WRTDS in parallel","text":"generalized workflow uses doParallel package:","code":"library(doParallel) library(parallel)  cl <- makeCluster(nCores) registerDoParallel(cl) eList <- modelEstimation(eList, verbose = FALSE, run.parallel = TRUE) stopCluster(cl)"},{"path":"/articles/parallel.html","id":"domc","dir":"Articles","previous_headings":"Setup > Registering your cores","what":"doMC","title":"Running WRTDS in parallel","text":"","code":"library(doMC) library(parallel)  cl <- makeCluster(nCores) registerDoMC(cl) eList <- modelEstimation(eList, verbose = FALSE, run.parallel = TRUE) stopCluster(cl)"},{"path":"/articles/parallel.html","id":"simple-benchmarking","dir":"Articles","previous_headings":"","what":"Simple Benchmarking","title":"Running WRTDS in parallel","text":"plan use modelEstimation function frequently, worth trying simple benchmark test determine running code parallel makes sense system. significantly robust benchmark testing available several R packages (see microbenchmark example), simple test can done system.time function: timing parallel code significantly faster (even slower!) regular non-parallel code, worth running parallel current computer.","code":"library(doParallel) library(parallel) library(EGRET)  eList <- Choptank_eList  nCores <- detectCores(logical = FALSE) - 1  system.time({   cl <- makeCluster(nCores)   registerDoParallel(cl)   eList <- modelEstimation(eList, verbose = FALSE, run.parallel = TRUE)   stopCluster(cl) }) user  system elapsed     9.11    0.95   33.34 system.time({   eList <- modelEstimation(eList, verbose = FALSE, run.parallel = FALSE) }) user  system elapsed    60.05    0.05   60.51"},{"path":"/articles/rResid.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Randomized Censored Data","text":"censored data present water quality data set, depicting type scatter plot challenge. applies problem plotting actual data values plotting residuals. follows example shows problem.  solid vertical lines, represent range values given censored value , distracting terms getting picture overall behavior data. can see even try look relationship concentration discharge.  difficult see relationship ammonia concentration discharge. look residuals fitted WRTDS model discharge also find difficult see pattern looks reasonable (horizontal cloud points centered zero residual line) substantial curvature relationship.  , plot informative. solutions might exist resolve problem graphical representation censored data?","code":""},{"path":"/articles/rResid.html","id":"the-concept-of-randomized-estimates-of-censored-values","dir":"Articles","previous_headings":"","what":"The concept of randomized estimates of censored values","title":"Randomized Censored Data","text":"think fitted WRTDS model, telling us : particular date particular discharge model estimates unique conditional probability distribution concentration. distribution always log normal distribution (means log concentration normal) distribution log concentration particular mean (EGRET package always called yHat) particular standard deviation (always called SE). Daily data frame columns names, showing value day record. However, days sample taken sample reported “less ” value, also know upper bound concentration . reporting limit. aside, following discussion hold interval censored value. EGRET allows common. simplicity discussion consider left censored data, code used considers interval censored data well. , can say particular censored value log true value mean yHat standard deviation SE, normally distributed, constrained part normal distribution less log reporting limit. random variable known truncated normal random variable. Fortunately R package entirely focused truncated normal distribution. called truncnorm. can use truncnorm generate random number censored values random number drawn lower portion normal distribution correct mean, standard deviation, upper bound. idea create random values substitute censored observations. call rObserved values (“r” denotes randomly generated observations) reside augmented version Sample data frame column called Sample$rObserved. figures illustrate truncated normal distribution density function looks like. show density censoring threshold two different examples. rObserved values samples density functions. area density function equal 1.  important understand randomly generated values never used WRTDS computations result estimates daily concentrations fluxes, annual average concentrations fluxes, trends. randomly generated values created strictly provide -easily interpreted set diagonstic graphics. example plot concentration versus time using approach. solid circles uncensored observations open circles rObserved values. One thing note values generated second time graph look slightly different. unique set values plotted. random numbers used different go back data set generate . show figure redo graphic second set random numbers. code shown graphics.   Careful examination two figures reveals black dots exactly , open circles different two. looking kinds plots necessarily looking see actually happened particular day, rather understand pattern relationship two variables plotted.","code":"eList <- makeAugmentedSample(eList) plotConcQ(eList, qUnit = 4, randomCensored = TRUE) # now do it all over again eList <- makeAugmentedSample(eList) plotConcQ(eList, qUnit = 4, randomCensored = TRUE)"},{"path":"/articles/rResid.html","id":"randomized-residuals","dir":"Articles","previous_headings":"","what":"Randomized residuals","title":"Randomized Censored Data","text":"Many diagnostics use EGRET plots residuals (y-axis) versus predicted value, time, discharge (x-axis). rObserved value, can compute randomized residual called rResid (“r” denotes randomly generated residuals) stored Sample$rResid EGRET. computation : rResid = rObserved - predicted value. three variables equation log concentration units. can look residuals plots following manner (using second set rObserved values computed ).","code":"plotResidTime(eList, randomCensored = TRUE) plotResidQ(eList, qUnit = 4, randomCensored = TRUE)"},{"path":"/articles/rResid.html","id":"details-for-how-to-include-random-residuals-in-your-computations","dir":"Articles","previous_headings":"","what":"Details for how to include random residuals in your computations","title":"Randomized Censored Data","text":"order use rObserved rResid making graphs EGRET process following. Bring data create eList usual way: eList <- mergeReport(INFO,Daily,Sample) Run modelEstimation usual way: eList <- modelEstimation(eList) augment Sample data frame inside eList command: produce one following graphics, using rObserved rResid values simply add argument randomCensored = TRUE call graphical function. Note doesn’t matter plotted observed value residual, argument always randomCensored = TRUE. original option showing vertical lines censored values remains available default functions. call can either say randomCensored = FALSE just include randomCensored argument list graphs appear without random values without open circle/closed circle symbology. censored values censored residuals shown vertical lines. functions approach applies : plotConcPred, plotConcQ, plotConcTime, plotConcTimeDaily, plotFluxPred, plotFluxQ, plotFluxTImeDaily, plotResidPred, plotResidQ, plotResidTime. also available two multiple plot functions: multiPlotOverview, fluxBiasMulti example:","code":"eList <- makeAugmentedSample(eList) multiPlotDataOverview(eList, qUnit = 4, randomCensored = TRUE) fluxBiasMulti(eList, qUnit = 4, fluxUnit = 9, randomCensored = TRUE)"},{"path":"/articles/rResid.html","id":"two-final-thoughts","dir":"Articles","previous_headings":"","what":"Two final thoughts","title":"Randomized Censored Data","text":"EGRET User Guide (https://pubs.usgs.gov/tm/04/a10/) distinction made graphical methods used simply describe data (graphics shown multiPlotDataOverview) distinct graphical methods used describe WRTDS model system (graphs fluxBiasMulti). randomCensored = TRUE option used multiPlotDataOverview, graphical functions normally don’t depend WRTDS model, now become hybrid, using WRTDS model generate random values used graphs. Take graph plotConcQ. randomCensored = FALSE pure representation data. assumptions made. , randomCensored = TRUE, now representation data partly based assumption fitted WRTDS model indeed correct model. fitted WRTDS model partly determining placement random values less reporting limit. analyst wants “pure” representation data without assumed model graphing, randomCensored option set FALSE. Also, figures shown fluxBiasMulti, kind circularity logic. circularity : using graphs assess adequacy model fit, using model estimate observations. circularity fatal flaw approach, reality user consider. balance, authors think using randomCensored = TRUE plots applies beneficial approach enhances ability analyst interpret figures. , reiterate , choice using random approach bearing whatsoever quantitative outputs WRTDS method EGRET package produces.","code":""},{"path":"/articles/streamflow_trend.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"Daily Streamflow Trend Analysis","text":"First, EGRET package needs installed loaded. , ’ll need need create eList object, contains site information daily discharge data streamgage. Page 13 EGRET user guide . post, use Choptank River Maryland first example. example data set included EGRET. data set consists site information, daily discharge data, water quality data, application use water quality data. Refer section near end document called Downloading data site interest see can set eList object USGS streamgage. two limitations users know application proceeding . code designed discharge records complete (gaps). usually problem USGS discharge records unless major gap (typically years length) streamgage operating. records number small gaps, users use established method filling missing data create gap-free record. discharge every day positive value (zero negative). EGRET code used read new data “work around” situations small number non-positive discharge values. adds small constant discharge data positive. almost impact results provided number non-positive days small, say less 0.1% days. translates 11 days 30 years. data sets zero negative flow days different code need written (appreciate user work developing set code). start, following R commands needed. Just get sense data look portion metadata (gage ID number, name, drainage area square kilometers) also see summary discharge data (discharge cubic meters per second).","code":"library(EGRET) eList <- Choptank_eList print(eList$INFO$site.no) ## [1] \"01491000\" print(eList$INFO$shortName) ## [1] \"Choptank River\" print(eList$INFO$drainSqKm) ## [1] 292.6687 print(summary(eList$Daily$Date)) ##         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.  ## \"1979-10-01\" \"1987-09-30\" \"1995-09-30\" \"1995-09-30\" \"2003-09-30\" \"2011-09-30\" print(summary(eList$Daily$Q)) ##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  ##   0.00991   0.93446   2.40693   4.08658   4.61565 246.35656"},{"path":"/articles/streamflow_trend.html","id":"loading-the-necessary-packages-and-other-r-code","dir":"Articles","previous_headings":"","what":"Loading the necessary packages and other R code","title":"Daily Streamflow Trend Analysis","text":"run analysis produce graphs need R functions addition EGRET package. can copy entire block code shown paste workspace (single copy paste) can create .R file code source time want use . Let’s say call flowTrends.R, time want use need “source” object flowTrends.R. addition EGRET functions use packages rkt, zyp, lubridate, Kendall. Make sure installed .","code":"library(rkt) library(zyp) library(lubridate)   ########## this is the function you will use to make a single trend graph  ##############   plotFlowTrend <- function (eList, istat, startDate = NA, endDate = NA,                             paStart = 4, paLong = 12, window = 30, qMax = NA,                             printTitle = TRUE, tinyPlot = FALSE,                             customPar = FALSE, runoff = FALSE,                            qUnit = 2, printStaName = TRUE, printPA = TRUE,                            printIstat = TRUE, cex = 0.8, cex.axis = 1.1,                            cex.main = 1.1, lwd = 2, col = \"black\", ...){   localDaily <- getDaily(eList)   localINFO <- getInfo(eList)   localINFO$paStart <- paStart   localINFO$paLong <- paLong   localINFO$window <- window   start <- as.Date(startDate)   end <- as.Date(endDate)      if(is.na(startDate)){     start <- as.Date(localDaily$Date[1])    }       if(is.na(endDate)){     end <- as.Date(localDaily$Date[length(localDaily$Date)])   }      localDaily <- subset(localDaily, Date >= start & Date <= end)   eList <- as.egret(localINFO,localDaily)   localAnnualSeries <- makeAnnualSeries(eList)   qActual <- localAnnualSeries[2, istat, ]   qSmooth <- localAnnualSeries[3, istat, ]   years <- localAnnualSeries[1, istat, ]   Q <- qActual   time <- years   LogQ <- log(Q)   mktFrame <- data.frame(time,LogQ)   mktFrame <- na.omit(mktFrame)   mktOut <- rkt::rkt(mktFrame$time,mktFrame$LogQ)   zypOut <- zyp::zyp.zhang(mktFrame$LogQ,mktFrame$time)   slope <- mktOut$B   slopePct <- 100 * (exp(slope)) - 100   slopePct <- format(slopePct,digits=2)   pValue <- zypOut[6]   pValue <- format(pValue,digits = 3)      if (is.numeric(qUnit)) {     qUnit <- qConst[shortCode = qUnit][[1]]   } else if (is.character(qUnit)) {     qUnit <- qConst[qUnit][[1]]   }      qFactor <- qUnit@qUnitFactor   yLab <- qUnit@qUnitTiny      if (runoff) {     qActual <- qActual * 86.4/localINFO$drainSqKm     qSmooth <- qSmooth * 86.4/localINFO$drainSqKm     yLab <- \"Runoff in mm/day\"   } else {     qActual <- qActual * qFactor     qSmooth <- qSmooth * qFactor   }      localSeries <- data.frame(years, qActual, qSmooth)         yInfo <- generalAxis(x = qActual, maxVal = qMax, minVal = 0,                         tinyPlot = tinyPlot)   xInfo <- generalAxis(x = localSeries$years, maxVal = decimal_date(end),                         minVal = decimal_date(start), padPercent = 0, tinyPlot = tinyPlot)      line1 <- localINFO$shortName   nameIstat <- c(\"minimum day\", \"7-day minimum\", \"30-day minimum\",                   \"median daily\", \"mean daily\", \"30-day maximum\", \"7-day maximum\",                   \"maximum day\")      line2 <-  paste0(\"\\n\", setSeasonLabelByUser(paStartInput = paStart,                                                paLongInput = paLong), \"  \", nameIstat[istat])      line3 <- paste0(\"\\nSlope estimate is \",slopePct,\"% per year, Mann-Kendall p-value is \",pValue)      if(tinyPlot){     title <- paste(nameIstat[istat])   } else {     title <- paste(line1, line2, line3)   }      if (!printTitle){     title <- \"\"   }      genericEGRETDotPlot(x = localSeries$years, y = localSeries$qActual,                        xlim = c(xInfo$bottom, xInfo$top), ylim = c(yInfo$bottom,                                                                    yInfo$top), xlab = \"\", ylab = yLab, customPar = customPar,                        xTicks = xInfo$ticks, yTicks = yInfo$ticks, cex = cex,                        plotTitle = title, cex.axis = cex.axis, cex.main = cex.main,                        tinyPlot = tinyPlot, lwd = lwd, col = col, ...)   lines(localSeries$years, localSeries$qSmooth, lwd = lwd,          col = col) }  ######################################################################################### ###### this the the function you will use to make the Quantile Kendall Plot ############# #########################################################################################  plotQuantileKendall <- function(eList, startDate = NA, endDate = NA,                        paStart = 4, paLong = 12,                            legendLocation = \"topleft\", legendSize = 1.0,                       yMax = NA, yMin = NA) {   localDaily <- eList$Daily   localINFO <- eList$INFO   localINFO$paStart <- paStart   localINFO$paLong <- paLong   start <- as.Date(startDate)   end <- as.Date(endDate)      if(is.na(startDate)){     start <- as.Date(localDaily$Date[1])    }       if(is.na(endDate)){     end <- as.Date(localDaily$Date[length(localDaily$Date)])   }      localDaily <- subset(localDaily, Date >= start & Date <= end)   eList <- as.egret(localINFO,localDaily)   eList <- setPA(eList, paStart=paStart, paLong=paLong)      v <- makeSortQ(eList)   sortQ <- v[[1]]   time <- v[[2]]   results <- trendSortQ(sortQ, time)   pvals <- c(0.001,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,0.999)   zvals <- qnorm(pvals)   name <- eList$INFO$shortName #  ymax <- trunc(max(results$slopePct)*10) #  ymax <- max(ymax + 2, 5) #  ymin <- floor(min(results$slopePct)*10) #  ymin <- min(ymin - 2, -5) #  yrange <- c(ymin/10, ymax/10) #  yticks <- axisTicks(yrange, log = FALSE)   ymax <- max(results$slopePct + 0.5, yMax, na.rm = TRUE)   ymin <- min(results$slopePct - 0.5, yMin, na.rm = TRUE)   yrange <- c(ymin, ymax)   yticks <- axisTicks(yrange, log = FALSE, nint =7)   p <- results$pValueAdj   color <- ifelse(p <= 0.1,\"black\",\"snow3\")   color <- ifelse(p < 0.05, \"red\", color)   pvals <- c(0.001,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,0.999)   zvals <- qnorm(pvals)   name <- paste0(\"\\n\", eList$INFO$shortName,\"\\n\",                  start,\" through \", end, \"\\n\",                   setSeasonLabelByUser(paStartInput = paStart, paLongInput = paLong))   plot(results$z,results$slopePct,col = color, pch = 20, cex = 1.0,         xlab = \"Daily non-exceedance probability\",         ylab = \"Trend slope in percent per year\",         xlim = c(-3.2, 3.2), ylim = yrange, yaxs = \"i\",         las = 1, tck = 0.02, cex.lab = 1.2, cex.axis = 1.2,         axes = FALSE, frame.plot=TRUE)   mtext(name, side =3, line = 0.2, cex = 1.2)   axis(1,at=zvals,labels=pvals, las = 1, tck = 0.02)   axis(2,at=yticks,labels = TRUE, las = 1, tck = 0.02)   axis(3,at=zvals,labels=FALSE, las = 1, tck=0.02)   axis(4,at=yticks,labels = FALSE, tick = TRUE, tck = 0.02)   abline(h=0,col=\"blue\")   legend(legendLocation,c(\"> 0.1\",\"0.05 - 0.1\",\"< 0.05\"),col = c(\"snow3\",                                            \"black\",\"red\"),pch = 20, title = \"p-value\",          pt.cex=1.0, cex = legendSize * 1.5) }      ######################################################################################### ############  This next function combines four individual trend graphs (for mimimum day, ########### median day, mean day, and maximum day) along with the quantile kendall graph #########################################################################################  plotFiveTrendGraphs <- function(eList, startDate = NA, endDate = NA,                                  paStart = 4, paLong = 12, qUnit = 2, window = 30,                                  legendLocation = \"topleft\", legendSize = 1.0) {   localDaily <- eList$Daily   localINFO <- eList$INFO   localINFO$paStart <- paStart   localINFO$paLong <- paLong   localINFO$window <- window      start <- as.Date(startDate)   end <- as.Date(endDate)      if(is.na(startDate)){     start <- as.Date(localDaily$Date[1])    }       if(is.na(endDate)){     end <- as.Date(localDaily$Date[length(localDaily$Date)])   }      localDaily <- subset(localDaily, Date >= start & Date <= end)      eList <- as.egret(localINFO,localDaily)   eList <- setPA(eList, paStart=paStart, paLong=paLong, window=window)   # this next line of code is inserted so that when paLong = 12, we always use the   # climate year when looking at the trends in the annual minimum flow   paStart1 <- if(paLong == 12)  4 else paStart   plotFlowTrend(eList, istat = 1, qUnit = qUnit, paStart = paStart1, paLong = paLong, window = window)   plotFlowTrend(eList, istat = 4, qUnit = qUnit, paStart = paStart, paLong = paLong, window = window)   plotFlowTrend(eList, istat = 8, qUnit = qUnit, paStart = paStart, paLong = paLong, window = window)   plotFlowTrend(eList, istat = 5, qUnit = qUnit, paStart = paStart, paLong = paLong, window = window)   # now the quantile kendall   plotQuantileKendall(eList, startDate = startDate, endDate = endDate, paStart = paStart,                       paLong = paLong, legendLocation = legendLocation, legendSize = legendSize)    }   ######################################################################################### ########### makeSortQ creates a matrix called Qsort.  ############It sorted from smallest to largest over dimDays  ############(if working with full year dimDays=365),  #############and also creates other vectors that contain information about this array. #########################################################################################  makeSortQ <- function(eList){   localINFO <- getInfo(eList)   localDaily <- getDaily(eList)   paStart <- localINFO$paStart   paLong <- localINFO$paLong   # determine the maximum number of days to put in the array   numDays <- length(localDaily$DecYear)   monthSeqFirst <- localDaily$MonthSeq[1]   monthSeqLast <- localDaily$MonthSeq[numDays]   # creating a data frame (called startEndSeq) of the MonthSeq values that go into each year   Starts <- seq(paStart, monthSeqLast, 12)   Ends <- Starts + paLong - 1   startEndSeq <- data.frame(Starts, Ends)   # trim this list of Starts and Ends to fit the period of record   startEndSeq <- subset(startEndSeq, Ends >= monthSeqFirst & Starts <= monthSeqLast)   numYearsRaw <- length(startEndSeq$Ends)   # set up some vectors to keep track of years   good <- rep(0, numYearsRaw)   numDays <- rep(0, numYearsRaw)   midDecYear <- rep(0, numYearsRaw)   Qraw <- matrix(nrow = 366, ncol = numYearsRaw)   for(i in 1: numYearsRaw) {     startSeq <- startEndSeq$Starts[i]     endSeq <- startEndSeq$Ends[i]     startJulian <- getFirstJulian(startSeq)     # startJulian is the first julian day of the first month in the year being processed     # endJulian is the first julian day of the month right after the last month in the year being processed     endJulian <- getFirstJulian(endSeq + 1)     fullDuration <- endJulian - startJulian     yearDaily <- localDaily[localDaily$MonthSeq >= startSeq & (localDaily$MonthSeq <= endSeq), ]     nDays <- length(yearDaily$Q)     if(nDays == fullDuration) {       good[i] <- 1       numDays[i] <- nDays       midDecYear[i] <- (yearDaily$DecYear[1] + yearDaily$DecYear[nDays]) / 2       Qraw[1:nDays,i] <- yearDaily$Q     }   else {       numDays[i] <- NA       midDecYear[i] <- NA     }   }   # now we compress the matrix down to equal number of values in each column   j <- 0   numGoodYears <- sum(good)   dayCounts <- ifelse(good==1, numDays, NA)   lowDays <- min(dayCounts, na.rm = TRUE)   highDays <- max(dayCounts, na.rm = TRUE)   dimYears <- numGoodYears   dimDays <- lowDays   sortQ <- matrix(nrow = dimDays, ncol = dimYears)   time <- rep(0,dimYears)   for (i in 1:numYearsRaw){     if(good[i]==1) {       j <- j + 1       numD <- numDays[i]       x <- sort(Qraw[1:numD, i])       # separate odd numbers from even numbers of days       if(numD == lowDays) {         sortQ[1:dimDays,j] <- x       } else {         sortQ[1:dimDays,j] <- if(odd(numD)) leapOdd(x) else leapEven(x)       }       time[j] <- midDecYear[i]     }    }      sortQList = list(sortQ,time)      return(sortQList)          } ######################################################################################### ########## Another function trendSortQ needed for Quantile Kendall #########################################################################################  trendSortQ <- function(Qsort, time){   # note requires packages zyp and rkt   nFreq <- dim(Qsort)[1]   nYears <- length(time)   results <- as.data.frame(matrix(ncol=9,nrow=nFreq))   colnames(results) <- c(\"slopeLog\",\"slopePct\",\"pValue\",\"pValueAdj\",\"tau\",\"rho1\",\"rho2\",\"freq\",\"z\")   for(iRank in 1:nFreq){     mkOut <- rkt::rkt(time,log(Qsort[iRank,]))     results$slopeLog[iRank] <- mkOut$B     results$slopePct[iRank] <- 100 * (exp(mkOut$B) - 1)     results$pValue[iRank] <- mkOut$sl     outZYP <- zyp.zhang(log(Qsort[iRank,]),time)     results$pValueAdj[iRank] <- outZYP[6]     results$tau[iRank] <- mkOut$tau     # I don't actually use this information in the current outputs, but the code is there      # if one wanted to look at the serial correlation structure of the flow series           serial <- acf(log(Qsort[iRank,]), lag.max = 2, plot = FALSE)     results$rho1[iRank] <- serial$acf[2]     results$rho2[iRank] <- serial$acf[3]     frequency <- iRank / (nFreq + 1)     results$freq[iRank] <- frequency     results$z[iRank] <- qnorm(frequency)       }   return(results) } ######################################################################################### ################################## getFirstJulian finds the julian date of first day ################################## of a given month #########################################################################################  getFirstJulian <- function(monthSeq){   year <- 1850 + trunc((monthSeq - 1) / 12)   month <- monthSeq - 12 * (trunc((monthSeq-1)/12))   charMonth <- ifelse(month<10, paste0(\"0\",as.character(month)), as.character(month))   theDate <- paste0(year,\"-\",charMonth,\"-01\")   Julian1 <- as.numeric(julian(as.Date(theDate),origin=as.Date(\"1850-01-01\")))   return(Julian1) }  ######################################################################################### ########### leapOdd  is a function for deleting one value  ############when the period that contains Februaries has a length that is an odd number #########################################################################################  leapOdd <- function(x){   n <- length(x)   m <- n - 1   mid <- (n + 1) / 2   mid1 <- mid + 1   midMinus <- mid - 1   y <- rep(NA, m)   y[1:midMinus] <- x[1:midMinus]   y[mid:m] <- x[mid1:n]   return(y)}  ######################################################################################### ########### leapEven  is a function for deleting one value  ############when the period that contains Februaries has a length that is an even number #########################################################################################  leapEven <- function(x){   n <- length(x)   m <- n - 1   mid <- n / 2   y <- rep(NA, m)   mid1 <- mid + 1   mid2 <- mid + 2   midMinus <- mid - 1   y[1:midMinus] <- x[1:midMinus]   y[mid] <- (x[mid] + x[mid1]) / 2   y[mid1:m] <- x[mid2 : n]   return(y) }  ######################################################################################### ####### determines if the length of a vector is an odd number ########################### #########################################################################################  odd <- function(x) {(!(x %% 2) == 0)}  ######################################################################################### ########### calcWY calculates the water year and inserts it into a data frame #########################################################################################   calcWY <- function (df) {   df$WaterYear <- as.integer(df$DecYear)   df$WaterYear[df$Month >= 10] <- df$WaterYear[df$Month >=                                                   10] + 1   return(df) } ######################################################################################### ##### calcCY calculates the climate year and inserts it into a data frame #########################################################################################  calcCY <- function (df){   df$ClimateYear <- as.integer(df$DecYear)   df$ClimateYear[df$Month >= 4] <- df$ClimateYear[df$Month >=                                                      4] + 1   return(df) } ######################################################################################### ######## smoother is a function does the trend in real discharge units and not logs.  ######## It is placed here so that users wanting to run this alternative have it available ######## but it is not actually called by any function in this document #########################################################################################  smoother <- function(xy, window){   edgeAdjust <- TRUE   x <- xy$x   y <- xy$y   n <- length(y)   z <- rep(0,n)   x1 <- x[1]   xn <- x[n]   for (i in 1:n) {     xi <- x[i]     distToEdge <- min((xi - x1), (xn - xi))     close <- (distToEdge < window)     thisWindow <- if (edgeAdjust & close)        (2 * window) - distToEdge     else window     w <- triCube(x - xi, thisWindow)     mod <- lm(xy$y ~ x, weights = w)     new <- data.frame(x = x[i])     z[i] <- predict(mod, new)   }   return(z) }"},{"path":"/articles/streamflow_trend.html","id":"making-a-graph-of-the-trend-in-a-single-flow-statistic","dir":"Articles","previous_headings":"","what":"Making a graph of the trend in a single flow statistic","title":"Daily Streamflow Trend Analysis","text":"Now need run plotFlowTrend function first part code just read . First run simplest form, use entire discharge record period analysis full climatic year. climatic year year starts April 1 ends March 31. default approach tends avoid breaking long-low flow period two segments, one two adjacent years. first run annual minimum daily discharge. use need know index flow statistics used EGRET. called istat statistics represented istat : (1) 1-day minimum, (2) 7-day minimum, (3) 30-day minimum, (4) median (5) mean, (6) 30-day maximum, (7) 7-day maximum, (8) 1-day maximum. run annual minimum daily discharge statistic set istat = 1. run plotFlowTrend function simplest form arguments need eList (contains metadata discharge data), istat. Discharge function Year, slope estimates -0.5% Mann-Kendall p-value 0.785","code":"plotFlowTrend(eList, istat = 1)"},{"path":"/articles/streamflow_trend.html","id":"explanation-of-the-flowtrend-plot-annual-minimum-day","dir":"Articles","previous_headings":"Making a graph of the trend in a single flow statistic","what":"Explanation of the FlowTrend Plot, annual minimum day","title":"Daily Streamflow Trend Analysis","text":"dots indicate discharge minimum day climate year period record. solid curve smoothed representation data. specifically smoother defined EGRET user guide (pages 16-18) 30-year window. record short one (32 years) typically look like straight line smooth curve. longer records can display substantial changes slope even non-monotonic. top graph see two pieces information. trend slope expressed percent per year p-value Mann-Kendall trend test data. slope computed using Thiel-Sen slope estimator. discussed pages 266-274 Helsel Hirsch, 2002, can found although called “Kendall-Theil Robust Line” text. calculated logarithms discharge data transformed express trend percent per year. p-value Mann-Kendall test computed using adjustment serial correlation introduced zyp R package (David Bronaugh Arelia Werner Pacific Climate Impacts Consortium (2013). zyp: Zhang + Yue-Pilon trends package. R package version 0.10-1. https://CRAN.R-project.org/package=zyp).","code":""},{"path":"/articles/streamflow_trend.html","id":"a-few-more-flowtrend-plots","dir":"Articles","previous_headings":"","what":"A few more FlowTrend Plots","title":"Daily Streamflow Trend Analysis","text":"can similar plots. case annual median day istat = 4, annual maximum day istat = 8, annual mean day istat = 5.","code":""},{"path":"/articles/streamflow_trend.html","id":"the-annual-median-day","dir":"Articles","previous_headings":"A few more FlowTrend Plots","what":"The annual median day","title":"Daily Streamflow Trend Analysis","text":"median day computed year record.middle day, 182 values discharges lower 182 values discharges greater (leap year average 183rd 184th ranked values). Everything else first plot. annual median day discharge record. Discharge function Year annual median day","code":"plotFlowTrend(eList, istat = 4)"},{"path":"/articles/streamflow_trend.html","id":"the-annual-maximum-day","dir":"Articles","previous_headings":"A few more FlowTrend Plots","what":"The annual maximum day","title":"Daily Streamflow Trend Analysis","text":"third plot maximum day year. Otherwise exactly construction first two plots. Note maximum daily average discharge general smaller annual peak discharge, maximum instantaneous discharge year, whereas highest daily average discharge. large rivers annual maximum day discharge tends close annual peak discharge can serve rough surrogate trend study. small stream, discharges may rise fall factor 2 course day, maximimum day values can different annual peak discharge. point add one concept, period analysis. first two plots data organized climate year. , look annual maximum annual mean discharge standard approach use water year. need designate want period analysis start month October (month 10). need add one argument call function. paStart = 10. need specify paStart first two plots, default paStart = 4. Notice change period analysis noted text graphic. Discharge function Year annual maximum day fourth plot annual mean discharge. constructed exactly manner previous three, represents mean streamflow days year rather single order statistic minimum, median, maximum. also use water year analysis. Discharge function Year annual mean discharge","code":"plotFlowTrend(eList, istat = 8, paStart = 10) plotFlowTrend(eList, istat = 5, paStart = 10)"},{"path":"/articles/streamflow_trend.html","id":"some-observations-about-these-figures","dir":"Articles","previous_headings":"","what":"Some observations about these figures","title":"Daily Streamflow Trend Analysis","text":"interesting note minimum discharge values trending downwards, although statistically significant trend. three discharge statistics trending upwards notable terms annual maximum daily discharge, terms slope +4.7% per year, p-value well 0.001. raises many questions variability discharge might changing time drivers trends happening various parts probability distribution discharge (commonly call flow duration curve). turn focus way summarizing changes look variations plotFlowTrend graphic.","code":""},{"path":"/articles/streamflow_trend.html","id":"variations-on-the-simplest-example","dir":"Articles","previous_headings":"","what":"Variations on the simplest example","title":"Daily Streamflow Trend Analysis","text":"call function plotFlowTrend many arguments (can see code shown ) just focus may useful data analyst: list optional arguments available user. startDate want evaluate trend shorter period contained entire Daily data frame, can specify different starting date. example, wanted analysis start Water Year 1981, say: startDate = “1980-10-01”. leaving startDate argment requesting analysis start data starts (case 1979-10-01). endDate want evalute trend period ends end data set can specify endDate. wanted end Water Year 2009 say: endDate = “2009-09-30”. paStart starting month period analysis. example interested trends streamflow series months starting August, say paStart = 8. default paStart = 4, starts April. paLong duration period analysis. , analysis covers 12 months paLong = 12 (default). period runs months August - November paStart = 8 paLong = 4. See pages 14 15 user guide detail paStart paLong. window smoothness curve plotted depends size window (measured years). window much smaller (say 10) curve shown rather jagged, becomes longer causes curve converge straight line. default value 30 works well also roughly consistant convention used climate science community, discuss 30-year normal period. precise meaning window described User Guide (pages 16 - 18). effect reported trend slope p-value. qMax argument allows user set maximum value vertical axis. left , graphic scales . set similar graphics may useful set qMax. qUnit argument allows user pick different discharge units. default qUnit = 2 cubic meters per second. common unit use qUnit = 1 cubic feet per second. runoff logical argument. default runoff = FALSE. studies nice express discharge runoff terms (discharge per unit area) amd setting runoff = TRUE can cause expressed terms runoff. example shows use several arguments. Say want see happen looked annual maximum daily discharge 1983 - 2010 (trimming three low years start one high year end), used shorter smoothing window, expressed results runoff mm/day Discharge function year runoff plot worth noting compared previous plot annual maximum daily discharges, removal four particular years brought substantial change slope significance trend. common issue trend analysis relatively short records.","code":"plotFlowTrend(eList, istat, startDate = NA, endDate = NA, paStart = 4, paLong = 12, window = 30, qMax = NA, qUnit = 2, runoff = FALSE) plotFlowTrend(eList, istat = 8, startDate = \"1982-10-01\", endDate = \"2010-09-30\", window = 15, runoff = TRUE)"},{"path":"/articles/streamflow_trend.html","id":"the-quantile-kendall-plot","dir":"Articles","previous_headings":"","what":"The Quantile-Kendall Plot","title":"Daily Streamflow Trend Analysis","text":"Now look new kind plot called Quantile-Kendall plot. plotted point plot trend slope (computed manner previous plots) given order statistic. point far left edge first order statistic, annual minimum daily discharge. result described first plot. next point right trend slope second order statistic (second lowest daily discharge year), continues far right trend slope 365th order statistic (annual maximum daily discharge). placement respect x-axis based z-statistic (standard normal deviate) associated order statistic. called daily non-exceedance probability. scale used convenience. -way assumes data follow particular distribution. simply used provide greatest resolution near tails daily discharge distribution. color represents p value Mann-Kendall test trend described . Red indicates trend significant alpha = 0.05. Black indicates attained significance 0.05 0.1. grey dots trends significant alpha level 0.1. looks like Choptank data set. see generally across probability distribution changes generally statistically significant except highest second highest days year. trends slightly negative low end distribution (lowest 10%). Near median positive modestly large (around 1.5% per year). near 90th percentile drop near zero slope 99th percentile seem particularly large. Quantile-Kendall Plot one special manipulation data needed account leap years (detail computation crucial understanding plots). 366 daily values observed leap year reduced one years 365 values. one value eliminated accomplished replacing two middle values ranked list values single value average two. similar approach used period analysis set months contains month February. number leap year values reduced one reduction takes place median value year.","code":"plotQuantileKendall(eList)"},{"path":"/articles/streamflow_trend.html","id":"variations-on-the-quantile-kendall","dir":"Articles","previous_headings":"","what":"Variations on the Quantile Kendall","title":"Daily Streamflow Trend Analysis","text":"might interested particularly looking trends certain season year. case Choptank know tropical storm generated floods particularly significant later part record mostly August, September October. , interest related flows happening spring early summer, period time delivery Chesapeake Bay (Choptank River flows) might want run analysis period March June. can use paStart = 3 paLong = 4. Quantile-Kendall Plot spring can see portion year, discharge trends rather minimal certainly statistically significant, except 5 highest flow days season show rather large trends annual maximum trend largest (percent per year) one significcant. arguments plotQuantileKendall function. mentioned discussion plotFlowTrend function, startDate endDate arguments. aren’t specified assumed analysis covers whole period Daily data frame. two arguments relate appearance graph. legendLocation argument simply determines graph legend placed. sometimes happens legend obscures data may need move another part graph. argument can take names “bottomleft”, “topright” “bottomright”. default “topleft”. don’t want legend (say making many Quantile Kendall plots single job can’t go adjust one), can specify legendLocation = NA. legendSize argument determines size legend. default legendSize = 1.0. want decrease dimensions legend decrease value. example 25% reduction achieved setting legendSize = 0.75. Typically one wouldn’t want go 0.4. yMax yMin two optional arguments set limits y-axis. don’t specify (just leave ) data dictate minimum maximum values y-axis (extend slightly beyond highest lowest values). , many graphs may want consistent axes, quick look graph tell trends large small, can set two values. example, say want every graph maximum value 5 minimum value -5, arguments just : yMax = 5, yMin = 5. “fail safe” mechanism code trends bigger specified values. Let’s say set yMax = 5 one particular graph trend slope 7.2 % per year. case y-axis extend slightly beyond value 7.2. Thus, value ever range. slopes plotted. example bringing arguments play. case want consider time period 1982-08-01 2010-11-30, months August October, want legend go bottom right half size saw first example. Quantile-Kendall Plot design modifications graph shows us unlike year whole, late summer fall period one substantially increasing discharge. median distribution top, trends greater 3% per year many significant least alpha level 0.1. one feature figure may look odd. fact lower end distribution many trend slopes exactly zero. Using gray dot far left example, trend slope estimation method uses pairwise comparisons lowest discharge year. USGS reporting conventions, many discharge values cluster around specific values, comparisons, many ties. slope estimate median pairwise slopes since significant number slopes zero, slope estimate zero.","code":"plotQuantileKendall(eList, paStart = 3, paLong = 4) plotQuantileKendall(eList, startDate = \"1982-08-01\", endDate = \"2010-11-30\",  paStart = 8, paLong = 3, legendLocation = \"bottomright\", legendSize = 0.5, yMax = 4, yMin = -4)"},{"path":"/articles/streamflow_trend.html","id":"putting-it-all-together-into-a-set-of-five-graphs","dir":"Articles","previous_headings":"","what":"Putting it all together into a set of five graphs","title":"Daily Streamflow Trend Analysis","text":"post also provides additional function produces total five graphics single command. four trend plots Quantile-Kendall. called plotFiveTrendGraphs. arguments ones seen : eList, startDate, endDate, paStart, paLong, qUnit, window, legendLocation, legendSize. simplest form look like (output plotted ).","code":"plotFiveTrendGraphs(eList)"},{"path":"/articles/streamflow_trend.html","id":"downloading-the-data-for-your-site-of-interest","dir":"Articles","previous_headings":"","what":"Downloading the data for your site of interest","title":"Daily Streamflow Trend Analysis","text":"steps downloading data USGS web services (obtaining user supplied information) also creating saving eList described pages 4-13 EGRET user guide. simple example: Say want look USGS station number 01646500 (Sugar River near Brodhead, WI) want consider data Climate Years 1921 2016. Note much longer period record causes computations take good deal time previous cases, still take well minute complete whole job. following commands needed. Quantile-Kendall Plots Sugar River near Brodhead, WI Quantile-Kendall Plots Sugar River near Brodhead, WI Quantile-Kendall Plots Sugar River near Brodhead, WI Quantile-Kendall Plots Sugar River near Brodhead, WI Quantile-Kendall Plots Sugar River near Brodhead, WI","code":"library(EGRET) sta <- \"05436500\" param <- \"00060\" # this is the parameter code for daily discharge startDate <- \"1920-04-01\" endDate <- \"2016-03-31\" INFO <- readNWISInfo(siteNumber = sta, parameterCd = param, interactive = FALSE) Daily <- readNWISDaily(siteNumber = sta, parameterCd = param, startDate = startDate,  endDate = endDate, verbose =  FALSE) eList <- as.egret(INFO, Daily) plotFiveTrendGraphs(eList, legendLocation = \"bottomleft\")"},{"path":"/articles/streamflow_trend.html","id":"final-thoughts","dir":"Articles","previous_headings":"","what":"Final thoughts","title":"Daily Streamflow Trend Analysis","text":"last set plots particularly interesting. see lowest 90 percent distribution, discharges rising record, particularly since 1950. highest 1% distribution discharges falling thoughout record. consequence overall variablity streamflow agricultural watershed generally declining time. generally thought related increasing use conservation practices watershed. worth noting can express percentage changes per year ways percent per year, example percentage change per decade percentage change entire period record. Take, example, estimated trend slope median last example. 0.68% per year. express percentage change per decade 7% per decade (change can computed 1.0068^10, 1.070, 7% increase). expressed entire 96 year record 92% increase period (computed 1.0068^96, 1.9167 increase 92%). graphical tools one way summarizing might call signature change given watershed. shows changes, lack changes, taken place parts probability distribution streamflow. potential tool evaluating hydrologic linked climate hydrologic models. Observing patterns graphs actual data versus patterns seen simulated data used, can provide insights ability models used project hydrologic changes future.","code":""},{"path":"/articles/units.html","id":"streamflow","dir":"Articles","previous_headings":"","what":"Streamflow","title":"Custom Axis Labels","text":"Streamflow values stored m^3/s. plots tables display discharge data, user-argument functions called qUnit. input can numeric 1 4, can one following text: “cfs”, “cms”, “thousandCfs”, “thousandCms”. numeric lines text can seen printqUnitCheatSheet function: example using default (qUnit = 2 corresonds “cms”), compared using qUnit = 1 (corresponding “cfs”): Plots discharge different units.","code":"printqUnitCheatSheet() ## The following codes apply to the qUnit list: ## 1 =  cfs  ( Cubic Feet per Second ) ## 2 =  cms  ( Cubic Meters per Second ) ## 3 =  thousandCfs  ( Thousand Cubic Feet per Second ) ## 4 =  thousandCms  ( Thousand Cubic Meters per Second ) eList <- Choptank_eList plotConcQ(eList) plotConcQ(eList, qUnit = 1)"},{"path":"/articles/units.html","id":"custom-units","dir":"Articles","previous_headings":"Streamflow","what":"Custom Units","title":"Custom Axis Labels","text":"scenario EGRET analysis done using streamflow value. example, let’s say want use precipitation substitution discharge. important point use data designed EGRET software, probably make sense use flux calculations. , places EGRET graphs tables interesting using alternative data. example make custom qUnit object. simple adding single line text. software needs know create nice labels variety different kind plots, conversion factor, need know conversion factor. example shows make custom qUnit precipitation millimeters unit: “slot” qUnit object required, qShortName, qUnitName, unitUSGS, prefix must characters. qUnitFactor must numeric (conversion factor data gets multiplied ). qUnitExpress qUnitTiny “expressions” allows text formatted. use custom unit: Plot custom axis, using precipitation instead discharge.","code":"qConst_precip <- new(\"qUnit\",                      qShortName = \"   mm  \",                      qUnitFactor = 1,                      qUnitName = \"Millimeter\",                      qUnitExpress = expression(paste(\"Precipitation in \",mm)),                      qUnitTiny = expression(paste(\"Precipitation \", \"(\", mm, \")\")),                      shortCode = 1,                      unitUSGS = \"Precipitation, in mm\",                      prefix = \"Precipitation\") plotConcQ(eList, qUnit = qConst_precip)"},{"path":"/articles/units.html","id":"data-input","dir":"Articles","previous_headings":"Streamflow","what":"Data input","title":"Custom Axis Labels","text":"values can used input data, data converted m^3/s qUnit argument eList created. data coming cubic feet per second, use readDailyUser function, specify qUnit = 1. take cfs data, store properly cms.","code":""},{"path":"/articles/units.html","id":"concentration","dir":"Articles","previous_headings":"","what":"Concentration","title":"Custom Axis Labels","text":"Concentration values stored mg/l. option comes default EGRET. However, can change unit display using eList$INFO$param.units (conversion options however). can also create custom concUnit shown :","code":"eList$INFO$param.units <- \"ng\"  deposition <- new(\"concUnit\",                   longPrefix = \"Deposition\",                   shortPrefix = \"Dep\")  plotConcQ(eList,            qUnit = qConst_precip,           concLab = deposition)"},{"path":"/articles/units.html","id":"flux","dir":"Articles","previous_headings":"","what":"Flux","title":"Custom Axis Labels","text":"variety units flux can used. plots tables display flux data, user-argument functions called fluxUnit. input can numeric 1 13, can one following text: numeric lines text can seen printFluxUnitCheatSheet function: comparison default values specified flux unit. Plots flux different units. example make custom fluxUnit object. simple adding single line text. software needs know create nice labels variety different kind plots, conversion factor, need know conversion factor. example shows make custom fluxUnit grams per day:","code":"names(fluxConst) ##  [1] \"poundsDay\"        \"tonsDay\"          \"kgDay\"            \"thousandKgDay\"    ##  [5] \"tonsYear\"         \"thousandTonsYear\" \"millionTonsYear\"  \"thousandKgYear\"   ##  [9] \"millionKgYear\"    \"billionKgYear\"    \"thousandTonsDay\"  \"millionKgDay\"     ## [13] \"kgYear\" printFluxUnitCheatSheet() ## The following codes apply to the fluxUnit list: ## 1 =  poundsDay  ( pounds/day ) ## 2 =  tonsDay  ( tons/day ) ## 3 =  kgDay  ( kg/day ) ## 4 =  thousandKgDay  ( thousands of kg/day ) ## 5 =  tonsYear  ( tons/year ) ## 6 =  thousandTonsYear  ( thousands of tons/year ) ## 7 =  millionTonsYear  ( millions of tons/year ) ## 8 =  thousandKgYear  ( thousands of kg/year ) ## 9 =  millionKgYear  ( millions of kg/year ) ## 10 =  billionKgYear  ( billions of kg/year ) ## 11 =  thousandTonsDay  ( thousands of tons/day ) ## 12 =  millionKgDay  ( millions of kg/day ) ## 13 =  kgYear  ( kg/year ) plotFluxHist(eList) plotFluxHist(eList, fluxUnit = 2) gDay <- new(\"fluxUnit\",              shortName = \"    g/day   \",              unitFactor = 1000,              unitName = \"g/day\",              unitExpress = expression(\"Flux in g/day\"),              unitExpressTiny = expression(\"Flux (g/day)\"),              unitEstimate = expression(\"flux in g/year\"),              unitEstimateTiny = expression(\"Est. flux in g/day\"),              unitUSGS = \"Flux, in grams per day\",              shortCode = 14)  plotFluxHist(eList, fluxUnit = gDay)"},{"path":"/articles/units.html","id":"month","dir":"Articles","previous_headings":"","what":"Month","title":"Custom Axis Labels","text":"also way customize way months displayed. might useful non-English speaking users instance. Although don’t capacity conversion text, come handy: Concentration month.","code":"spanish_month <- new(\"monthLabel\",          monthAbbrev = c(\"enero\",   \"feb\",  \"marzo\", \"abr\",                          \"mayo\",    \"jun\",  \"jul\", \"agosto\", \"set\",                          \"oct\", \"nov\", \"dic\"),          monthFull = c(\"enero\", \"febrero\",  \"marzo\", \"abril\",                        \"mayo\",  \"junio\",    \"julio\", \"agosto\", \"septiembre\",                        \"octubre\",   \"noviembre\", \"diciembre\"),          monthSingle = c(\"E\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\",                          \"A\", \"S\", \"O\", \"N\", \"D\"))  eList$INFO$param.units <- \"mg/L\"  concentration_esp <- new(\"concUnit\",                          longPrefix = \"Concentración\",                          shortPrefix = \"conc.\")  boxConcMonth(eList, printTitle = FALSE, showXLabels = FALSE,              monthLab = spanish_month, concLab = concentration_esp)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Hirsch. Author. Laura DeCicco. Author, maintainer. Tim Cohn. Contributor. David Watkins. Contributor. Lindsay Carr. Contributor. Jennifer Murphy. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hirsch, R.M., De Cicco, L.., 2015, User guide Exploration Graphics RivEr Trends (EGRET) dataRetrieval: R packages hydrologic data (version 2.0, February 2015): U.S. Geological Survey Techniques Methods book 4, chap. A10, 93 p., doi:10.3133/tm4A10","code":"@InBook{,   author = {Robert M. Hirsch and Laura A. {De Cicco}},   title = {User guide to Exploration and Graphics for RivEr Trends (EGRET) and dataRetrieval: R packages for hydrologic data},   publisher = {U.S. Geological Survey},   address = {Reston, VA},   booktitle = {Techniques and Methods},   institution = {U.S. Geological Survey},   year = {2015},   chapter = {A10},   url = {https://pubs.usgs.gov/tm/04/a10/}, }"},{"path":"/index.html","id":"egret-","dir":"","previous_headings":"","what":"Exploration and Graphics for RivEr Trends","title":"Exploration and Graphics for RivEr Trends","text":"Exploration Graphics RivEr Trends (EGRET): R-package analysis long-term changes water quality streamflow, including water-quality method Weighted Regressions Time, Discharge, Season (WRTDS). Look new improved documentation : https://rconnect.usgs.gov/EGRET/ link official USGS publication user guide : https://pubs.usgs.gov/tm/04/a10/ companion package EGRETci implements set approaches analysis uncertainty associated WRTDS trend analysis. familiar traditional EGRET workflow, check Overview Updates see latest updates relate. Recent introduction WRTDS EGRET package 12th National Monitoring Conference April 19, 2021: New capabilities","code":""},{"path":"/index.html","id":"package-installation","dir":"","previous_headings":"","what":"Package Installation","title":"Exploration and Graphics for RivEr Trends","text":"install EGRET package, must using R 3.0 greater run following command:","code":"install.packages(\"EGRET\")"},{"path":"/index.html","id":"background","dir":"","previous_headings":"","what":"Background:","title":"Exploration and Graphics for RivEr Trends","text":"Evaluating long-term changes river conditions (water quality discharge) important use hydrologic data. carry evaluations, hydrologist needs tools facilitate several key steps process: acquiring data records variety sources, structuring ways facilitate analysis, routines process data extract information changes may happening, graphical techniques can display findings change. R package EGRET (Exploration Graphics RivEr Trends) developed carrying steps integrated manner. designed accept easily data three sources: U.S. Geological Survey hydrologic data, Water Quality Portal Data (currently including U.S. Environmental Protection Agency (EPA) STORET data, USDA STEWARDS data), user-supplied flat files. EGRET package components oriented towards description long-term changes streamflow statistics (high flow, average flow, low flow) well changes water quality. water-quality analysis, uses Weighted Regressions Time, Discharge Season (WRTDS) describe long-term trends concentration flux. EGRET also creates wide range graphical presentations water-quality data WRTDS results. following report serves user guide, providing detailed guidance installation use software, documentation analysis methods used, well guidance kinds questions approaches software can facilitate. EGRET includes statistics graphics streamflow history, water quality trends, statistical modeling algorithm Weighted Regressions Time, Discharge, Season (WRTDS). Please see official EGRET User Guide information EGRET package: https://doi.org/10.3133/tm4A10 best ways learn WRTDS approach read User Guide two journal articles. articles available, free, journals published. first relates nitrate total phosphorus data 9 rivers draining Chesapeake Bay. URL : https://onlinelibrary.wiley.com/doi/full/10.1111/j.1752-1688.2010.00482.x. second application nitrate data 8 monitoring sites Mississippi River major tributaries. URL : https://pubs.acs.org/doi/abs/10.1021/es201221s thorough discussion generalized flow normalization method implemented EGRET enhancements, see paper: “Tracking changes nutrient delivery western Lake Erie: Approaches compensate variability trends streamflow”: (https://www.sciencedirect.com/science/article/pii/S0380133018302235).","code":""},{"path":"/index.html","id":"sample-workflow","dir":"","previous_headings":"","what":"Sample Workflow","title":"Exploration and Graphics for RivEr Trends","text":"WRTDS Choptank River Greensboro MD, Nitrate:","code":"library(EGRET)  ############################ # Gather discharge data: siteID <- \"01491000\" #Choptank River at Greensboro, MD startDate <- \"\" #Gets earliest date endDate <- \"2011-09-30\" # Gather sample data: parameter_cd<-\"00631\" #5 digit USGS code Sample <- readNWISSample(siteID,parameter_cd,startDate,endDate) #Gets earliest date from Sample record: #This is just one of many ways to assure the Daily record #spans the Sample record startDate <- min(as.character(Sample$Date))  # Gather discharge data: Daily <- readNWISDaily(siteID,\"00060\",startDate,endDate) # Gather site and parameter information:  # Here user must input some values for # the default (interactive=TRUE) INFO<- readNWISInfo(siteID,parameter_cd) INFO$shortName <- \"Choptank River at Greensboro, MD\"  # Merge discharge with sample data: eList <- mergeReport(INFO, Daily, Sample) library(EGRET) # Sample data included in package: eList <- Choptank_eList  boxConcMonth(eList) boxQTwice(eList) plotConcTime(eList) plotConcQ(eList) multiPlotDataOverview(eList) # Run WRTDS model: eList <- modelEstimation(eList) #>  #>  first step running estCrossVal may take about 1 minute #>  estCrossVal % complete: #> 0    1   2   3   4   5   6   7   8   9   10   #> 11   12  13  14  15  16  17  18  19  20   #> 21   22  23  24  25  26  27  28  29  30   #> 31   32  33  34  35  36  37  38  39  40   #> 41   42  43  44  45  46  47  48  49  50   #> 51   52  53  54  55  56  57  58  59  60   #> 61   62  63  64  65  66  67  68  69  70   #> 71   72  73  74  75  76  77  78  79  80   #> 81   82  83  84  85  86  87  88  89  90   #> 91   92  93  94  95  96  97  98  99   #> Next step running  estSurfaces with survival regression: #> Survival regression (% complete): #> 0    1   2   3   4   5   6   7   8   9   10   #> 11   12  13  14  15  16  17  18  19  20   #> 21   22  23  24  25  26  27  28  29  30   #> 31   32  33  34  35  36  37  38  39  40   #> 41   42  43  44  45  46  47  48  49  50   #> 51   52  53  54  55  56  57  58  59  60   #> 61   62  63  64  65  66  67  68  69  70   #> 71   72  73  74  75  76  77  78  79  80   #> 81   82  83  84  85  86  87  88  89  90   #> 91   92  93  94  95  96  97  98  99   #> Survival regression: Done  #eList: plotConcTimeDaily(eList) plotFluxTimeDaily(eList) plotConcPred(eList) plotFluxPred(eList) plotResidPred(eList) plotResidQ(eList) plotResidTime(eList) boxResidMonth(eList) boxConcThree(eList) plotConcHist(eList) plotFluxHist(eList) # Multi-line plots: date1 <- \"1985-09-01\" date2 <- \"1997-09-01\" date3 <- \"2010-09-01\" qBottom<-0.2 qTop<-10 plotConcQSmooth(eList, date1, date2, date3, qBottom, qTop,                     concMax=2,legendTop = 0.85) q1 <- 2 q2 <- 10 q3 <- 20 centerDate <- \"07-01\" yearEnd <- 1980 yearStart <- 2010 plotConcTimeSmooth(eList, q1, q2, q3, centerDate, yearStart, yearEnd, legendTop = 0.55, legendLeft = 1990) # Multi-plots: fluxBiasMulti(eList) #Contour plots: clevel<-seq(0,2,0.5) yearStart <- 1980 yearEnd <- 2010  plotContours(eList, yearStart,yearEnd,qBottom=0.5,              qTop = 20, contourLevels = clevel) plotDiffContours(eList, year0 = 1990,                  year1 = 2010,                  qBottom = 0.5,                  qTop = 20,                  maxDiff = 0.6)"},{"path":"/index.html","id":"sample-workflow-for-a-flowhistory-application-for-the-entire-record","dir":"","previous_headings":"Sample Workflow","what":"Sample workflow for a flowHistory application for the entire record","title":"Exploration and Graphics for RivEr Trends","text":"","code":"library(EGRET)  # Flow history analysis # Gather discharge data: siteID <- \"01491000\" #Choptank River at Greensboro, MD startDate <- \"\" # Get earliest date endDate <- \"\" # Get latest date Daily <- readNWISDaily(siteID, \"00060\", startDate, endDate) #> There are 27371 data points, and 27371 days. # Gather site and parameter information: # Here user must input some values for # the default (interactive=TRUE) INFO <- readNWISInfo(siteID, \"00060\") #> Your site for streamflow data is: #>  01491000 . #> Your site name is CHOPTANK RIVER NEAR GREENSBORO, MD  #> but you can modify this to a short name in a style you prefer.  #> This name will be used to label graphs and tables.  #> If you want the program to use the name given above, just do a carriage return, #> otherwise enter the preferred short name(no quotes): #>  #> The latitude and longitude of the site are:  38.99719 ,  -75.78581 (degrees north and west). #>  #> The drainage area at this site is  113 square miles #>  which is being stored as 292.6687 square kilometers. #>  #> It is helpful to set up a station abbreviation when doing multi-site studies, #> enter a unique id (three or four characters should work). It is case sensitive.   #> Even if you don't feel you need an abbreviation for your site you need to enter something(no quotes): #>  #> Your water quality data are for parameter number: #> 00060  #> which has the name:' Discharge, cubic feet per second '. #> Typically you will want a shorter name to be used in graphs and tables. #> The suggested short name is:' Stream flow, mean. daily '. #> If you would like to change the short name, enter it here,  #> otherwise just hit enter (no quotes): #> The units for the water quality data are:  ft3/s . #> It is helpful to set up a constiuent abbreviation, enter a unique id  #> three or four characters should work something like tn or tp or NO3). #> Even if you don't feel you need an abbreviation you need to enter something (no quotes): #>  #> Required concentration units are mg/l.  #> The INFO dataframe indicates: ft3/s  #> Flux calculations will be wrong if units are not consistent. INFO$shortName <- \"Choptank River at Greensboro, MD\" eList <- as.egret(INFO, Daily, NA, NA)  # Check flow history data: plotFlowSingle(eList, istat = 7,qUnit = \"thousandCfs\") plotSDLogQ(eList) plotQTimeDaily(eList, qLower = 1, qUnit = 3) plotFour(eList, qUnit=3) plotFourStats(eList, qUnit=3)"},{"path":"/index.html","id":"model-archive","dir":"","previous_headings":"","what":"Model Archive","title":"Exploration and Graphics for RivEr Trends","text":"using WRTDS model, important able reproduce results future. following version R package dependencies used recently pass embedded tests within package. guarantee reproducible results using future versions R updated versions package dependencies; however, make diligent efforts test update future modeling environments.","code":"sessioninfo::session_info() #> ─ Session info ─────────────────────────────────────────────────────────────── #>  setting  value #>  version  R version 4.2.2 (2022-10-31 ucrt) #>  os       Windows 10 x64 (build 19044) #>  system   x86_64, mingw32 #>  ui       RTerm #>  language (EN) #>  collate  English_United States.utf8 #>  ctype    English_United States.utf8 #>  tz       America/Chicago #>  date     2022-12-09 #>  pandoc   2.19.2 @ C:/Program Files/RStudio/bin/quarto/bin/tools/ (via rmarkdown) #>  #> ─ Packages ─────────────────────────────────────────────────────────────────── #>  package       * version date (UTC) lib source #>  assertthat      0.2.1   2019-03-21 [1] CRAN (R 4.2.1) #>  bit             4.0.5   2022-11-15 [1] CRAN (R 4.2.2) #>  bit64           4.0.5   2020-08-30 [1] CRAN (R 4.2.2) #>  class           7.3-20  2022-01-16 [2] CRAN (R 4.2.2) #>  classInt        0.4-8   2022-09-29 [1] CRAN (R 4.2.1) #>  cli             3.4.1   2022-09-23 [1] CRAN (R 4.2.1) #>  colorspace      2.0-3   2022-02-21 [1] CRAN (R 4.2.1) #>  crayon          1.5.2   2022-09-29 [1] CRAN (R 4.2.1) #>  curl            4.3.3   2022-10-06 [1] CRAN (R 4.2.1) #>  dataRetrieval   2.7.12  2022-12-08 [1] local #>  DBI             1.1.3   2022-06-18 [1] CRAN (R 4.2.1) #>  digest          0.6.30  2022-10-18 [1] CRAN (R 4.2.2) #>  dotCall64       1.0-2   2022-10-03 [1] CRAN (R 4.2.1) #>  dplyr           1.0.10  2022-09-01 [1] CRAN (R 4.2.1) #>  e1071           1.7-12  2022-10-24 [1] CRAN (R 4.2.2) #>  EGRET         * 3.0.7.3 2022-09-23 [1] local #>  ellipsis        0.3.2   2021-04-29 [1] CRAN (R 4.2.1) #>  evaluate        0.18    2022-11-07 [1] CRAN (R 4.2.2) #>  fansi           1.0.3   2022-03-24 [1] CRAN (R 4.2.1) #>  fastmap         1.1.0   2021-01-25 [1] CRAN (R 4.2.1) #>  fields          14.1    2022-08-12 [1] CRAN (R 4.2.1) #>  generics        0.1.3   2022-07-05 [1] CRAN (R 4.2.1) #>  ggplot2         3.4.0   2022-11-04 [1] CRAN (R 4.2.2) #>  glue            1.6.2   2022-02-24 [1] CRAN (R 4.1.3) #>  gridExtra       2.3     2017-09-09 [1] CRAN (R 4.2.1) #>  gtable          0.3.1   2022-09-01 [1] CRAN (R 4.2.1) #>  highr           0.9     2021-04-16 [1] CRAN (R 4.2.1) #>  hms             1.1.2   2022-08-19 [1] CRAN (R 4.2.1) #>  htmltools       0.5.4   2022-12-07 [1] CRAN (R 4.2.2) #>  httr            1.4.4   2022-08-17 [1] CRAN (R 4.2.2) #>  KernSmooth      2.23-20 2021-05-03 [2] CRAN (R 4.2.2) #>  knitr           1.41    2022-11-18 [1] CRAN (R 4.2.2) #>  lattice         0.20-45 2021-09-22 [2] CRAN (R 4.2.2) #>  lifecycle       1.0.3   2022-10-07 [1] CRAN (R 4.2.1) #>  magrittr        2.0.3   2022-03-30 [1] CRAN (R 4.1.3) #>  maps            3.4.1   2022-10-30 [1] CRAN (R 4.2.2) #>  Matrix          1.5-3   2022-11-11 [1] CRAN (R 4.2.2) #>  munsell         0.5.0   2018-06-12 [1] CRAN (R 4.2.1) #>  pillar          1.8.1   2022-08-19 [1] CRAN (R 4.2.1) #>  pkgconfig       2.0.3   2019-09-22 [1] CRAN (R 4.2.1) #>  proxy           0.4-27  2022-06-09 [1] CRAN (R 4.2.1) #>  R6              2.5.1   2021-08-19 [1] CRAN (R 4.2.1) #>  Rcpp            1.0.9   2022-07-08 [1] CRAN (R 4.2.1) #>  readr           2.1.3   2022-10-01 [1] CRAN (R 4.2.1) #>  rlang           1.0.6   2022-09-24 [1] CRAN (R 4.2.1) #>  rmarkdown       2.18    2022-11-09 [1] CRAN (R 4.2.2) #>  rstudioapi      0.14    2022-08-22 [1] CRAN (R 4.2.1) #>  scales          1.2.1   2022-08-20 [1] CRAN (R 4.2.1) #>  sessioninfo     1.2.2   2021-12-06 [1] CRAN (R 4.2.1) #>  sf              1.0-9   2022-11-08 [1] CRAN (R 4.2.2) #>  spam            2.9-1   2022-08-07 [1] CRAN (R 4.2.1) #>  stringi         1.7.8   2022-07-11 [1] CRAN (R 4.2.1) #>  stringr         1.5.0   2022-12-02 [1] CRAN (R 4.2.2) #>  survival        3.4-0   2022-08-09 [1] CRAN (R 4.2.1) #>  tibble          3.1.8   2022-07-22 [1] CRAN (R 4.2.1) #>  tidyselect      1.2.0   2022-10-10 [1] CRAN (R 4.2.1) #>  tzdb            0.3.0   2022-03-28 [1] CRAN (R 4.2.1) #>  units           0.8-0   2022-02-05 [1] CRAN (R 4.2.1) #>  utf8            1.2.2   2021-07-24 [1] CRAN (R 4.2.1) #>  vctrs           0.5.1   2022-11-16 [1] CRAN (R 4.2.2) #>  viridis         0.6.2   2021-10-13 [1] CRAN (R 4.2.1) #>  viridisLite     0.4.1   2022-08-22 [1] CRAN (R 4.2.1) #>  vroom           1.6.0   2022-09-30 [1] CRAN (R 4.2.1) #>  xfun            0.35    2022-11-16 [1] CRAN (R 4.2.2) #>  yaml            2.3.6   2022-10-18 [1] CRAN (R 4.2.1) #>  #>  [1] C:/Users/ldecicco/Documents/R/win-library/4.2 #>  [2] C:/Program Files/R/R-4.2.2/library #>  #> ──────────────────────────────────────────────────────────────────────────────"},{"path":"/index.html","id":"reporting-bugs","dir":"","previous_headings":"","what":"Reporting bugs","title":"Exploration and Graphics for RivEr Trends","text":"Please consider reporting bugs asking questions Issues page: https://github.com/USGS-R/EGRET/issues","code":""},{"path":"/index.html","id":"subscribe","dir":"","previous_headings":"","what":"Subscribe","title":"Exploration and Graphics for RivEr Trends","text":"Please email questions, comments, feedback : egret_comments@usgs.gov Additionally, subscribe email list concerning updates R packages, please send request egret_comments@usgs.gov.","code":""},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Exploration and Graphics for RivEr Trends","text":"want encourage warm, welcoming, safe environment contributing project. See code conduct information.","code":""},{"path":"/index.html","id":"package-support","dir":"","previous_headings":"","what":"Package Support","title":"Exploration and Graphics for RivEr Trends","text":"Water Mission Area USGS supported development maintenance EGRET R-package. maintenance expected stable October 2024. Resources available primarily maintenance responding user questions. Priorities development new features determined EGRET development team.","code":""},{"path":"/index.html","id":"sunset-date","dir":"","previous_headings":"","what":"Sunset date","title":"Exploration and Graphics for RivEr Trends","text":"Funding EGRET currently expires fall 2024. Expectations maintenance customer service continue supported past date.","code":""},{"path":"/index.html","id":"how-to-cite-egret","dir":"","previous_headings":"","what":"How to cite EGRET:","title":"Exploration and Graphics for RivEr Trends","text":"","code":"citation(package = \"EGRET\") #>  #> To cite EGRET in publications, please use: #>  #>   Hirsch, R.M., and De Cicco, L.A., 2015, User guide to Exploration and #>   Graphics for RivEr Trends (EGRET) and dataRetrieval: R packages for #>   hydrologic data (version 2.0, February 2015): U.S. Geological Survey #>   Techniques and Methods book 4, chap. A10, 93 p., doi:10.3133/tm4A10 #>  #> A BibTeX entry for LaTeX users is #>  #>   @InBook{, #>     author = {Robert M. Hirsch and Laura A. {De Cicco}}, #>     title = {User guide to Exploration and Graphics for RivEr Trends (EGRET) and dataRetrieval: R packages for hydrologic data}, #>     publisher = {U.S. Geological Survey}, #>     address = {Reston, VA}, #>     booktitle = {Techniques and Methods}, #>     institution = {U.S. Geological Survey}, #>     year = {2015}, #>     chapter = {A10}, #>     url = {https://pubs.usgs.gov/tm/04/a10/}, #>   }"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Exploration and Graphics for RivEr Trends","text":"See list WRTDS applications print: https://rconnect.usgs.gov/EGRET/articles/References_WRTDS.html","code":""},{"path":"/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Exploration and Graphics for RivEr Trends","text":"software approved release U.S. Geological Survey (USGS). Although software subjected rigorous review, USGS reserves right update software needed pursuant analysis review. warranty, expressed implied, made USGS U.S. Government functionality software related material shall fact release constitute warranty. Furthermore, software released condition neither USGS U.S. Government shall held liable damages resulting authorized unauthorized use.","code":""},{"path":"/reference/Constants.html","id":null,"dir":"Reference","previous_headings":"","what":"Constants included with EGRET — Constants","title":"Constants included with EGRET — Constants","text":"fluxConstFlux conversion object qConstFlow conversion object monthInfoMonth object","code":""},{"path":"/reference/Constants.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constants included with EGRET — Constants","text":"","code":"fluxConst #> $poundsDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   lbs/day  \" #>  #> Slot \"unitFactor\": #> [1] 2.204623 #>  #> Slot \"unitName\": #> [1] \"pounds/day\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in pounds/day\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (lbs/d)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in pounds/day\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux (lbs/d)\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in pounds per day\" #>  #> Slot \"shortCode\": #> [1] 1 #>  #>  #> $tonsDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   tons/day  \" #>  #> Slot \"unitFactor\": #> [1] 0.001102 #>  #> Slot \"unitName\": #> [1] \"tons/day\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in tons/day\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (tons/d)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in tons/day\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux (tons/d)\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in tons per day\" #>  #> Slot \"shortCode\": #> [1] 2 #>  #>  #> $kgDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"    kg/day  \" #>  #> Slot \"unitFactor\": #> [1] 1 #>  #> Slot \"unitName\": #> [1] \"kg/day\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in kg/day\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (kg/d)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in kg/day\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux (kg/d)\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in kilograms per day\" #>  #> Slot \"shortCode\": #> [1] 3 #>  #>  #> $thousandKgDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \" 10^3 kg/day\" #>  #> Slot \"unitFactor\": #> [1] 0.001 #>  #> Slot \"unitName\": #> [1] \"thousands of kg/day\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^3 * kg/day)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^3 * kg/d, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^3 * kg/day)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^3 * kg/d, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in thousands of kilograms per day\" #>  #> Slot \"shortCode\": #> [1] 4 #>  #>  #> $tonsYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   tons/yr  \" #>  #> Slot \"unitFactor\": #> [1] 0.402619 #>  #> Slot \"unitName\": #> [1] \"tons/year\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in tons/year\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (tons/yr)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in tons/year\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux (tons/yr)\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in tons per year\" #>  #> Slot \"shortCode\": #> [1] 5 #>  #>  #> $thousandTonsYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"  10^3 tons/yr\" #>  #> Slot \"unitFactor\": #> [1] 0.000402619 #>  #> Slot \"unitName\": #> [1] \"thousands of tons/year\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^3 * tons/yr)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^3 * tons/yr, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^3 * tons/yr)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^3 * tons/yr, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in thousands of tons per year\" #>  #> Slot \"shortCode\": #> [1] 6 #>  #>  #> $millionTonsYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"  10^6 tons/yr\" #>  #> Slot \"unitFactor\": #> [1] 4.02619e-07 #>  #> Slot \"unitName\": #> [1] \"millions of tons/year\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^6 * tons/yr)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^6 * tons/yr, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^6 * tons/yr)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^6 * tons/yr, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in millions of tons per year\" #>  #> Slot \"shortCode\": #> [1] 7 #>  #>  #> $thousandKgYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   10^3 kg/yr\" #>  #> Slot \"unitFactor\": #> [1] 0.36525 #>  #> Slot \"unitName\": #> [1] \"thousands of kg/year\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^3 * kg/yr)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^3 * kg/yr, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^3 * kg/yr)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^3 * kg/yr, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in thousands of kilograms per year\" #>  #> Slot \"shortCode\": #> [1] 8 #>  #>  #> $millionKgYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   10^6 kg/yr\" #>  #> Slot \"unitFactor\": #> [1] 0.00036525 #>  #> Slot \"unitName\": #> [1] \"millions of kg/year\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^6 * kg/yr)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^6 * kg/yr, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^6 * kg/yr)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^6 * kg/yr, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in millions of kilograms per year\" #>  #> Slot \"shortCode\": #> [1] 9 #>  #>  #> $billionKgYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   10^9 kg/yr\" #>  #> Slot \"unitFactor\": #> [1] 3.6525e-07 #>  #> Slot \"unitName\": #> [1] \"billions of kg/year\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in\", 10^9 * kg/yr)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^9 * kg/yr, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in\", 10^9 * kg/yr)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^9 * kg/yr, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in billions of kilograms per year\" #>  #> Slot \"shortCode\": #> [1] 10 #>  #>  #> $thousandTonsDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \" 10^3 tons/day\" #>  #> Slot \"unitFactor\": #> [1] 1.102e-06 #>  #> Slot \"unitName\": #> [1] \"thousands of tons/day\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^3 * tons/day)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^3 * tons/d, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^3 * tons/day)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^3 * tons/d, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in thousands of tons per day\" #>  #> Slot \"shortCode\": #> [1] 11 #>  #>  #> $millionKgDay #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"   10^6 kg/day\" #>  #> Slot \"unitFactor\": #> [1] 1e-06 #>  #> Slot \"unitName\": #> [1] \"millions of kg/day\" #>  #> Slot \"unitExpress\": #> expression(paste(\"Flux in \", 10^6 * kg/day)) #>  #> Slot \"unitExpressTiny\": #> expression(paste(\"Flux \", \"(\", 10^6 * kg/d, \")\")) #>  #> Slot \"unitEstimate\": #> expression(paste(\"flux in \", 10^6 * kg/day)) #>  #> Slot \"unitEstimateTiny\": #> expression(paste(\"Est. flux \", \"(\", 10^6 * kg/d, \")\")) #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in millions of kilograms per day\" #>  #> Slot \"shortCode\": #> [1] 12 #>  #>  #> $kgYear #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"    kg/yr   \" #>  #> Slot \"unitFactor\": #> [1] 365.25 #>  #> Slot \"unitName\": #> [1] \"kg/year\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in kg/year\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (kg/yr)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in kg/year\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux in kg/yr\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in kilograms per year\" #>  #> Slot \"shortCode\": #> [1] 13 #>  #>  fluxConst[['kgDay']] #> An object of class \"fluxUnit\" #> Slot \"shortName\": #> [1] \"    kg/day  \" #>  #> Slot \"unitFactor\": #> [1] 1 #>  #> Slot \"unitName\": #> [1] \"kg/day\" #>  #> Slot \"unitExpress\": #> expression(\"Flux in kg/day\") #>  #> Slot \"unitExpressTiny\": #> expression(\"Flux (kg/d)\") #>  #> Slot \"unitEstimate\": #> expression(\"flux in kg/day\") #>  #> Slot \"unitEstimateTiny\": #> expression(\"Est. flux (kg/d)\") #>  #> Slot \"unitUSGS\": #> [1] \"Flux, in kilograms per day\" #>  #> Slot \"shortCode\": #> [1] 3 #>  fluxConst[['kgDay']]@unitName #> [1] \"kg/day\" qConst #> $cfs #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"   cfs  \" #>  #> Slot \"qUnitFactor\": #> [1] 35.31467 #>  #> Slot \"qUnitName\": #> [1] \"Cubic Feet per Second\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", ft^3/s)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", ft^3/s, \")\")) #>  #> Slot \"shortCode\": #> [1] 1 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in cubic feet per second\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  #>  #> $cms #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"   cms  \" #>  #> Slot \"qUnitFactor\": #> [1] 1 #>  #> Slot \"qUnitName\": #> [1] \"Cubic Meters per Second\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", m^3/s)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", m^3/s, \")\")) #>  #> Slot \"shortCode\": #> [1] 2 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in cubic meters per second\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  #>  #> $thousandCfs #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"10^3 cfs\" #>  #> Slot \"qUnitFactor\": #> [1] 0.03531467 #>  #> Slot \"qUnitName\": #> [1] \"Thousand Cubic Feet per Second\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", 10^3 * ft^3/s)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", 10^3 * ft^3/s, \")\")) #>  #> Slot \"shortCode\": #> [1] 3 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in thousands of cubic feet per second\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  #>  #> $thousandCms #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"10^3 cms\" #>  #> Slot \"qUnitFactor\": #> [1] 0.001 #>  #> Slot \"qUnitName\": #> [1] \"Thousand Cubic Meters per Second\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", 10^3 * m^3/s)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", 10^3 * m^3/s, \")\")) #>  #> Slot \"shortCode\": #> [1] 4 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in thousands of cubic meters per second\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  #>  #> $mmDay #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"mm/day\" #>  #> Slot \"qUnitFactor\": #> [1] 86400000 #>  #> Slot \"qUnitName\": #> [1] \"Cubic Millimeters per Day\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", mm^3/day)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", mm^3/day, \")\")) #>  #> Slot \"shortCode\": #> [1] 5 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in cubic millimeters per day\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  #>  qConst[['cfs']] #> An object of class \"qUnit\" #> Slot \"qShortName\": #> [1] \"   cfs  \" #>  #> Slot \"qUnitFactor\": #> [1] 35.31467 #>  #> Slot \"qUnitName\": #> [1] \"Cubic Feet per Second\" #>  #> Slot \"qUnitExpress\": #> expression(paste(\"Discharge in \", ft^3/s)) #>  #> Slot \"qUnitTiny\": #> expression(paste(\"Discharge \", \"(\", ft^3/s, \")\")) #>  #> Slot \"shortCode\": #> [1] 1 #>  #> Slot \"unitUSGS\": #> [1] \"Discharge, in cubic feet per second\" #>  #> Slot \"prefix\": #> [1] \"Discharge\" #>  qConst[['cfs']]@qUnitName #> [1] \"Cubic Feet per Second\" concConst[['concentration']] #> An object of class \"concUnit\" #> Slot \"longPrefix\": #> [1] \"Concentration\" #>  #> Slot \"shortPrefix\": #> [1] \"Conc\" #>  concConst[['concentration']]@shortPrefix #> [1] \"Conc\""},{"path":[]},{"path":"/reference/EGRET-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EGRET package includes WRTDS and flowHistory — EGRET-package","text":"Collection functions WRTDS flowHistory analysis,  produce graphs tables data results analyses.","code":""},{"path":"/reference/EGRET-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"EGRET package includes WRTDS and flowHistory — EGRET-package","text":"Hirsch, R.M., De Cicco, L.., 2014, User guide Exploration Graphics RivEr Trends  (EGRET) dataRetrieval: R packages hydrologic data: U.S. Geological Survey Techniques Methods book 4,  chap. A10, 94 p., doi:10.3133/tm4A10","code":""},{"path":"/reference/EGRET-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EGRET package includes WRTDS and flowHistory — EGRET-package","text":"Robert M. Hirsch rhirsch@usgs.gov, Laura De Cicco ldecicco@usgs.gov","code":""},{"path":"/reference/INFOdataframe.html","id":null,"dir":"Reference","previous_headings":"","what":"Import metadata to create INFO data frame — INFOdataframe","title":"Import metadata to create INFO data frame — INFOdataframe","text":"Populates INFO data frame either NWIS (readNWISInfo), Water Quality Portal (readWQPInfo), user-supplied files (readUserInfo).","code":""},{"path":"/reference/INFOdataframe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import metadata to create INFO data frame — INFOdataframe","text":"","code":"readNWISInfo(siteNumber, parameterCd, interactive = TRUE)  readWQPInfo(siteNumber, parameterCd, interactive = TRUE)  readUserInfo(filePath, fileName, hasHeader = TRUE, separator = \",\",   interactive = TRUE)"},{"path":"/reference/INFOdataframe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import metadata to create INFO data frame — INFOdataframe","text":"siteNumber character site number.  readNWISInfo, usually 8 digit number, readWQPInfo, usually longer code. instance, USGS site number Water Quality Portal form `USGS-XXXXXXXX`. siteNumber left blank (empty string), interactive option allows users enter required information hand, otherwise fields left blank. parameterCd character USGS parameter code (5 digit number) characteristic name (using readWQPInfo).  parameterCd left blank (empty string), interactive option allows users enter required information hand, otherwise fields left blank. interactive logical Option interactive mode.  true, user interaction error handling data checks. filePath character specifying path file (used readUserInfo) fileName character name file open (used readUserInfo) hasHeader logical true first row data column headers (used readUserInfo) separator character separates data cells (used readUserInfo)","code":""},{"path":"/reference/INFOdataframe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import metadata to create INFO data frame — INFOdataframe","text":"INFO data frame. metadata can stored INFO. However, 8 columns EGRET uses name functions: *** Additionally, EGRET assumes concentrations saved mg/l. variation 'mg/l' found INFO$param.units, functions calculate flux issue warning.  conversion mg/l user-specified flux unit (e.g., kg/day) uses hard-coded conversion factors.","code":""},{"path":[]},{"path":"/reference/INFOdataframe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import metadata to create INFO data frame — INFOdataframe","text":"","code":"# These examples require an internet connection to run # Automatically gets information about site 05114000 and temperature # \\donttest{ INFO <- readNWISInfo('05114000','00010',interactive = FALSE) # } # These examples require an internet connection to run # Automatically gets information about site 01594440 and temperature, no interaction with user nameToUse <- 'Specific conductance' pcodeToUse <- '00095' # \\donttest{ # INFO <- readWQPInfo('USGS-04024315',pcodeToUse, interactive = FALSE)  # INFO2 <- readWQPInfo('WIDNR_WQX-10032762',nameToUse, interactive = FALSE) # To adjust the label names: # INFO$shortName <- \"Little\" # INFO$paramShortName <- \"SC\" # } filePath <- system.file(\"extdata\", package=\"EGRET\") fileName <- 'infoTest.csv' INFO <- readUserInfo(filePath,fileName, separator=\",\",interactive=FALSE)"},{"path":"/reference/as.egret.html","id":null,"dir":"Reference","previous_headings":"","what":"Create named list for EGRET analysis — as.egret","title":"Create named list for EGRET analysis — as.egret","text":"Create named list INFO, Daily, Sample dataframes, surface matrix. available, NA ","code":""},{"path":"/reference/as.egret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create named list for EGRET analysis — as.egret","text":"","code":"as.egret(INFO, Daily, Sample = NA, surfaces = NA)"},{"path":"/reference/as.egret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create named list for EGRET analysis — as.egret","text":"INFO dataframe containing INFO dataframe Daily dataframe containing daily data Sample dataframe containing sample data surfaces matrix returned modelEstimation. Default NA.","code":""},{"path":"/reference/as.egret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create named list for EGRET analysis — as.egret","text":"eList named list Daily, Sample, INFO dataframes, along surfaces matrix. values can NA, EGRET functions work missing parts named list eList.","code":""},{"path":[]},{"path":"/reference/as.egret.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create named list for EGRET analysis — as.egret","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) INFO <- getInfo(eList) eList_flowHistory <- as.egret(INFO, Daily) plotFlowSingle(eList_flowHistory, 1)  Sample <- getSample(eList) surfaces <- getSurfaces(eList) eList_full <- as.egret(INFO, Daily, Sample, surfaces) plotFluxQ(eList_full)"},{"path":"/reference/blankTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Deletes the computed values during periods of time when there are no sample data — blankTime","title":"Deletes the computed values during periods of time when there are no sample data — blankTime","text":"function used data analyst believes gap sample data record  long estimates period reliable.   used periods several years duration.   period, values Conc, Flux, FNConc FNFlux converted NA.","code":""},{"path":"/reference/blankTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deletes the computed values during periods of time when there are no sample data — blankTime","text":"","code":"blankTime(eList, startBlank, endBlank)"},{"path":"/reference/blankTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deletes the computed values during periods of time when there are no sample data — blankTime","text":"eList named list least Daily dataframe startBlank character specifying starting date blank period, input quotes yyyy-mm-dd format endBlank character specifying ending date blank period, input quotes yyyy-mm-dd format","code":""},{"path":"/reference/blankTime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deletes the computed values during periods of time when there are no sample data — blankTime","text":"eList named list modified Daily data frame.","code":""},{"path":"/reference/blankTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deletes the computed values during periods of time when there are no sample data — blankTime","text":"","code":"startBlank = \"2004-10-01\" endBlank = \"2006-09-30\" eList <- Choptank_eList eList <- blankTime(eList, startBlank, endBlank)"},{"path":"/reference/boxConcMonth.html","id":null,"dir":"Reference","previous_headings":"","what":"Box plot of the water quality data by month — boxConcMonth","title":"Box plot of the water quality data by month — boxConcMonth","text":"Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata. Box widths proportional square root number samples month. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/boxConcMonth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box plot of the water quality data by month — boxConcMonth","text":"","code":"boxConcMonth(eList, printTitle = TRUE, cex = 0.8, cex.axis = 1.1,   cex.main = 1.1, las = 1, logScale = FALSE, tcl = 0.5,   tinyPlot = FALSE, customPar = FALSE, showYLabels = TRUE, concLab = 1,   showXLabels = TRUE, showXAxis = TRUE, showYAxis = TRUE, monthLab = 1,   ...)"},{"path":"/reference/boxConcMonth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box plot of the water quality data by month — boxConcMonth","text":"eList named list least Sample INFO dataframes printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex las numeric 0,1,2,3; style axis labels, see ?par logScale logical TRUE y plotted log axis tcl number defaults 0.5, specifies length tick marks fraction height line text tinyPlot logical variable, TRUE plot designed plotted small part multi-plot figure, default FALSE. customPar logical defaults FALSE. TRUE, par() set user calling function showYLabels logical defaults TRUE. FALSE, y axis label plotted concLab object concUnit class, numeric represented short code,  character representing descriptive name. showXLabels logical defaults TRUE. FALSE, x axis label plotted showXAxis logical defaults TRUE. FALSE, x axis plotted showYAxis logical defaults TRUE. FALSE, y axis plotted monthLab object monthLabel class, numeric represented short code,  character representing descriptive name. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/boxConcMonth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box plot of the water quality data by month — boxConcMonth","text":"","code":"eList <- Choptank_eList # Water year: boxConcMonth(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) boxConcMonth(eList)  spanish_month <- new(\"monthLabel\",                   monthAbbrev = c(\"enero\",  \"feb\",   \"marzo\", \"abr\",                                   \"mayo\",  \"jun\",  \"jul\", \"agosto\", \"set\",                                   \"oct\",  \"nov\", \"dic\"),                   monthFull = c(\"enero\",  \"febrero\",   \"marzo\", \"abril\",                                   \"mayo\",  \"junio\",  \"julio\", \"agosto\", \"septiembre\",                                   \"octubre\",  \"noviembre\", \"diciembre\"),                   monthSingle = c(\"E\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\",                                   \"A\", \"S\", \"O\", \"N\", \"D\")) boxConcMonth(eList, monthLab = spanish_month,               showXLabels = FALSE, printTitle = FALSE)"},{"path":"/reference/boxConcThree.html","id":null,"dir":"Reference","previous_headings":"","what":"Three box plots side-by-side — boxConcThree","title":"Three box plots side-by-side — boxConcThree","text":"function used compare distribution concentration  sample predicted data set. shows three boxplots.  One sample,  one predictions days sample values, one days  (whether sample values).  Box widths proportional square root number observations represented box. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/boxConcThree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Three box plots side-by-side — boxConcThree","text":"","code":"boxConcThree(eList, tinyPlot = FALSE, printTitle = TRUE,   moreTitle = \"WRTDS\", customPar = FALSE, font.main = 2, cex = 0.8,   cex.main = 1.1, cex.axis = 1.1, concLab = 1, ...)"},{"path":"/reference/boxConcThree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Three box plots side-by-side — boxConcThree","text":"eList named list least Daily, Sample, INFO dataframes tinyPlot logical variable, TRUE plot designed plotted small part multi-plot figure, default FALSE. printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) moreTitle character specifying additional information go figure title, typically information specific estimation method used, default additional information customPar logical defaults FALSE. TRUE, par() set user calling function font.main font used plot main titles cex numerical value giving amount plotting symbols magnified cex.main magnification used main titles relative current setting cex cex.axis magnification used axis annotation relative current setting cex concLab object concUnit class, numeric represented short code,  character representing descriptive name. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/boxConcThree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Three box plots side-by-side — boxConcThree","text":"","code":"eList <- Choptank_eList # Water year: boxConcThree(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) boxConcThree(eList)"},{"path":"/reference/boxQTwice.html","id":null,"dir":"Reference","previous_headings":"","what":"Two box plots side-by-side, discharge on sample days, and discharge on all days — boxQTwice","title":"Two box plots side-by-side, discharge on sample days, and discharge on all days — boxQTwice","text":"function used compare distribution discharges sample data set  discharges full daily data set. Note discharge plotted logarithmic axis. boxplot created  using log values scale presented original units.  ideal situation show two boxes roughly similar  sample boxplot median, upper quartile, higher values  slightly greater boxplot days. Box widths proportional square root number observations (left box based number sampled days, right box based total number days record). Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/boxQTwice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two box plots side-by-side, discharge on sample days, and discharge on all days — boxQTwice","text":"","code":"boxQTwice(eList, printTitle = TRUE, qUnit = 2, cex = 0.8,   cex.main = 1.1, logScale = TRUE, cex.axis = 1.1, tcl = 0.5,   las = 1, tinyPlot = FALSE, usgsStyle = FALSE, customPar = FALSE, ...)"},{"path":"/reference/boxQTwice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two box plots side-by-side, discharge on sample days, and discharge on all days — boxQTwice","text":"eList named list least Daily, Sample, INFO dataframes printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. cex numerical value giving amount plotting symbols magnified cex.main magnification used main titles relative current setting cex logScale logical TRUE y plotted log axis. Defaults TRUE. cex.axis magnification used axis annotation relative current setting cex tcl number defaults 0.5, specifies length tick marks fraction height line text las numeric 0,1,2,3; style axis labels, see ?par tinyPlot logical variable, TRUE plot designed plotted small part multi-plot figure, default FALSE. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. customPar logical defaults FALSE. TRUE, par() set user calling function ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/boxQTwice.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two box plots side-by-side, discharge on sample days, and discharge on all days — boxQTwice","text":"","code":"eList <- Choptank_eList # Water year: boxQTwice(eList)  boxQTwice(eList, qUnit=1) boxQTwice(eList, qUnit='cfs')  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) boxQTwice(eList)"},{"path":"/reference/boxResidMonth.html","id":null,"dir":"Reference","previous_headings":"","what":"A box plot of WRTDS residuals by month — boxResidMonth","title":"A box plot of WRTDS residuals by month — boxResidMonth","text":"function produces boxplot residuals WRTDS, expressed natural log concentration units.  provides alternative viewing standardized residuals, residual divided estimated standard error.  monthly boxplot widths proportional square root sample size.  residuals censored value determined difference natural log average upper lower.    bounds sample value, minus log space estimate concentration. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata","code":""},{"path":"/reference/boxResidMonth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A box plot of WRTDS residuals by month — boxResidMonth","text":"","code":"boxResidMonth(eList, stdResid = FALSE, las = 1, printTitle = TRUE,   cex = 0.8, cex.axis = 1.1, cex.main = 1.1, font.main = 2,   tinyPlot = FALSE, customPar = FALSE, monthLab = 1,   randomCensored = FALSE, ...)"},{"path":"/reference/boxResidMonth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A box plot of WRTDS residuals by month — boxResidMonth","text":"eList named list least Sample INFO dataframes stdResid logical variable, TRUE uses standardized residual, FALSE uses actual, default FALSE las numeric 0,1,2,3; style axis labels printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex font.main font used plot main titles tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE customPar logical defaults FALSE. TRUE, par() set user calling function monthLab object monthLabel class, numeric represented short code,  character representing descriptive name. randomCensored logical. Show censored residuals randomized. Default = FALSE. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/boxResidMonth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A box plot of WRTDS residuals by month — boxResidMonth","text":"","code":"eList <- Choptank_eList # Water year: boxResidMonth(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart = 6, paLong = 3) boxResidMonth(eList)"},{"path":"/reference/calculateMonthlyResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","title":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","text":"Computes monthly mean values discharge, concentration, flux, flow-normalized concentration flow-normalized flux (Q, Conc, FNConc, Flux, FNFlux) SI units WRTDSKalman run outputs averages Q, Conc, GenConc, FNConc, Flux, GenFlux, FNFlux.  Note Flux, GenFlux, FNFlux values average flux values (totals). discharge units m3/s, concentration mg/L, flux kg/day. returns data frame containing month, year, decimal year, mean values DecYear, Q, Conc, GenConc, FNConc, Flux, GenFlux, FNFlux.","code":""},{"path":"/reference/calculateMonthlyResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","text":"","code":"calculateMonthlyResults(eList)"},{"path":"/reference/calculateMonthlyResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","text":"eList named list least Daily dataframes","code":""},{"path":"/reference/calculateMonthlyResults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","text":"MonthlyResults data frame numeric values describing monthly average values","code":""},{"path":"/reference/calculateMonthlyResults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates monthly mean values of Q, Conc, FNConc, Flux, and FNFlux for the entire record.  If WRTDSKalman has been run it also includes the monthly mean values of GenConc and GenFlux. — calculateMonthlyResults","text":"","code":"eList <- Choptank_eList monthlyResults <- calculateMonthlyResults(eList)"},{"path":"/reference/censoredSegments.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic plotting function to create censored line segments — censoredSegments","title":"Generic plotting function to create censored line segments — censoredSegments","text":"Basic plotting framework EGRET dot plots. Graphical parameters default values work well plots, can re-assigned. See ?par complete definitions optional input variables.","code":""},{"path":"/reference/censoredSegments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic plotting function to create censored line segments — censoredSegments","text":"","code":"censoredSegments(yBottom, yLow, yHigh, x, Uncen, col = \"black\", lwd = 1)"},{"path":"/reference/censoredSegments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic plotting function to create censored line segments — censoredSegments","text":"yBottom number specifying minimum flux (required) yLow vector specifying x data (required), ConcLow yHigh vector specifying x data (required), ConcHigh x vector x data (required) Uncen vector defines whether values censored (0) (1) col color points plot, see ?par 'Color Specification' lwd number line width","code":""},{"path":[]},{"path":"/reference/censoredSegments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic plotting function to create censored line segments — censoredSegments","text":"","code":"x <- c(1,2,3,4,5,6) y <- c(1,3,4,3.3,4.4,7) xlim <- c(min(x)*.75,max(x)*1.25) ylim <- c(0,1.25*max(y)) xlab <- \"Date\" ylab <- \"Concentration\" xTicks <- pretty(xlim) yTicks <- pretty(ylim) genericEGRETDotPlot(x=x, y=y,                      xlim=xlim, ylim=ylim,                     xlab=xlab, ylab=ylab,                     xTicks=xTicks, yTicks=yTicks,                     plotTitle=\"Test\" ) yBottom <- 0 yLow <- c(NA,3,4,3.3,4,7) yHigh <- c(1,3,4,3.3,5,NA) Uncen <- c(0,1,1,1,0,0) censoredSegments(yBottom=yBottom,yLow=yLow,yHigh=yHigh,x=x,Uncen=Uncen)"},{"path":"/reference/checkStartEndDate.html","id":null,"dir":"Reference","previous_headings":"","what":"checkStartEndDate — checkStartEndDate","title":"checkStartEndDate — checkStartEndDate","text":"Checks start date end date.  , give user opportunity correct, otherwise create warning.","code":""},{"path":"/reference/checkStartEndDate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"checkStartEndDate — checkStartEndDate","text":"","code":"checkStartEndDate(startDate, endDate, interactive = TRUE)"},{"path":"/reference/checkStartEndDate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"checkStartEndDate — checkStartEndDate","text":"startDate character endDate character interactive logical Option interactive mode.  true, user interaction error handling data checks.","code":""},{"path":"/reference/checkStartEndDate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"checkStartEndDate — checkStartEndDate","text":"vector first value startDate, second endDate","code":""},{"path":"/reference/checkStartEndDate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"checkStartEndDate — checkStartEndDate","text":"","code":"startDate <- '1985-01-01'     endDate <- '1990-01-01'     checkStartEndDate(startDate, endDate) #> [1] \"1985-01-01\" \"1990-01-01\""},{"path":"/reference/checkSurfaceSpan.html","id":null,"dir":"Reference","previous_headings":"","what":"checkSurfaceSpan — checkSurfaceSpan","title":"checkSurfaceSpan — checkSurfaceSpan","text":"checkSurfaceSpan","code":""},{"path":"/reference/checkSurfaceSpan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"checkSurfaceSpan — checkSurfaceSpan","text":"","code":"checkSurfaceSpan(eList)"},{"path":"/reference/checkSurfaceSpan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"checkSurfaceSpan — checkSurfaceSpan","text":"eList named list least Daily, Sample, INFO dataframes","code":""},{"path":"/reference/checkSurfaceSpan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"checkSurfaceSpan — checkSurfaceSpan","text":"","code":"eList <- Choptank_eList checkSurfaceSpan(eList)"},{"path":"/reference/cleanUp.html","id":null,"dir":"Reference","previous_headings":"","what":"cleanUp eList — cleanUp","title":"cleanUp eList — cleanUp","text":"Takes eList input. duplicated dates Sample data frame,  randomly select one value date.  censored values data set replaced random censored values.  days duplicate samples censored valued eList returned function identical eList passed .","code":""},{"path":"/reference/cleanUp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cleanUp eList — cleanUp","text":"","code":"cleanUp(eList)"},{"path":"/reference/cleanUp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cleanUp eList — cleanUp","text":"eList named list INFO, Daily, Sample dataframes surfaces matrix.","code":""},{"path":"/reference/cleanUp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cleanUp eList — cleanUp","text":"eList duplicated dates Sample data frame randomly sampled censored values replaced random values.","code":""},{"path":"/reference/cleanUp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cleanUp eList — cleanUp","text":"function run iteration generating random sequence  WRTDSKalman function","code":""},{"path":"/reference/cleanUp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"cleanUp eList — cleanUp","text":"","code":"eList <- Choptank_eList  eList <- cleanUp(eList)"},{"path":"/reference/compressData.html","id":null,"dir":"Reference","previous_headings":"","what":"Compress sample data frame — compressData","title":"Compress sample data frame — compressData","text":"Using raw data least dateTime, value, code, populates measured data portion Sample dataframe used EGRET. ConcLow  = Lower bound observed concentration ConcHigh = Upper bound observed concentration Uncen    = 1 uncensored, 0 censored","code":""},{"path":"/reference/compressData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compress sample data frame — compressData","text":"","code":"compressData(data, verbose = TRUE, interactive = NULL)"},{"path":"/reference/compressData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compress sample data frame — compressData","text":"data dataframe contains least dateTime, value, code columns verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/compressData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compress sample data frame — compressData","text":"data frame returnDataFrame data frame containing dateTime, ConcHigh, ConcLow, Uncen","code":""},{"path":"/reference/compressData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compress sample data frame — compressData","text":"","code":"dateTime <- c('1985-01-01', '1985-01-02', '1985-01-03') comment1 <- c(\"\",\"\",\"\") value1 <- c(1,2,3) comment2 <- c(\"\",\"<\",\"\") value2 <- c(2,3,4) comment3 <- c(\"\",\"\",\"<\") value3 <- c(3,4,5) dataInput <- data.frame(dateTime, comment1, value1,        comment2, value2,        comment3, value3, stringsAsFactors=FALSE) compressData(dataInput) #>     dateTime ConcLow ConcHigh Uncen #> 1 1985-01-01       6        6     1 #> 2 1985-01-02       6        9     0 #> 3 1985-01-03       7       12     0"},{"path":"/reference/concUnit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"concUnit class — concUnit-class","title":"concUnit class — concUnit-class","text":"details concUnit class","code":""},{"path":"/reference/concUnit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"concUnit class — concUnit-class","text":"longPrefix character specifying long name     concentration labels. shortPrefix character specifying short name     concentration labels.","code":""},{"path":"/reference/cumQdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative flow calculation — cumQdate","title":"Cumulative flow calculation — cumQdate","text":"function computes first day calendar year specific fraction cumulative flow year exceeded.  Typically one looks point half cumulative flow happened (fract = 0.5). portion year considered set paStart paLong. matrix returned 2 columns:  first year (integer period analysis ends), second day year fraction exceeded. None rows NA values.","code":""},{"path":"/reference/cumQdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative flow calculation — cumQdate","text":"","code":"cumQdate(eList, paStart = 10, paLong = 12, fract = 0.5)"},{"path":"/reference/cumQdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative flow calculation — cumQdate","text":"eList named list least Sample INFO dataframes paStart numeric integer specifying starting month period analysis, 1 <= paStart <= 12, default 10 paLong numeric integer specifying length period analysis, months, 1 <= paLong <= 12, default 12 fract numeric fraction flow","code":""},{"path":"/reference/cumQdate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative flow calculation — cumQdate","text":"annualSeries integer matrix two columns.  first column calendar year end period   second column day year flow exceeded specified fraction   entire period considered","code":""},{"path":"/reference/cumQdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative flow calculation — cumQdate","text":"common use type analysis snowmelt period year. (example) assume snowmelt starts month March ends July set paStart = 3 paLong = 5","code":""},{"path":"/reference/cumQdate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative flow calculation — cumQdate","text":"","code":"eList <- Choptank_eList annualFlow <- cumQdate(eList) head(annualFlow) #>      [,1] [,2] #> [1,] 1980   77 #> [2,] 1981   98 #> [3,] 1982   68 #> [4,] 1983  103 #> [5,] 1984   75 #> [6,] 1985   76 plot(annualFlow)  mod1 <- lm(annualFlow[,2] ~ annualFlow[,1]) summary(mod1) #>  #> Call: #> lm(formula = annualFlow[, 2] ~ annualFlow[, 1]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -61.022 -19.700   3.093  15.992  62.331  #>  #> Coefficients: #>                  Estimate Std. Error t value Pr(>|t|) #> (Intercept)     -623.1512  1128.3270  -0.552    0.585 #> annualFlow[, 1]    0.3528     0.5654   0.624    0.537 #>  #> Residual standard error: 29.53 on 30 degrees of freedom #> Multiple R-squared:  0.01281,\tAdjusted R-squared:  -0.02009  #> F-statistic: 0.3894 on 1 and 30 DF,  p-value: 0.5374 #>"},{"path":"/reference/dataOverview.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Overview for WRTDS — dataOverview","title":"Data Overview for WRTDS — dataOverview","text":"Gives summary data used WRTDS analysis","code":""},{"path":"/reference/dataOverview.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data Overview for WRTDS — dataOverview","text":"","code":"dataOverview(Daily, Sample)"},{"path":"/reference/dataOverview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data Overview for WRTDS — dataOverview","text":"Daily dataframe Sample dataframe","code":""},{"path":[]},{"path":"/reference/dataOverview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data Overview for WRTDS — dataOverview","text":"","code":"eList <- Choptank_eList exDaily <- getDaily(eList) exSample <- getSample(eList) dataOverview(Daily = exDaily, Sample = exSample) #>  #>  Discharge Record is 11688 days long, which is 32 years #>  First day of the discharge record is 1979-10-01 and last day is 2011-09-30 #>  The water quality record has 606 samples #>  The first sample is from 1979-10-24 and the last sample is from 2011-09-29 #>  Discharge: Minimum, mean and maximum 0.00991 4.09 246 #>  Concentration: Minimum, mean and maximum 0.05 1.1 2.4 #>  Percentage of the sample values that are censored is 0.17 %"},{"path":"/reference/dateFormatCheck.html","id":null,"dir":"Reference","previous_headings":"","what":"Check date format — dateFormatCheck","title":"Check date format — dateFormatCheck","text":"Checks see format YYYY-MM-DD. Also performs date checks.","code":""},{"path":"/reference/dateFormatCheck.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check date format — dateFormatCheck","text":"","code":"dateFormatCheck(date)"},{"path":"/reference/dateFormatCheck.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check date format — dateFormatCheck","text":"date character","code":""},{"path":"/reference/dateFormatCheck.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check date format — dateFormatCheck","text":"condition logical TRUE FALSE checks passed failed","code":""},{"path":"/reference/dateFormatCheck.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check date format — dateFormatCheck","text":"","code":"date <- '1985-01-01' dateFormatCheck(date) #> [1] TRUE dateWrong <- '1999/1/7' dateFormatCheck(dateWrong) #> [1] FALSE"},{"path":"/reference/decimalDate.html","id":null,"dir":"Reference","previous_headings":"","what":"decimalDate — decimalDate","title":"decimalDate — decimalDate","text":"Create decimal date date/time vector.","code":""},{"path":"/reference/decimalDate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"decimalDate — decimalDate","text":"","code":"decimalDate(rawData)"},{"path":"/reference/decimalDate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"decimalDate — decimalDate","text":"rawData vector dates dateTimes.","code":""},{"path":"/reference/decimalDate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"decimalDate — decimalDate","text":"","code":"dateTime <- c('1984-02-28 13:56',               '1984-03-01 00:00',               '1986-03-01 00:00',               '1986-10-15 00:00') decimalDate(dateTime) #> [1] 1984.160 1984.164 1986.162 1986.786  dateTime <- c('1984-02-28',                '1984-03-01',               '1986-03-01',               '1986-10-15') decimalDate(dateTime) #> [1] 1984.158 1984.164 1986.162 1986.786"},{"path":"/reference/decimalHighLow.html","id":null,"dir":"Reference","previous_headings":"","what":"decimalHighLow — decimalHighLow","title":"decimalHighLow — decimalHighLow","text":"decimalHighLow figures highest lowest decimal year based water year. input data frame columns Month DecYear.","code":""},{"path":"/reference/decimalHighLow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"decimalHighLow — decimalHighLow","text":"","code":"decimalHighLow(df)"},{"path":"/reference/decimalHighLow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"decimalHighLow — decimalHighLow","text":"df data.frame Month, DecYear, Month columns","code":""},{"path":"/reference/decimalHighLow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"decimalHighLow — decimalHighLow","text":"list DecHigh DecLow (water year high/low decimal values)","code":""},{"path":"/reference/decimalHighLow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"decimalHighLow — decimalHighLow","text":"","code":"eList <- Choptank_eList highLow <- decimalHighLow(eList$Sample)  DecHigh <- highLow[[\"DecHigh\"]] DecLow <- highLow[[\"DecLow\"]]"},{"path":"/reference/errorStats.html","id":null,"dir":"Reference","previous_headings":"","what":"Error statistics — errorStats","title":"Error statistics — errorStats","text":"function takes fitted WRTDS model computes error statistics residuals used cross-validation residuals,  slightly larger regular regression residuals case censored data, residuals computed random residuals computed makeAugmentedSample(), function returns list error statistics also prints console","code":""},{"path":"/reference/errorStats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Error statistics — errorStats","text":"","code":"errorStats(eList)"},{"path":"/reference/errorStats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Error statistics — errorStats","text":"eList named list least Daily, Sample, INFO dataframes","code":""},{"path":"/reference/errorStats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Error statistics — errorStats","text":"erStats numeric vector consisting following statistics RsqLC R squared value predictions ln(Concentration) RsqLF R squared value predictions ln(Flux) rmse root mean squared error ln(Concentration), value apply Flux sepPercent standard error prediction Concentration, expressed percent     value apply Flux","code":""},{"path":"/reference/errorStats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Error statistics — errorStats","text":"","code":"eList <- Choptank_eList errorStats(eList) #>  #>  Root Mean Squared Error in natural log units =  0.295 #>  Rsquared for natural log of concentration    =  0.459 #>  Rsquared for natural log of flux             =  0.95 #>  Standard error of estimate = 30.1 % #>   RsqLogC RsqLogF  rmse sepPercent #> 1   0.459    0.95 0.295       30.1"},{"path":"/reference/estCrossVal.html","id":null,"dir":"Reference","previous_headings":"","what":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","title":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","text":"function fits WRTDS model n times (n number observations).   fit, data value estimated eliminated record.  gives predictions depend knowing actual result day.  Thus provides \"honest\" estimate model performance traditional  error analysis uses data.","code":""},{"path":"/reference/estCrossVal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","text":"","code":"estCrossVal(DecLow, DecHigh, Sample, windowY = 7, windowQ = 2,   windowS = 0.5, minNumObs = 100, minNumUncen = 50, edgeAdjust = TRUE,   verbose = TRUE)"},{"path":"/reference/estCrossVal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","text":"DecLow number specifying minimum decimal year DecHigh number specifying maximum decimal year Sample data frame containing sample values, default Sample windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 edgeAdjust logical specifying whether use modified method calculating windows edge record.  modified method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether display progress message","code":""},{"path":"/reference/estCrossVal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","text":"SampleCrossV data frame containing sample data augmented results cross-validation exercise","code":""},{"path":"/reference/estCrossVal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jack-Knife cross validation of the WRTDS (Weighted Regressions on Time, Discharge, and Season) — estCrossVal","text":"","code":"eList <- Choptank_eList Sample <- getSample(eList) Daily <- getDaily(eList) numDays <- length(Daily$DecYear) DecLow <- Daily$DecYear[1] DecHigh <- Daily$DecYear[numDays] # \\donttest{ SampleCrossV <- estCrossVal(DecLow,DecHigh,Sample) #>  #>  estCrossVal % complete: #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t # }"},{"path":"/reference/estDailyFromSurfaces.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"Uses surfaces matrix estimated estSurfaces estimate 6 daily time series   appends Daily data frame.  time series (order):   yHat, estimated natural log concentration, dimensionless   SE, standard error natural log concentration   ConcDay, estimated concentration mg/L   FluxDay, estimated flux kg/day   FNConc, flow-normalized concentration mg/L   FNFlux, flow-normalized flux kg/day Bin LogQ values day--year.","code":""},{"path":"/reference/estDailyFromSurfaces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"","code":"estDailyFromSurfaces(eList, localsurfaces = NA, localDaily = NA)  getConcFluxFromSurface(eList, allLogQsByDayOfYear, localDaily,   localsurfaces = NA)  getSurfaceEstimates(eList, localsurfaces = NA, localDaily = NA)  bin_Qs(localDaily)"},{"path":"/reference/estDailyFromSurfaces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"eList named list least Daily INFO dataframes, surface matrix localsurfaces surface -riding one stored eList.  Default NA. localDaily data frame override eList$Daily.  Default NA. allLogQsByDayOfYear list","code":""},{"path":"/reference/estDailyFromSurfaces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"egret object altered Daily dataframe Daily dataframe yHat, SE, ConcDay FluxDay calulated","code":""},{"path":"/reference/estDailyFromSurfaces.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"results stored augmented version Daily data frame, returned part EGRET object.","code":""},{"path":"/reference/estDailyFromSurfaces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimates all daily values of Concentration, Flux, Flow-Normalized Concentration, and Flow Normalized Flux — estDailyFromSurfaces","text":"","code":"eList <- Choptank_eList ################################################# # This is usually done in modelEstimation: Daily <- getDaily(eList) surfaceIndexParameters<-surfaceIndex(Daily) INFO <- eList$INFO INFO$bottomLogQ<-surfaceIndexParameters[['bottomLogQ']] INFO$stepLogQ<-surfaceIndexParameters[['stepLogQ']] INFO$nVectorLogQ<-surfaceIndexParameters[['nVectorLogQ']] INFO$bottomYear<-surfaceIndexParameters[['bottomYear']] INFO$stepYear<-surfaceIndexParameters[['stepYear']] INFO$nVectorYear<-surfaceIndexParameters[['nVectorYear']] eList$INFO <- INFO ################################################# # \\donttest{ Daily <- estDailyFromSurfaces(eList) # }"},{"path":"/reference/estSurfaces.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","title":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","text":"function uses weighted survival regression estimate three surfaces cover complete range DecYear log(Q) values Daily data set.  surfaces :   (1) estimated log concentration (yHat),    (2) estimated standard error (SE),    (3) estimated concentration (ConcHat).  mapped array covers complete space daily discharge time.  first index discharge, layed 14 equally spaced levels log(Q). second index time, layed 16 increments calendar year, starting January 1.  returns 3 dimensional array called surfaces.  array used estimate 3 quantities given day daily values record.","code":""},{"path":"/reference/estSurfaces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","text":"","code":"estSurfaces(eList, surfaceStart = NA, surfaceEnd = NA, localSample = NA,   windowY = 7, windowQ = 2, windowS = 0.5, minNumObs = 100,   minNumUncen = 50, edgeAdjust = TRUE, verbose = TRUE,   interactive = NULL, run.parallel = FALSE)"},{"path":"/reference/estSurfaces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","text":"eList named list least Sample Daily dataframes surfaceStart Date object start surface slice (character starting date data retrieval form YYYY-MM-DD). Default NA . surfaceEnd Date object end surface slice (character starting date data retrieval form YYYY-MM-DD). Default NA . localSample data frame override eList$Sample. Default NA . windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 edgeAdjust logical specifying whether use modified method calculating windows edge record. Default TRUE. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead run.parallel logical run bootstrapping parallel ","code":""},{"path":"/reference/estSurfaces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","text":"surfaces array containing three surfaces estimated, array 3 dimensional","code":""},{"path":"/reference/estSurfaces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the three surfaces (for yHat, SE and ConcHat) as a function of DecYear and logQ and store in the three-dimensional object called surfaces — estSurfaces","text":"","code":"eList <- Choptank_eList # \\donttest{ surfaces <- estSurfaces(eList) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done  surfaceStart <- \"1984-10-01\" surfaceEnd <- \"1986-09-30\" surfaces_1 <- estSurfaces(eList, surfaceStart, surfaceEnd) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done  wall_sample <- head(eList$Sample, n=500)  surface_wall <- estSurfaces(eList, localSample = wall_sample) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done  # }"},{"path":"/reference/fixSampleFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Sample dataframe — fixSampleFrame","title":"Update Sample dataframe — fixSampleFrame","text":"Used updating Sample dataframe ConcLow ConcHigh manually adjusted.  Adjusts ConcAve Uncen columns.","code":""},{"path":"/reference/fixSampleFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Sample dataframe — fixSampleFrame","text":"","code":"fixSampleFrame(eList)"},{"path":"/reference/fixSampleFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update Sample dataframe — fixSampleFrame","text":"eList named list least Sample dataframes","code":""},{"path":"/reference/fixSampleFrame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update Sample dataframe — fixSampleFrame","text":"localSample data frame","code":""},{"path":"/reference/fixSampleFrame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update Sample dataframe — fixSampleFrame","text":"","code":"eList <- Choptank_eList Sample <- eList$Sample Sample[1,c(\"ConcLow\",\"ConcHigh\")] <- c(NA, 0.01) # Adjusted to left-censored Sample[2,c(\"ConcLow\",\"ConcHigh\")] <- c(1.1, 1.3) # Adjusted to interval-censored Sample[3,c(\"ConcLow\",\"ConcHigh\")] <- c(1.3, 1.3) # Simple adjustment eList$Sample <- Sample eList <- fixSampleFrame(eList) eList$Sample[1:3,] #>         Date ConcLow ConcHigh Uncen ConcAve Julian Month Day  DecYear MonthSeq #> 1 1979-10-24      NA     0.01     0   0.005  47412    10 298 1979.813     1558 #> 2 1979-12-05     1.1     1.30     0   1.200  47454    12 340 1979.928     1560 #> 3 1979-12-21     1.3     1.30     1   1.300  47470    12 356 1979.971     1560 #>        SinDY     CosDY        Q     LogQ        yHat        SE   ConcHat #> 1 -0.9230562 0.3846651 3.199804 1.163089 -0.22595368 0.2178958 0.8169198 #> 2 -0.4393995 0.8982918 2.973269 1.089662 -0.06320888 0.2295575 0.9638105 #> 3 -0.1792808 0.9837980 2.944952 1.080093  0.06656706 0.2418137 1.1005433"},{"path":"/reference/flexFN.html","id":null,"dir":"Reference","previous_headings":"","what":"Flexible Flow Normalization — flexFN","title":"Flexible Flow Normalization — flexFN","text":"function implements generalized flow normalization.  means  determining  flow normalized concentration flow normalized flux  given year, specified list years create discharge  record used flow-normalization process.  set years defined  dateInfo object.","code":""},{"path":"/reference/flexFN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flexible Flow Normalization — flexFN","text":"","code":"flexFN(eList, dateInfo, localsurfaces = NA, oldSurface = FALSE,   flowNormStartCol = \"flowNormStart\", flowNormEndCol = \"flowNormEnd\",   flowStartCol = \"flowStart\", flowEndCol = \"flowEnd\")"},{"path":"/reference/flexFN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flexible Flow Normalization — flexFN","text":"eList named list least Daily, Sample, INFO dataframes dateInfo data frame 4 columns. column names descriptions  described .  Default NA. localsurfaces surface  (3-dimensional matrix) -riding one stored  eList Default = NA. oldSurface logical, TRUE, use surface object eList.  Default FALSE. flowNormStartCol character, name column dateInfo starts segment flow normalization flowNormEndCol character, name column dateInfo ends segment flow normalization flowStartCol character, name column dateInfo starts segment portion flow populated flow-normalized values. flowEndCol character, name column dateInfo ends segment portion flow populated flow-normalized values.","code":""},{"path":"/reference/flexFN.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flexible Flow Normalization — flexFN","text":"named list, eList, containing INFO, Daily, Sample, surfaces objects","code":""},{"path":"/reference/flexFN.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flexible Flow Normalization — flexFN","text":"","code":"eList <- Choptank_eList eList <- setUpEstimation(eList) flowNormStart <- c(\"1979-10-01\",\"1990-01-01\",\"1992-10-10\") flowNormEnd <- c(\"1995-06-06\",\"2004-03-03\",\"2011-09-29\") flowStart <- c(\"1979-10-01\",\"1995-06-07\",\"2004-03-04\") flowEnd <- c(\"1995-06-06\",\"2004-03-03\",\"2011-09-29\")  dateInfo <- data.frame(flowNormStart,                        flowNormEnd,                        flowStart,                         flowEnd,                         stringsAsFactors = FALSE) # \\donttest{ newEList <- flexFN(eList, dateInfo) plotFluxHist(newEList) flexPlotAddOn(newEList)   wallSurface <- estSurfaces(eList, localSample = eList$Sample[1:500,]) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done wallEList <- flexFN(eList, dateInfo, localsurface = wallSurface) plotFluxHist(wallEList)  # }"},{"path":"/reference/flexPlotAddOn.html","id":null,"dir":"Reference","previous_headings":"","what":"Flexible Flow Normalization Plot Add On — flexPlotAddOn","title":"Flexible Flow Normalization Plot Add On — flexPlotAddOn","text":"Flexible Flow Normalization Plot Add ","code":""},{"path":"/reference/flexPlotAddOn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flexible Flow Normalization Plot Add On — flexPlotAddOn","text":"","code":"flexPlotAddOn(eList, showArrows = TRUE, showRect = TRUE,   customPalette = NULL)"},{"path":"/reference/flexPlotAddOn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flexible Flow Normalization Plot Add On — flexPlotAddOn","text":"eList named list least Daily, Sample, INFO dataframes showArrows logical whether show arrows representing flow segments showRect logical whether show rectangles representing sample segments customPalette character vector colors hexadecimal string form \"#rrggbb\".  Defaults NULL, indicates use default palette (21 segments).","code":""},{"path":"/reference/flexPlotAddOn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flexible Flow Normalization Plot Add On — flexPlotAddOn","text":"","code":"eList <- Choptank_eList eList <- setUpEstimation(eList) flowNormStart <- c(\"1979-10-01\",\"1990-01-01\",\"1992-10-10\") flowNormEnd <- c(\"1995-06-06\",\"2004-03-03\",\"2011-09-29\") flowStart <- c(\"1979-10-01\",\"1995-06-07\",\"2004-03-04\") flowEnd <- c(\"1995-06-06\",\"2004-03-03\",\"2011-09-29\")  dateInfo <- data.frame(flowNormStart,                        flowNormEnd,                        flowStart,                         flowEnd,                         stringsAsFactors = FALSE) # \\donttest{ newEList <- flexFN(eList, dateInfo) plotFluxHist(newEList) flexPlotAddOn(newEList)   plotFluxHist(newEList) flexPlotAddOn(newEList, customPalette=c(\"#d5ce48\", \"#fd300f\", \"#3e0289\"))  # }"},{"path":"/reference/flowDuration.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","title":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","text":"function useful helping analyst determine empirical probability distribution  streamflow particular part year whole year.  particularly useful setting discharge scales various plots package.","code":""},{"path":"/reference/flowDuration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","text":"","code":"flowDuration(eList, centerDate = \"09-30\", qUnit = 2, span = 365,   monthLab = 1)"},{"path":"/reference/flowDuration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","text":"eList named list least Daily INFO dataframes centerDate character specifying center date part year flow duration calculated, form \"mm-dd\" (must quotes). Default  \"09-30\" qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. Default qUnit = 2, corresponds cubic meters per second. span number half-width window discharge values  used constructing flow-duration curve. full year desired value greater  182 . Note window 2-months width, span value  30. Default 365. monthLab object monthLabel class, numeric represented short code,  character representing descriptive name.","code":""},{"path":"/reference/flowDuration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","text":"qDuration named vector flow duration information.","code":""},{"path":"/reference/flowDuration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes several values of the flow duration curve for streamflow centered on a specific date of the year — flowDuration","text":"","code":"eList <- Choptank_eList # for a window of 30 days either side of June 25 expressed in units # of cfs: flowDuration(eList, \"06-25\", qUnit = 1, span = 30)  #>  #> Flow Duration for Choptank River  #>  #> Flow duration period is centered on June 25  #> And spans the period from May 26  To July 25 #>  #> Discharge units are Cubic Feet per Second  #>    min     5%    10%    25%    50%    75%    90%    95%    max  #>    3.6   13.0   16.0   30.0   52.0  100.0  213.0  335.0 3830.0  # for a flow-duration curve covering the whole year,  # expressed in units of cms, and returning a data frame of results:  qDuration <- flowDuration(eList, qUnit = 2)  #>  #> Flow Duration for Choptank River  #>  #> Flow duration is based on full year #>  #> Discharge units are Cubic Meters per Second"},{"path":"/reference/fluxBiasMulti.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces 8-panel plot that is useful for determining if there is a flux bias problem — fluxBiasMulti","title":"Produces 8-panel plot that is useful for determining if there is a flux bias problem — fluxBiasMulti","text":"plots use jack-knife estimates WRTDS investigate potential flux bias problem.  can also used estimates constructed methods (LOADEST) results stored data frame organized like Sample data frame.  allows additional label information indicate method used. use plot described Hirsch, Robert M., 2014.  Large Biases Regression-Based Constituent Flux Estimates: Causes Diagnostic Tools. Journal American Water Resources Association (JAWRA) 1-24. DOI: 10.1111/jawr.12195 Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/fluxBiasMulti.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces 8-panel plot that is useful for determining if there is a flux bias problem — fluxBiasMulti","text":"","code":"fluxBiasMulti(eList, qUnit = 2, fluxUnit = 3, moreTitle = \"WRTDS\",   cex = 0.7, cex.axis = 1.1, cex.main = 1.1, randomCensored = FALSE,   col = \"black\", lwd = 1, concLab = 1, monthLab = 1, ...)"},{"path":"/reference/fluxBiasMulti.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces 8-panel plot that is useful for determining if there is a flux bias problem — fluxBiasMulti","text":"eList named list least Sample, Daily, INFO dataframes qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. fluxUnit object fluxUnit class. printFluxUnitCheatSheet, numeric represented short code, character representing descriptive name. moreTitle character specifying additional information go figure title, typically information specific estimation method used, default additional information cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex randomCensored logical, TRUE plot random value censored data.  Default FALSE. col color points plot, see ?par 'Color Specification' lwd number line width concLab object concUnit class, numeric represented short code,  character representing descriptive name. monthLab object monthLabel class, numeric represented short code,  character representing descriptive name. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":"/reference/fluxBiasMulti.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces 8-panel plot that is useful for determining if there is a flux bias problem — fluxBiasMulti","text":"","code":"eList <- Choptank_eList # Water year: fluxBiasMulti(eList)  fluxBiasMulti(eList, fluxUnit = 2)  # Graphs consisting of Jun-Aug eList <- setPA(eList,paStart=6,paLong=3) fluxBiasMulti(eList)"},{"path":"/reference/fluxBiasStat.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","title":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","text":"Computes three versions flux bias:    first censored values set miniumum.    second censored values set maximum.    third average two.       practice rarely noticable difference among .","code":""},{"path":"/reference/fluxBiasStat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","text":"","code":"fluxBiasStat(localSample)"},{"path":"/reference/fluxBiasStat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","text":"localSample data frame contains concentration data, default name Sample","code":""},{"path":"/reference/fluxBiasStat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","text":"fluxBias vector three numerical values, lower bound, upper bound average estimate ratio (mean estimated flux - mean observed flux) / mean estimated flux.  Typically one use fluxBias[3]","code":""},{"path":"/reference/fluxBiasStat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the flux bias statistic: (mean of estimated flux - mean of observed flux)  / mean of estimated flux — fluxBiasStat","text":"","code":"eList <- Choptank_eList Sample <- getSample(eList) fluxBias <- fluxBiasStat(Sample)"},{"path":"/reference/fluxUnit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"fluxUnit class — fluxUnit-class","title":"fluxUnit class — fluxUnit-class","text":"details fluxUnit class","code":""},{"path":"/reference/fluxUnit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"fluxUnit class — fluxUnit-class","text":"shortName character specifying short name. unitFactor numeric representing conversion factor unitName character specifying full name. unitExpress expression specifying full name starting Observed. unitExpressTiny expression specifying abbreviated name starting Observed. unitEstimate expression specifying full name starting Estimated. unitEstimateTiny expression specifying abbreviated name starting Estimated. unitUSGS character specifying flux full text. shortCode number quick lookup","code":""},{"path":"/reference/generalAxis.html","id":null,"dir":"Reference","previous_headings":"","what":"Axis generation for log discharge — generalAxis","title":"Axis generation for log discharge — generalAxis","text":"Discharge axis tick generation","code":""},{"path":"/reference/generalAxis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Axis generation for log discharge — generalAxis","text":"","code":"generalAxis(x, maxVal, minVal, units = NA, logScale = FALSE,   tinyPlot = FALSE, padPercent = 5, concentration = TRUE, concLab = 1,   usgsStyle = FALSE, prettyDate = TRUE)"},{"path":"/reference/generalAxis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Axis generation for log discharge — generalAxis","text":"x vector create scale maxVal number maximum value returned scale minVal number minimum value returned scale units character concentration units. Typically found INFO$param.units. logScale logical whether return log scale tinyPlot logical padPercent number used pad max min specified concentration logical concentration=TRUE, labels returned concentration units, otherwise flux units. concLab object concUnit class, numeric represented short code,  character representing descriptive name. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels prettyDate logical use 'pretty' limits date axis TRUE, force yearStart/yearEnd limits FALSE","code":""},{"path":"/reference/generalAxis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Axis generation for log discharge — generalAxis","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) INFO <- getInfo(eList) x <- Daily$Q max <- max(x) min <- 0 units <- INFO$param.units generalAxis(x, max, min, units) #> $ticks #> [1]   0  50 100 150 200 250 #>  #> $bottom #> [1] 0 #>  #> $top #> [1] 250 #>  #> $label #> [1] \"Concentration in mg/l as N\" #>  min <- min(x) generalAxis(x, max, min, units, log=TRUE) #> $ticks #>  [1] 5e-03 1e-02 2e-02 5e-02 1e-01 2e-01 5e-01 1e+00 2e+00 5e+00 1e+01 2e+01 #> [13] 5e+01 1e+02 2e+02 5e+02 #>  #> $bottom #> [1] 0.005 #>  #> $top #> [1] 500 #>  #> $label #> [1] \"Concentration in mg/l as N\" #>  generalAxis(Daily$ConcDay, 100, 0, concLab = \"concentration\") #> $ticks #>  [1]   0  10  20  30  40  50  60  70  80  90 100 #>  #> $bottom #> [1] 0 #>  #> $top #> [1] 100 #>  #> $label #> [1] \"Concentration in NA\" #>"},{"path":"/reference/genericEGRETDotPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic EGRET plotting function — genericEGRETDotPlot","title":"Generic EGRET plotting function — genericEGRETDotPlot","text":"Basic plotting framework EGRET dot plots. Graphical parameters default values work well plots, can re-assigned. See ?par complete definitions optional input variables.","code":""},{"path":"/reference/genericEGRETDotPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic EGRET plotting function — genericEGRETDotPlot","text":"","code":"genericEGRETDotPlot(x, y, xlim, ylim, xTicks = pretty(xlim),   yTicks = pretty(ylim), printTitle = TRUE, xaxs = \"i\", xlab = \"\",   yaxs = \"i\", ylab = \"\", plotTitle = \"\", pch = 20, cex = 0.7,   cex.main = 1.3, font.main = 2, cex.lab = 1.2, tcl = 0.5,   cex.axis = 1, las = 1, xDate = FALSE, tinyPlot = FALSE,   hLine = FALSE, oneToOneLine = FALSE, rmSciX = FALSE, rmSciY = FALSE,   customPar = FALSE, col = \"black\", lwd = 1, showXLabels = TRUE,   showYLabels = TRUE, showXAxis = TRUE, showYAxis = TRUE,   removeFirstX = FALSE, removeLastX = FALSE, removeFirstY = FALSE,   removeLastY = FALSE, ...)"},{"path":"/reference/genericEGRETDotPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic EGRET plotting function — genericEGRETDotPlot","text":"x vector specifying x data (required) y vector specifying y data (required) xlim vector specifying x plotting range (required) ylim vector specifying y plotting range (required) xTicks vector specifying x axis tick placement (required) yTicks vector specifying y axis tick placement (required) printTitle logical defaults TRUE, plotting parameter control whether title xaxs character defaults \"\", defines style x-axis interval calculation.  Possible values , r, e, s, d. xlab character defaults \"\", defines x label yaxs character defaults \"\", defines style y-axis interval calculation.  Possible values , r, e, s, d. ylab character defaults \"\", defines y label plotTitle character defaults \"\", defines plot title pch number defaults 20, specifies plot symbol cex number defaults 0.7, specifies plotting text magnification cex.main number defaults 1.3, specifies title text magnification font.main number defaults 2, specifies font use text cex.lab number defaults 1.2 specifies label text magnification tcl number defaults 0.5, specifies length tick marks fraction height line text. cex.axis number defaults 1, specifies axis text magnification las number represents style axis labels xDate logical defaults FALSE, changes x label \"year-month\" format set TRUE total years less 4. tinyPlot logical defaults FALSE, TRUE, changes defaults appropriate multi-plot hLine logical defaults FALSE, inserts horizontal line zero oneToOneLine logical defaults FALSE, inserts 1:1 line rmSciX logical defaults FALSE, changes x label scientific fixed rmSciY logical defaults FALSE, changes y label scientific fixed customPar logical defaults FALSE. TRUE, par() set user calling function col color points plot, see ?par 'Color Specification' lwd number line width showXLabels logical defaults TRUE. FALSE, x axis label plotted showYLabels logical defaults TRUE. FALSE, y axis label plotted showXAxis logical defaults TRUE. FALSE, x axis plotted showYAxis logical defaults TRUE. FALSE, y axis plotted removeFirstX logical defaults FALSE. TRUE, removes first x axis label. can handy plotting mutliple plots. removeLastX logical defaults FALSE. TRUE, removes last x axis label. can handy plotting mutliple plots. removeFirstY logical defaults FALSE. TRUE, removes first y axis label. can handy plotting mutliple plots. removeLastY logical defaults FALSE. TRUE, removes last y axis label. can handy plotting mutliple plots. ... additional graphical parameters can adjusted","code":""},{"path":"/reference/genericEGRETDotPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic EGRET plotting function — genericEGRETDotPlot","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) x <- Daily$Date y <- Daily$Q xlim <- c(min(x),max(x)) ylim <- c(min(y),1.05*max(y)) xlab <- \"Date\" ylab <- \"Flow\" genericEGRETDotPlot(x=x, y=y,                      xlim=xlim, ylim=ylim,                     xlab=xlab, ylab=ylab,                     plotTitle=\"Test\" )"},{"path":"/reference/genmissing.html","id":null,"dir":"Reference","previous_headings":"","what":"genmissing — genmissing","title":"genmissing — genmissing","text":"Written Tim Cohn","code":""},{"path":"/reference/genmissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"genmissing — genmissing","text":"","code":"genmissing(X1, XN, rho, N)"},{"path":"/reference/genmissing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"genmissing — genmissing","text":"X1 value gap XN value gap rho lag one autocorrelation N length sequence including X1 XN. two gap length","code":""},{"path":"/reference/genmissing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"genmissing — genmissing","text":"genmissing numeric vector length N, conditioned first value (X1) last value (XN) specified lag one autocorrelation limit (N large) values normal mean 0 variance 1","code":""},{"path":"/reference/getDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Daily dataframe from EGRET object — getDaily","title":"Get Daily dataframe from EGRET object — getDaily","text":"named list EGRET object, extract Daily dataframe","code":""},{"path":"/reference/getDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Daily dataframe from EGRET object — getDaily","text":"","code":"getDaily(x, ...)  # S3 method for egret getDaily(x, ...)  # S3 method for default getDaily(x, ...)"},{"path":"/reference/getDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Daily dataframe from EGRET object — getDaily","text":"x EGRET object named list ... additional parameters","code":""},{"path":"/reference/getDaily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Daily dataframe from EGRET object — getDaily","text":"Daily dataframe","code":""},{"path":[]},{"path":"/reference/getDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Daily dataframe from EGRET object — getDaily","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList)"},{"path":"/reference/getInfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Get INFO dataframe from EGRET object — getInfo","title":"Get INFO dataframe from EGRET object — getInfo","text":"named list EGRET object, extract INFO dataframe","code":""},{"path":"/reference/getInfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get INFO dataframe from EGRET object — getInfo","text":"","code":"getInfo(x, ...)  # S3 method for egret getInfo(x, ...)  # S3 method for default getInfo(x, ...)"},{"path":"/reference/getInfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get INFO dataframe from EGRET object — getInfo","text":"x EGRET object named list ... additional parameters","code":""},{"path":"/reference/getInfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get INFO dataframe from EGRET object — getInfo","text":"INFO dataframe","code":""},{"path":[]},{"path":"/reference/getInfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get INFO dataframe from EGRET object — getInfo","text":"","code":"eList <- Choptank_eList INFO <- getInfo(eList)"},{"path":"/reference/getSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Sample dataframe from EGRET object — getSample","title":"Get Sample dataframe from EGRET object — getSample","text":"named list EGRET object, extract Sample dataframe","code":""},{"path":"/reference/getSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Sample dataframe from EGRET object — getSample","text":"","code":"getSample(x, ...)  getSample(x, ...)  getSample.default(x, ...)"},{"path":"/reference/getSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Sample dataframe from EGRET object — getSample","text":"x EGRET object named list ... additional parameters","code":""},{"path":"/reference/getSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Sample dataframe from EGRET object — getSample","text":"Sample dataframe","code":""},{"path":[]},{"path":"/reference/getSample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Sample dataframe from EGRET object — getSample","text":"","code":"eList <- Choptank_eList Sample <- getSample(eList)"},{"path":"/reference/getSurfaces.html","id":null,"dir":"Reference","previous_headings":"","what":"Get surfaces matrix from EGRET object — getSurfaces","title":"Get surfaces matrix from EGRET object — getSurfaces","text":"named list EGRET object, extract surfaces matrix","code":""},{"path":"/reference/getSurfaces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get surfaces matrix from EGRET object — getSurfaces","text":"","code":"getSurfaces(x, ...)  # S3 method for egret getSurfaces(x, ...)  # S3 method for default getSurfaces(x, ...)"},{"path":"/reference/getSurfaces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get surfaces matrix from EGRET object — getSurfaces","text":"x EGRET object named list ... additional parameters","code":""},{"path":"/reference/getSurfaces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get surfaces matrix from EGRET object — getSurfaces","text":"Sample dataframe","code":""},{"path":[]},{"path":"/reference/getSurfaces.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get surfaces matrix from EGRET object — getSurfaces","text":"","code":"eList <- Choptank_eList surfaces <- getSurfaces(eList)"},{"path":"/reference/helperEGRET.html","id":null,"dir":"Reference","previous_headings":"","what":"EGRET helper functions — print.egret","title":"EGRET helper functions — print.egret","text":"small collection helper functions","code":""},{"path":"/reference/helperEGRET.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EGRET helper functions — print.egret","text":"","code":"# S3 method for egret print(x, ...)  # S3 method for egret plot(x, ...)  nDischarge(x)  nObservations(x)  nCensoredVals(x)"},{"path":"/reference/helperEGRET.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EGRET helper functions — print.egret","text":"x EGRET object ... additional parameters","code":""},{"path":[]},{"path":"/reference/helperEGRET.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EGRET helper functions — print.egret","text":"","code":"Choptank_eList #> Daily discharge: #>         Date        Q #> 1 1979-10-01 1.897229 #> ... #>             Date        Q #> 11688 2011-09-30 9.457827 #>  #> Sample data: #>         Date ConcLow ConcHigh        Q #> 1 1979-10-24    0.62     0.62 3.199804 #> ... #>           Date ConcLow ConcHigh        Q #> 606 2011-09-29     0.8      0.8 13.90357 #>  #> Choptank River:Inorganic nitrogen (nitrate and nitrite) #> Parameter units: mg/l as N  #> Drainage area: 292.6687 km^2 print(Arkansas_eList) #> Daily discharge: #>            Date     Q #> 9132 1989-10-01 37600 #> ... #>             Date    Q #> 17532 2012-09-30 2210 #>  #> Sample data: #>         Date    Q ConcLow ConcHigh #> 1 1990-09-18 1730      NA     0.05 #> ... #>           Date    Q ConcLow ConcHigh #> 254 2012-09-25 1030   0.043    0.043 #>  #> Arkansas River at Murray Lock and Dam (Lock and Dam No. 7):Ammonia #> Parameter units: mg/l as N  #> Drainage area: 395783.7 km^2 plot(Choptank_eList)  plot(Choptank_eList, cex.main=0.7)  nDischarge(Arkansas_eList) #> [1] 8401 nObservations(Arkansas_eList) #> [1] 254 nCensoredVals(Arkansas_eList) #> [1] 115"},{"path":"/reference/is.egret.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for EGRET object — is.egret","title":"Check for EGRET object — is.egret","text":"Checks object see EGRET object","code":""},{"path":"/reference/is.egret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for EGRET object — is.egret","text":"","code":"is.egret(x)"},{"path":"/reference/is.egret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for EGRET object — is.egret","text":"x object check","code":""},{"path":"/reference/is.egret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for EGRET object — is.egret","text":"logical","code":""},{"path":"/reference/is.egret.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for EGRET object — is.egret","text":"","code":"eList <- Choptank_eList is.egret(eList) #> [1] TRUE"},{"path":"/reference/jitterSam.html","id":null,"dir":"Reference","previous_headings":"","what":"jitter Sample — jitterSam","title":"jitter Sample — jitterSam","text":"function used cases numerical problems  estimation WRTDS model.  mostly happens bootstrap  estimation data sets large.  order reduce  collinearity explanatory variables, random noise added  time log discharge variables Sample data frame.","code":""},{"path":"/reference/jitterSam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"jitter Sample — jitterSam","text":"","code":"jitterSam(Sam, V = 0.2)"},{"path":"/reference/jitterSam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"jitter Sample — jitterSam","text":"Sam data frame least columns DecYear LogQ V multiplier sd LogQ jitter. example V = 0.02, means sd LnQ jitter 0.02*sdLQ","code":""},{"path":"/reference/jitterSam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"jitter Sample — jitterSam","text":"SamR data frame structured like Sam data frame  time discharge variables modified adding random jitter","code":""},{"path":"/reference/jitterSam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"jitter Sample — jitterSam","text":"","code":"eList <- Choptank_eList Sample_jitter <- jitterSam(eList$Sample)"},{"path":"/reference/logPretty1.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","title":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","text":"Axis tick marks log scale cases data cover many orders magnitude graph small.  tick marks designed progress factors 10.","code":""},{"path":"/reference/logPretty1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","text":"","code":"logPretty1(xMin, xMax)"},{"path":"/reference/logPretty1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","text":"xMin numeric value minimum value plotted, must > 0 xMax numeric value maximum value plotted, must > xMax","code":""},{"path":"/reference/logPretty1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","text":"xTicks vector representing values tick marks","code":""},{"path":"/reference/logPretty1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up tick marks for an axis with a log scale, where the graph is small — logPretty1","text":"","code":"xMin <- 0.7 xMax <- 990000 logPretty1(xMin, xMax) #> [1] 1e-01 1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 xMin <- 3 xMax <- 15 logPretty1(xMin, xMax) #> [1]   1  10 100"},{"path":"/reference/logPretty3.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up tick marks for an axis with a log scale — logPretty3","title":"Sets up tick marks for an axis with a log scale — logPretty3","text":"Axis tick marks log scale.  tick marks designed progress 3 tick marks every factor 10.  example: 2,5,10,20,50,100,200,500.","code":""},{"path":"/reference/logPretty3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up tick marks for an axis with a log scale — logPretty3","text":"","code":"logPretty3(xMin, xMax)"},{"path":"/reference/logPretty3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up tick marks for an axis with a log scale — logPretty3","text":"xMin numeric value minimum value plotted, must >0 xMax numeric value maximum value plotted, must >xMax","code":""},{"path":"/reference/logPretty3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up tick marks for an axis with a log scale — logPretty3","text":"xTicks vector representing values tick marks","code":""},{"path":"/reference/logPretty3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up tick marks for an axis with a log scale — logPretty3","text":"","code":"logPretty3(0.7, 990000) #>  [1] 5e-01 1e+00 2e+00 5e+00 1e+01 2e+01 5e+01 1e+02 2e+02 5e+02 1e+03 2e+03 #> [13] 5e+03 1e+04 2e+04 5e+04 1e+05 2e+05 5e+05 1e+06 logPretty3(3, 15) #> [1]  2  5 10 20"},{"path":"/reference/makeAnnualSeries.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"Part flowHistory system.  data come Daily INFO data frames.  Note function setPA must run establish period analysis (e.g. water year).","code":""},{"path":"/reference/makeAnnualSeries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"","code":"makeAnnualSeries(eList, edgeAdjust = TRUE)"},{"path":"/reference/makeAnnualSeries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"eList named list least Daily INFO dataframes edgeAdjust logical specifying whether use modified method  calculating windows edge record.  modified method tends  reduce curvature near start end record.   Default TRUE, logical INFO$edgeAdjust override default.","code":""},{"path":"/reference/makeAnnualSeries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"annualSeries matrix contains annual series streamflow statistics annualSeries matrix 3 * 8 * numYears, numYears number years data set first dimension 1 year, 2 actual value, 3 smoothed value second dimension, index istat value (identifying flow statistic) third dimension year","code":""},{"path":"/reference/makeAnnualSeries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"smooth loess smooth computed log flow values transformed back real space Smoothing window fixed number years, window width default value 20 years can modified changing value INFO data frame (using setPA function)","code":""},{"path":"/reference/makeAnnualSeries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces annual series of 8 streamflow statistics (and a lowess smooth of them) from daily streamflow data — makeAnnualSeries","text":"","code":"eList <- Choptank_eList annualSeries <- makeAnnualSeries(eList)"},{"path":"/reference/makeAugmentedSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"function used add two columns Sample data frame: rResid rObserved.  rResid randomized residual value computed log concentration units, rObserved  randomized 'observed' value concentration concentration units.  computed censored samples (\"less values\").  created purposes plotting used computations EGRET.","code":""},{"path":"/reference/makeAugmentedSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"","code":"makeAugmentedSample(eList)"},{"path":"/reference/makeAugmentedSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"eList named list least Sample dataframe","code":""},{"path":"/reference/makeAugmentedSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"eList named list modified Sample data frame.","code":""},{"path":"/reference/makeAugmentedSample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"WRTDS model must estimated function can run.  random value generated lies reporting limit zero distributed truncated log-normal distribution, parameters derived fitted WRTDS model. random values never used computations EGRET used purposes plotting data set residuals.  plotted functions shown open circles.","code":""},{"path":"/reference/makeAugmentedSample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create randomized residuals and observations for data sets that have some censored data — makeAugmentedSample","text":"","code":"choptankAugmented <- makeAugmentedSample(Choptank_eList)"},{"path":"/reference/makeDateInfo.html","id":null,"dir":"Reference","previous_headings":"","what":"makeDateInfo — makeDateInfo","title":"makeDateInfo — makeDateInfo","text":"Create data frame organizes date segmentations runSeries.","code":""},{"path":"/reference/makeDateInfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"makeDateInfo — makeDateInfo","text":"","code":"makeDateInfo(windowSide, surfaceStart, surfaceEnd, firstQDate0, lastQDate0)"},{"path":"/reference/makeDateInfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"makeDateInfo — makeDateInfo","text":"windowSide integer number automatically generated span sections,  default 7. NA, code use surfaceStart character (Date) YYYY-MM-DD. Date want analysis start, must surfaceEnd character (Date) YYYY-MM-DD. Date want analysis end, must end firstQDate0 character (Date) YYYY-MM-DD. first day used flow normalizing distributions, default  start eList$Daily lastQDate0 character (Date) YYYY-MM-DD. last day used flow normalizating distributions, default end eList$Daily","code":""},{"path":"/reference/makeDateInfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"makeDateInfo — makeDateInfo","text":"","code":"windowSide <- 7 surfaceStart <- \"1984-01-01\" surfaceEnd <- \"2012-12-31\" firstQDate0 <- \"1970-01-01\" lastQDate0 <- \"2014-06-01\" dateInfo <- makeDateInfo(windowSide,                           surfaceStart, surfaceEnd,                           firstQDate0, lastQDate0)"},{"path":"/reference/mergeReport.html","id":null,"dir":"Reference","previous_headings":"","what":"mergeReport — mergeReport","title":"mergeReport — mergeReport","text":"function three things.  1) transfers daily discharge value  Daily data frame Sample data frame days samples. 2) merges INFO, Daily Sample data frames form eList object,  3) prints \"report\" basic information Daily  Sample data frames.","code":""},{"path":"/reference/mergeReport.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mergeReport — mergeReport","text":"","code":"mergeReport(INFO, Daily, Sample = NA, surfaces = NA, verbose = TRUE,   interactive = NULL)"},{"path":"/reference/mergeReport.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mergeReport — mergeReport","text":"INFO dataframe metadata Sample Daily data frames. Daily dataframe containing daily discharge data Sample dataframe containing sample data surfaces matrix returned modelEstimation. Default NA. verbose logical specifying whether display summary information  Daily Sample dataframes. interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/mergeReport.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mergeReport — mergeReport","text":"eList named list least INFO, Daily data frames.  can also include Sample data frame.","code":""},{"path":"/reference/mergeReport.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"mergeReport — mergeReport","text":"must INFO Daily data frame function work. case study flow , consideration water quality.   water quality considered INFO, Daily, Sample need provided call function. Note Sample dataframe global environment  update flow information.","code":""},{"path":[]},{"path":"/reference/mergeReport.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mergeReport — mergeReport","text":"","code":"siteNumber <- '01491000' pCode <- '00631' # \\donttest{ Daily <- readNWISDaily(siteNumber,'00060', '1984-10-01', '') #> There are 13951 data points, and 13951 days. Sample <- readNWISSample(siteNumber,pCode, '1984-10-01', '') #> Warning: NWIS qw web services are being retired. #> Please see vignette('qwdata_changes', package = 'dataRetrieval') #> for more information. #> https://cran.r-project.org/web/packages/dataRetrieval/vignettes/qwdata_changes.html INFO <- readNWISInfo(siteNumber,pCode,interactive=FALSE) eList <- mergeReport(INFO, Daily, Sample) #>  #> There are 47 duplicated Sample dates. Sample <- eList$Sample plot(eList)   # Create eList with no water quality data:  eList <- mergeReport(INFO, Daily, Sample = NA) plotFour(eList)  # }"},{"path":"/reference/modelEstimation.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","title":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","text":"one function three things.  1) jack-knife cross-validation WRTDS model augments Sample data frame eList, 2) fits WRTDS model creating surfaces matrix places eList (surfaces matrix expresses estimated concentration function discharge time),  3) estimates daily values concentration flux, flow normalized concentration  flux places Daily data frame eList.  returns named list following dataframes: Daily, INFO, Sample, matrix: surfaces.","code":""},{"path":"/reference/modelEstimation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","text":"","code":"modelEstimation(eList, windowY = 7, windowQ = 2, windowS = 0.5,   minNumObs = 100, minNumUncen = 50, edgeAdjust = TRUE, verbose = TRUE,   run.parallel = FALSE)"},{"path":"/reference/modelEstimation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","text":"eList named list least INFO, Daily, Sample dataframes windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 minNumObs numeric specifying minimum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 edgeAdjust logical specifying whether use modified method calculating windows edge record. edgeAdjust method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether display progress message run.parallel logical run WRTDS parallel ","code":""},{"path":"/reference/modelEstimation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","text":"eList named list INFO, Daily, Sample dataframes, along surfaces matrix.","code":""},{"path":"/reference/modelEstimation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation process for the WRTDS (Weighted Regressions on Time, Discharge, and Season) — modelEstimation","text":"","code":"eList <- Choptank_eList # \\donttest{ eList <- modelEstimation(eList) #>  #>  first step running estCrossVal may take about 1 minute #>  estCrossVal % complete: #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Next step running  estSurfaces with survival regression: #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done # }"},{"path":"/reference/monthLabel-class.html","id":null,"dir":"Reference","previous_headings":"","what":"monthLabel class — monthLabel-class","title":"monthLabel class — monthLabel-class","text":"details monthLabel class","code":""},{"path":"/reference/monthLabel-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"monthLabel class — monthLabel-class","text":"monthAbbrev character specifying abbreviated month name. monthFull character specifying full month name monthSingle character specifying single letter month.","code":""},{"path":"/reference/multiPlotDataOverview.html","id":null,"dir":"Reference","previous_headings":"","what":"Produces a 4 panel plot that gives an overview of the data set prior to any processing — multiPlotDataOverview","title":"Produces a 4 panel plot that gives an overview of the data set prior to any processing — multiPlotDataOverview","text":"function produces 4 plots based data stored eList.   four plots 1) log concentration versus log discharge, 2) log concentration versus time 3) boxplot log concentration month,  4) side--side boxplot sampled discharges daily discharges.  save space, graphic labeled top 4 graph display. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/multiPlotDataOverview.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produces a 4 panel plot that gives an overview of the data set prior to any processing — multiPlotDataOverview","text":"","code":"multiPlotDataOverview(eList, qUnit = 2, cex.main = 1.2,   randomCensored = FALSE, logScaleConc = TRUE, logScaleQ = TRUE,   concLab = 1)"},{"path":"/reference/multiPlotDataOverview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produces a 4 panel plot that gives an overview of the data set prior to any processing — multiPlotDataOverview","text":"eList named list least Daily, Sample, INFO dataframes qUnit object qUnit class printqUnitCheatSheet,  numeric represented short code, character representing descriptive name. cex.main magnification used main titles relative current setting cex randomCensored logical. Show censored values randomized. Default FALSE. TRUE, makeAugmentedSample must run first. logScaleConc logical TRUE y concentration graphs plotted log axis. Default TRUE. logScaleQ logical TRUE y streamflow graphs plotted log axis. Default TRUE. concLab object concUnit class, numeric represented short code,  character representing descriptive name.","code":""},{"path":[]},{"path":"/reference/multiPlotDataOverview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produces a 4 panel plot that gives an overview of the data set prior to any processing — multiPlotDataOverview","text":"","code":"eList <- Choptank_eList # Water year: multiPlotDataOverview(eList, qUnit=1)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) multiPlotDataOverview(eList, qUnit=1)    # Custom axes: eList$INFO$param.units <- \"ng\" qConst_precip <- new(\"qUnit\",                      qShortName = \"   mm  \",                      qUnitFactor = 1,                      qUnitName = \"Millimeter\",                      qUnitExpress = expression(paste(\"Precipitation in \",mm)),                      qUnitTiny = expression(paste(\"Precipitation \", \"(\", mm, \")\")),                      shortCode = 1,                      unitUSGS = \"Precipitation, in mm\",                      prefix = \"Precipitation\")  deposition <- new(\"concUnit\",                   longPrefix = \"Deposition\",                   shortPrefix = \"Dep\")  multiPlotDataOverview(eList,                        qUnit = qConst_precip,                        concLab = deposition)"},{"path":"/reference/plot15.html","id":null,"dir":"Reference","previous_headings":"","what":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","title":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","text":"Part flowHistory system.  results expressed runoff (mm/day). individual plots constructed method used plotFlowSingle.  annual results based Water Year.  seasons defined following groups months: SON, DJF, MAM, JJA.","code":""},{"path":"/reference/plot15.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","text":"","code":"plot15(eList, yearStart, yearEnd)"},{"path":"/reference/plot15.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","text":"eList named list least Daily INFO dataframes yearStart numeric value year graph start, default NA, indicates graph start first annual value yearEnd numeric value year graph end, default NA, indicates graph end last annual value","code":""},{"path":"/reference/plot15.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","text":"formatting purposes best use following commands calling plot15 function (savePath pathname directory store output) #   plotName <- paste(savePath, \"plot15.\", eList$INFO$shortName, \".ps\", sep = \"\") #   postscript(file = plotName, width = 8, height = 10, horizontal = FALSE, family = \"Helvetica\") running plot15, user needs give command dev.()","code":""},{"path":[]},{"path":"/reference/plot15.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Makes 15 graphs of streamflow statistics on a single page.  These encompass the 7-day minimum, mean, and 1-day maximum for each of the following 5 Periods of Analysis: Annual, Fall, Winter, Spring and Summer. — plot15","text":"","code":"eList <- Choptank_eList # \\donttest{ plot15(eList, yearStart = 1980, yearEnd = 2010)  dev.off() #> null device  #>           1  # }"},{"path":"/reference/plot1of15.html","id":null,"dir":"Reference","previous_headings":"","what":"plots 1 of the 15 graphs of streamflow statistics on a single page — plot1of15","title":"plots 1 of the 15 graphs of streamflow statistics on a single page — plot1of15","text":"Part flowHistory system.  designed create component graphs function plot15. 15 graphs include annual four seasonal graphs 3 flow statistics: 1-day maximum, mean, 7-day minimum. computations involved ones used plotFlowSingle makeAnnualSeries","code":""},{"path":"/reference/plot1of15.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plots 1 of the 15 graphs of streamflow statistics on a single page — plot1of15","text":"","code":"plot1of15(eList, yearStart, yearEnd, qf, istat, isBottom = FALSE)"},{"path":"/reference/plot1of15.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plots 1 of the 15 graphs of streamflow statistics on a single page — plot1of15","text":"eList named list least Daily INFO dataframes yearStart numeric value year graph start yearEnd numeric value year graph end qf scale factor convert discharge cubic feet per second mm/day, 86 / (drainage area square kilometers) istat numeric value selecting flow statistic plotted, must integer 1 8 isBottom logical, TRUE graph bottom row thus needs x axis labels, FALSE need labels","code":""},{"path":"/reference/plot1of15.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plots 1 of the 15 graphs of streamflow statistics on a single page — plot1of15","text":"","code":"eList <- Choptank_eList plot1of15(eList, 1980, 2010, 0.2938476, 5)"},{"path":"/reference/plotConcHist.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph of annual concentration and flow normalized concentration versus year — plotConcHist","title":"Graph of annual concentration and flow normalized concentration versus year — plotConcHist","text":"Data come named list (eList), contains Daily dataframe daily flow data, INFO dataframe metadata. annual concentrations \"time-weighted\" mean concentrations (opposed \"flow-weighted\").  annual results reported specified \"period analysis\" can  entire water year, calendar, season even individual month.   User specifies period analysis call setupYears. User can specify plotting three possible series.  units mg/L.   Annual mean concentration    WRTDS_K version annual mean concentration (requires WRTDSKalman run)   Flow normalized mean concentration Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/plotConcHist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph of annual concentration and flow normalized concentration versus year — plotConcHist","text":"","code":"plotConcHist(eList, yearStart = NA, yearEnd = NA, concMax = NA,   printTitle = TRUE, tinyPlot = FALSE, usgsStyle = FALSE,   plotFlowNorm = TRUE, plotAnnual = TRUE, plotGenConc = FALSE,   cex = 0.8, cex.axis = 1.1, cex.main = 1.1, lwd = 2, col = \"black\",   col.pred = \"green\", concLab = 1, col.gen = \"red\", customPar = FALSE,   ...)"},{"path":"/reference/plotConcHist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph of annual concentration and flow normalized concentration versus year — plotConcHist","text":"eList named list least Daily INFO dataframes yearStart numeric calendar year containing first estimated annual value plotted, default NA (allows set automatically data) yearEnd numeric calendar year just last estimated annual value plotted, default NA (allows set automatically data) concMax numeric. Maximum value concentration plotted. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels plotFlowNorm logical variable TRUE flow normalized line plotted, FALSE plotted plotAnnual logical variable TRUE, annual concentration points WRTDS output plotted, FALSE plotted plotGenConc logical variable. TRUE, annual concentration points WRTDS_K output plotted, FALSE plotted cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex lwd number magnification line width. col color points plot, see ?par 'Color Specification' col.pred color flow normalized line plot, see ?par 'Color Specification' concLab object concUnit class, numeric represented short code,  character representing descriptive name. col.gen color points WRTDS_K output plot, see ?par 'Color Specification' customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotConcHist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph of annual concentration and flow normalized concentration versus year — plotConcHist","text":"","code":"yearStart <- 2001 yearEnd <- 2010 eList <- Choptank_eList  plotConcHist(eList, yearStart, yearEnd)"},{"path":"/reference/plotConcPred.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of Observed Concentration versus Estimated Concentration — plotConcPred","title":"Plot of Observed Concentration versus Estimated Concentration — plotConcPred","text":"Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/plotConcPred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of Observed Concentration versus Estimated Concentration — plotConcPred","text":"","code":"plotConcPred(eList, concMax = NA, logScale = FALSE, printTitle = TRUE,   tinyPlot = FALSE, cex = 0.8, cex.axis = 1.1, cex.main = 1.1,   customPar = FALSE, col = \"black\", lwd = 1, randomCensored = FALSE,   concLab = 1, usgsStyle = FALSE, ...)"},{"path":"/reference/plotConcPred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of Observed Concentration versus Estimated Concentration — plotConcPred","text":"eList named list least Sample INFO dataframes concMax number specifying maximum value used vertical axis, default NA (allows set automatically data) logScale logical, default TRUE, TRUE indicates x y axes log scale. FALSE indicates x y arithmetic scale. printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width randomCensored logical. Show censored values randomized. concLab object concUnit class, numeric represented short code,  character representing descriptive name. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotConcPred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of Observed Concentration versus Estimated Concentration — plotConcPred","text":"","code":"eList <- Choptank_eList # Water year: plotConcPred(eList)   # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotConcPred(eList)"},{"path":"/reference/plotConcQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of Observed Concentration versus Discharge — plotConcQ","title":"Plot of Observed Concentration versus Discharge — plotConcQ","text":"Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata. Discharge plotted log scale. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/plotConcQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of Observed Concentration versus Discharge — plotConcQ","text":"","code":"plotConcQ(eList, qUnit = 2, tinyPlot = FALSE, logScale = FALSE,   randomCensored = FALSE, concMax = NA, concMin = NA,   printTitle = TRUE, cex = 0.8, cex.axis = 1.1, cex.main = 1.1,   usgsStyle = FALSE, rmSciX = FALSE, rmSciY = FALSE, customPar = FALSE,   col = \"black\", lwd = 1, concLab = 1, ...)"},{"path":"/reference/plotConcQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of Observed Concentration versus Discharge — plotConcQ","text":"eList named list least Sample INFO dataframes qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. tinyPlot logical variable, TRUE plot designed plotted small part multipart figure, default FALSE. logScale logical TRUE x y plotted log axis randomCensored logical. Show censored values randomized. concMax number specifying maximum value used vertical axis, default NA (allows set automatically data) concMin numeric value lower limit concentration shown vertical log graph, default NA  (causes lower limit set automatically, based data). value ignored linear scales, using 0 minimum value concentration axis. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. rmSciX logical defaults FALSE, changes x label scientific fixed rmSciY logical defaults FALSE, changes y label scientific fixed customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width concLab object concUnit class, numeric represented short code,  character representing descriptive name. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":"/reference/plotConcQ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot of Observed Concentration versus Discharge — plotConcQ","text":"function two possible ways plot censored values (e.g. \"less-values\"). default plot vertical line goes reporting limit bottom graph. alternative set randomCensored = TRUE.  case random value used plotting individual sample value.  random value lies reporting limit zero distributed truncated log normal based fitted WRTDS model. function makeAugmentedSample must run first randomCensored = TRUE.  Running makeAugmentedSample requires modelEstimation already run. random censored values used create readable plots used computations data set.  random censored values shown open circles non-censored data shown filled dots.","code":""},{"path":[]},{"path":"/reference/plotConcQ.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of Observed Concentration versus Discharge — plotConcQ","text":"","code":"eList <- Choptank_eList # Water year: plotConcQ(eList)  plotConcQ(eList, logScale=TRUE)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotConcQ(eList)"},{"path":"/reference/plotConcQSmooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot up to three curves representing the concentration versus discharge relationship. Each curve is a different point in time. — plotConcQSmooth","title":"Plot up to three curves representing the concentration versus discharge relationship. Each curve is a different point in time. — plotConcQSmooth","text":"plots like vertical slice estimated concentration surface seen plotContours function.   plots show concentration-discharge relationship changing time.  Typically time points selected three years time year spaced period record.  necessary.   Another possibility use explore seasonal differences.  case three dates year different times year. plot can also help identify situations windowQ may small.  substantial oscillations curves, windowQ increased.  Alternatively, windowQ may large.  can seen windowQ reduced (say 1.0).  good choice windowQ value just great enough damp oscillations curves. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotConcQSmooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot up to three curves representing the concentration versus discharge relationship. Each curve is a different point in time. — plotConcQSmooth","text":"","code":"plotConcQSmooth(eList, date1, date2, date3, qLow, qHigh, qUnit = 2,   legendLeft = 0, legendTop = 0, concMax = NA, concMin = NA,   bw = FALSE, printTitle = TRUE, printValues = FALSE, minNumObs = 100,   minNumUncen = 50, colors = c(\"black\", \"red\", \"green\"),   printLegend = TRUE, windowY = 7, windowQ = 2, windowS = 0.5,   tinyPlot = FALSE, customPar = FALSE, lwd = 2, cex = 0.8,   cex.axis = 1.1, cex.main = 1.1, cex.legend = 1.2, lineVal = c(1, 1,   1), logScale = FALSE, edgeAdjust = TRUE, concLab = 1,   usgsStyle = FALSE, ...)"},{"path":"/reference/plotConcQSmooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot up to three curves representing the concentration versus discharge relationship. Each curve is a different point in time. — plotConcQSmooth","text":"eList named list least Sample INFO dataframes date1 character specifying date first curve graph, form \"yyyy-mm-dd\" (must quotes) date2 character specifying date second curve graph, form \"yyyy-mm-dd\" (must quotes).  one curve wanted NA date3 character specifying date third curve graph, form \"yyyy-mm-dd\" (must quotes).  third curve wanted NA qLow numeric value lowest discharge considered, expressed units discharge used (specified qUnit) qHigh numeric value highest discharge considered, expressed units discharge used (specified qUnit) qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. legendLeft numeric represents left edge legend units plot. legendTop numeric represents top edge legend units plot. concMax numeric value upper limit concentration shown graph, default = NA (causes upper limit set automatically, based data) concMin numeric value lower limit concentration shown vertical log graph, default NA  (causes lower limit set automatically, based data). value ignored linear scales, using 0 minimum value concentration axis. bw logical TRUE graph produced black white, default FALSE (means use color) printTitle logical variable TRUE title printed, FALSE printed printValues logical variable TRUE results shown graph also printed console returned dataframe (can useful quantifying changes seen visually graph), default FALSE (printed) minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 colors color vector lines plot, see ?par 'Color Specification'. Defaults c(\"black\",\"red\",\"green\") printLegend logical TRUE, legend included windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 tinyPlot logical variable, TRUE plot designed plotted small part multipart figure, default FALSE. customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. lwd number line width, default 2 cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex cex.legend magnification used legend annotation relative current setting cex lineVal vector line types. Defaults c(1,1,1) solid line line. Options: 0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash logScale logical whether use log scale y axis. Default FALSE edgeAdjust logical specifying whether use modified method calculating windows edge record.  modified method tends reduce curvature near start end record.  Default TRUE. concLab object concUnit class, numeric represented short code,  character representing descriptive name. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotConcQSmooth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot up to three curves representing the concentration versus discharge relationship. Each curve is a different point in time. — plotConcQSmooth","text":"","code":"date1 <- \"1982-06-01\" date2 <- \"1994-06-01\" date3 <- \"2010-06-01\" qLow <- 0.5 qHigh <- 50 eList <- Choptank_eList # \\donttest{ plotConcQSmooth(eList, date1, date2, date3, qLow, qHigh,                  legendLeft = 0.6, legendTop = 0.7)  plotConcQSmooth(eList, date1, date2, date3, qLow, qHigh,                 logScale=TRUE, legendLeft = 0.6, legendTop = 0.7)  # }"},{"path":"/reference/plotConcTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of Observed Concentration versus Time — plotConcTime","title":"Plot of Observed Concentration versus Time — plotConcTime","text":"function allows user plot data, also limit two ways.    data can limited observed concentrations collected specified discharge range.    data can also limited observed certain months year.      two selection criteria can combined. example,      may want plot data discharges 100 500 cubic feet per second months March, April May. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotConcTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of Observed Concentration versus Time — plotConcTime","text":"","code":"plotConcTime(eList, qUnit = 2, yearStart = NA, yearEnd = NA,   qLower = NA, qUpper = NA, randomCensored = FALSE, tinyPlot = FALSE,   concMax = NA, concMin = NA, printTitle = TRUE, logScale = FALSE,   cex = 0.8, cex.axis = 1.1, cex.main = 1.1, customPar = FALSE,   col = \"black\", lwd = 1, concLab = 1, usgsStyle = FALSE, ...)"},{"path":"/reference/plotConcTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of Observed Concentration versus Time — plotConcTime","text":"eList named list least Sample INFO dataframes qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. yearStart numeric calendar year containing first estimated annual value plotted, default NA (allows set automatically data) yearEnd numeric calendar year just last estimated annual value plotted, default NA (allows set automatically data) qLower numeric lower bound values discharge used select data points plotted, units specified qUnit, default = NA equivalent lower bound zero desired lower bound zero use qLower = NA qUpper numeric upper bound values discharge selection data points plotted, units specified qUnit, default = NA equivalent upper bound infinity randomCensored logical. Show censored values randomized. tinyPlot logical variable, TRUE plot designed plotted small part multipart figure, default FALSE. concMax numeric value maximum value used vertical axis, default NA (allows set automatically data) concMin numeric value lower limit concentration shown vertical log graph, default NA  (causes lower limit set automatically, based data). value ignored linear scales, using 0 minimum value concentration axis. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure). logScale logical. TRUE concentration plotted log axis, default FALSE. cex numerical value giving amount plotting symbols magnified. cex.axis magnification used axis annotation relative current setting cex. cex.main magnification used main titles relative current setting cex. customPar logical defaults FALSE. TRUE, par() set user calling function. (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width. concLab object concUnit class, numeric represented short code,  character representing descriptive name. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels ... arbitrary functions sent generic plotting function.  See ?par details possible parameters.","code":""},{"path":"/reference/plotConcTime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot of Observed Concentration versus Time — plotConcTime","text":"function two possible ways plot censored values (e.g. \"less-values\"). default plot vertical line goes reporting limit bottom graph. alternative set randomCensored = TRUE.  case random value used plotting individual sample value.  random value lies reporting limit zero distributed truncated log normal based fitted WRTDS model. function makeAugmentedSample must run first randomCensored = TRUE.  Running makeAugmentedSample requires modelEstimation already run. random censored values used create readable plots used computations data set.  random censored values shown open circles non-censored data shown filled dots.","code":""},{"path":[]},{"path":"/reference/plotConcTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of Observed Concentration versus Time — plotConcTime","text":"","code":"eList <- Choptank_eList # Water year: plotConcTime(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotConcTime(eList,               qUnit = 1,              qLower = 100,              qUpper = 10000)  plotConcTime(eList, logScale=TRUE)  plotConcTime(eList,               qUnit = 1,               qLower = 100, qUpper = 10000,               randomCensored = TRUE)"},{"path":"/reference/plotConcTimeDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the time series of daily concentration estimates and the sample values for the days that were sampled — plotConcTimeDaily","title":"Plot of the time series of daily concentration estimates and the sample values for the days that were sampled — plotConcTimeDaily","text":"plot useful visual examination ability WRTDS, model, fit  data, seen time-series perspective.  graph useful covers period just years complete record complete record can done repeated use series segments. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotConcTimeDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the time series of daily concentration estimates and the sample values for the days that were sampled — plotConcTimeDaily","text":"","code":"plotConcTimeDaily(eList, yearStart = NA, yearEnd = NA, tinyPlot = FALSE,   concMax = NA, printTitle = TRUE, cex = 0.8, cex.axis = 1.1,   randomCensored = FALSE, cex.main = 1.1, customPar = FALSE,   col = \"black\", lwd = 1, prettyDate = TRUE, usgsStyle = FALSE, ...)"},{"path":"/reference/plotConcTimeDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the time series of daily concentration estimates and the sample values for the days that were sampled — plotConcTimeDaily","text":"eList named list least Daily, Sample, INFO dataframes yearStart numeric specifying starting date (expressed decimal years, example 1989.0) plot yearEnd numeric specifiying ending date plot tinyPlot logical variable, TRUE plot designed short wide, default FALSE. concMax number specifying maximum value used vertical axis, default NA (allows set automatically data) printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex randomCensored TRUE plot random value censored data.  Default FALSE. cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width prettyDate logical use 'pretty' limits date axis TRUE, force yearStart/yearEnd limits FALSE usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels ... arbitrary functions sent generic plotting function.  See ?par details possible parameters","code":""},{"path":[]},{"path":"/reference/plotConcTimeDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the time series of daily concentration estimates and the sample values for the days that were sampled — plotConcTimeDaily","text":"","code":"eList <- Choptank_eList # Water year: plotConcTimeDaily(eList)  plotConcTimeDaily(eList, yearStart=1998,yearEnd=2001)"},{"path":"/reference/plotConcTimeSmooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot up to three curves representing the concentration versus time relationship, each curve representing a different flow. — plotConcTimeSmooth","title":"Plot up to three curves representing the concentration versus time relationship, each curve representing a different flow. — plotConcTimeSmooth","text":"plots show concentration-time relationship changing flow. plot can also help identify situations windowY may small.  substantial oscillations curves, windowY increased. Alternatively, windowY may large.  can seen windowY reduced (say 4.0).  good choice windowY value just great enough damp oscillations curves. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data INFO dataframe metadata.","code":""},{"path":"/reference/plotConcTimeSmooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot up to three curves representing the concentration versus time relationship, each curve representing a different flow. — plotConcTimeSmooth","text":"","code":"plotConcTimeSmooth(eList, q1, q2, q3, centerDate, yearStart, yearEnd,   qUnit = 2, legendLeft = 0, legendTop = 0, concMax = NA,   concMin = NA, bw = FALSE, printTitle = TRUE, colors = c(\"black\",   \"red\", \"green\"), printValues = FALSE, tinyPlot = FALSE, concLab = 1,   monthLab = 1, minNumObs = 100, minNumUncen = 50, windowY = 10,   windowQ = 2, windowS = 0.5, cex.main = 1.1, lwd = 2,   printLegend = TRUE, cex.legend = 1.2, cex = 0.8, cex.axis = 1.1,   customPar = FALSE, lineVal = c(1, 1, 1), logScale = FALSE,   edgeAdjust = TRUE, usgsStyle = FALSE, ...)"},{"path":"/reference/plotConcTimeSmooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot up to three curves representing the concentration versus time relationship, each curve representing a different flow. — plotConcTimeSmooth","text":"eList named list least Sample INFO dataframes q1 numeric discharge value first curve shown plot. expressed units specified qUnit. q2 numeric discharge value second curve shown plot. expressed units specified qUnit. want second curve argument must q2=NA q3 numeric discharge value third curve shown plot. expressed units specified qUnit. want third curve argument must q3=NA centerDate character time year used center date smoothing. expressed month day must form \"mm-dd\" yearStart numeric starting year graph. first value plotted curve first instance centerDate year designated yearStart. yearEnd numeric end sequence values plotted graph.last value last instance centerDate prior start yearEnd. (Note, number values plotted curve yearEnd-yearStart.) qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. legendLeft numeric represents left edge legend units plot. legendTop numeric represents top edge legend units plot. concMax numeric value upper limit concentration shown graph, default = NA (causes upper limit set automatically, based data) concMin numeric value lower limit concentration shown vertical log graph, default NA  (causes lower limit set automatically, based data). value ignored linear scales, using 0 minimum value concentration axis. bw logical TRUE graph produced black white, default FALSE (means use color) printTitle logical variable TRUE title printed, FALSE printed colors color vector lines plot, see ?par 'Color Specification'. Defaults c(\"black\",\"red\",\"green\") printValues logical variable TRUE results shown graph printed console returned dataframe (can useful quantifying changes seen visually graph), default FALSE (printed) tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE concLab object concUnit class, numeric represented short code,  character representing descriptive name. monthLab object monthLabel class, numeric represented short code,  character representing descriptive name. minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 windowY numeric specifying half-window width time dimension, units years, default 10 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 cex.main magnification used main titles relative current setting cex lwd line width, positive number, defaulting 2 printLegend logical TRUE, legend included cex.legend number magnification  legend cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. lineVal vector line types. Defaults c(1,1,1) solid line line. Options: 0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash logScale logical whether use log scale y axis. edgeAdjust logical specifying whether use modified method calculating windows edge record.  modified method tends reduce curvature near start end record.  Default TRUE. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels ... arbitrary functions sent generic plotting function.  See ?par details possible parameters","code":""},{"path":[]},{"path":"/reference/plotConcTimeSmooth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot up to three curves representing the concentration versus time relationship, each curve representing a different flow. — plotConcTimeSmooth","text":"","code":"q1 <- 1 q2 <- 10 q3 <- 100 centerDate <- \"07-01\" yearStart <- 1990 yearEnd <- 2010 eList <- Choptank_eList plotConcTimeSmooth(eList, q1, q2,q3, centerDate,                     yearStart, yearEnd, legendLeft = 1997,                     legendTop = 0.44, cex.legend = 0.9)  plotConcTimeSmooth(eList, q1, q2,q3, centerDate, yearStart,                     yearEnd, logScale = TRUE, legendLeft = 1994,                     legendTop = 0.4, cex.legend = 0.9)"},{"path":"/reference/plotContours.html","id":null,"dir":"Reference","previous_headings":"","what":"Color contour plot of the estimated surfaces as a function of discharge and time (surfaces include log concentration, standard error, and concentration) — plotContours","title":"Color contour plot of the estimated surfaces as a function of discharge and time (surfaces include log concentration, standard error, and concentration) — plotContours","text":"plots normally used plotting estimated concentration surface (whatSurface = 3) can used explore  estimated surfaces log concentration standard error (log space) determines bias correction.  plots often interpretable time limits plot less decade. explore changes long time period best multiple times, various time slices 2 years (example) use function plotDiffContours. Although lot optional arguments function, set logical default. Obtaining plot provides good insight useful experiment several arguments yearStart, yearEnd, qBottom, qTop, contourLevels. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotContours.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Color contour plot of the estimated surfaces as a function of discharge and time (surfaces include log concentration, standard error, and concentration) — plotContours","text":"","code":"plotContours(eList, yearStart, yearEnd, qBottom = NA, qTop = NA,   whatSurface = 3, qUnit = 2, contourLevels = NA, span = 60,   pval = 0.05, printTitle = TRUE, vert1 = NA, vert2 = NA, horiz = NA,   tcl = 0.03, flowDuration = TRUE, customPar = FALSE, yTicks = NA,   tick.lwd = 1, usgsStyle = FALSE, lwd = 2, cex.main = 1,   cex.axis = 1, concLab = 1, color.palette = colorRampPalette(c(\"white\",   \"gray\", \"blue\", \"red\")), ...)"},{"path":"/reference/plotContours.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Color contour plot of the estimated surfaces as a function of discharge and time (surfaces include log concentration, standard error, and concentration) — plotContours","text":"eList named list least Daily INFO dataframes, surfaces matrix yearStart numeric value starting date graph, expressed decimal year (typically whole number 1989.0) yearEnd numeric value ending date graph, expressed decimal year, (example 1993.0) qBottom numeric value bottom edge graph, expressed units discharge used (specified qUnit). NA choose \"pretty\" lower limit nearest 5% discharge.  yTicks specified, first value yTicks becomes lowest discharge shown figure. qTop numeric value top edge graph, expressed units discharge used (specified qUnit). NA choose \"pretty\" upper limit nearest 95% discharge. yTicks specified, last value yTicks becomes highest discharge shown figure. whatSurface numeric value, can accept 1, 2, 3;  whatSurface=1 yHat (log concentration), whatSurface=2 SE (standard error log concentration), whatSurface=3 ConcHat (unbiased estimate concentration), default = 3. qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. contourLevels numeric vector containing contour levels contour plot, arranged ascending order, default NA (causes contour levels set automatically, based data) span numeric, half-width (days) smoothing window computing flow duration information, default = 60 pval numeric, probability value lower flow frequency line graph printTitle logical variable TRUE title printed, FALSE printed vert1 numeric, location time black vertical line figure, yearStart<vert1<yearEnd, default NA (vertical line drawn) vert2 numeric, location time black vertical line figure, yearStart<vert2<yearEnd, default NA (vertical line drawn) horiz numeric, location discharge black horizontal line figure, qBottom<vert1<qTop, default NA (horizontal line drawn) tcl numeric, length tick marks inches, default 0.03 flowDuration logical variable TRUE plot flow duration lines (5 95 flow percentiles), FALSE plot , default = TRUE customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins. yTicks vector yTick labels marks plotted log space. (example yTicks = c(3, 5, 10, 20, 50, 100, 200, 400). first last values determine range y axis. NA, tick marks automatically generated. tick.lwd line width axis ticks, default 1 usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. lwd numeric, line width flowDuration curve, default 2 cex.main magnification used main titles relative current setting cex cex.axis magnification used axis annotation relative current setting cex concLab object concUnit class, numeric represented short code,  character representing descriptive name. color.palette function creates color palette contour plot. Default goes white gray blue red  using function colorRampPalette(c(\"white\",\"gray\",\"blue\",\"red\")). preset options heat.colors, topo.colors, terrain.colors. ... arbitrary functions sent generic plotting function.  See ?par details possible parameters","code":""},{"path":"/reference/plotContours.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Color contour plot of the estimated surfaces as a function of discharge and time (surfaces include log concentration, standard error, and concentration) — plotContours","text":"","code":"yearStart <- 2002 yearEnd <- 2010 qBottom <- 0.5 qTop<- 20 clevel <- seq(0,2,0.25) eList <- Choptank_eList plotContours(eList, yearStart, yearEnd, qBottom, qTop,               contourLevels = clevel)    plotContours(eList, yearStart, yearEnd, qBottom, qTop = 50,               contourLevels = clevel, flowDuration = FALSE)   colors <- colorRampPalette(c(\"white\",\"black\")) plotContours(eList, yearStart, yearEnd, qBottom, qTop = 50,               contourLevels = clevel, color.palette = colors,               flowDuration = FALSE)"},{"path":"/reference/plotDiffContours.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots the difference between two years from a contour plot created by plotContours — plotDiffContours","title":"Plots the difference between two years from a contour plot created by plotContours — plotDiffContours","text":"plots normally used plotting changes estimated concentration surface (whatSurface=3) can used explore  changes estimated surfaces log concentration standard error (log space) determines bias correction. difference can shown either arithmetic difference percentage difference. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotDiffContours.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots the difference between two years from a contour plot created by plotContours — plotDiffContours","text":"","code":"plotDiffContours(eList, year0, year1, qBottom = NA, qTop = NA,   maxDiff = NA, whatSurface = 3, tcl = 0.03, qUnit = 2, span = 60,   pval = 0.05, printTitle = TRUE, plotPercent = FALSE, vert1 = NA,   vert2 = NA, horiz = NA, flowDuration = TRUE, yTicks = NA,   tick.lwd = 1, lwd = 2, cex.main = 0.95, cex.axis = 1,   customPar = FALSE, usgsStyle = FALSE,   color.palette = colorRampPalette(c(\"blue\", \"white\", \"red\")), concLab = 1,   monthLab = 1, ...)"},{"path":"/reference/plotDiffContours.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots the difference between two years from a contour plot created by plotContours — plotDiffContours","text":"eList named list least Daily INFO dataframes, surfaces matrix year0 numeric value calendar year first year pair years analysis, whole number year1 numeric value calendar year second year pair years analysis, whole number qBottom numeric value bottom edge graph, expressed units discharge used (specified qUnit). NA choose \"pretty\" lower limit nearest 5% discharge. yTicks specified, first value yTicks becomes lowest discharge shown figure. qTop numeric value top edge graph, expressed units discharge used (specified qUnit). NA choose \"pretty\" upper limit nearest 95% discharge. yTicks specified, last value yTicks becomes highest discharge shown figure. maxDiff numeric value absolute value largest change concentration shown figure. NA, scale set 5% 95% concentration difference. plotPercent = TRUE maxDiff maximum percentage difference. whatSurface numeric value, can accept 1, 2, 3;  whatSurface = 1 yHat (log concentration), whatSurface = 2 SE (standard error log concentration), whatSurface = 3 ConcHat (unbiased estimate concentration), default = 3 tcl numeric, length tick marks inches, default 0.1 qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. span numeric, half-width (days) smoothing window computing flow duration information, default = 60 pval numeric, probability value lower flow frequency line graph printTitle logical variable TRUE title printed, FALSE printed plotPercent logical. TRUE, plots percent difference, FALSE, plots arithmetic differences. Defaults FALSE. vert1 numeric, location time black vertical line figure, yearStart < vert1 < yearEnd, default NA (vertical line drawn) vert2 numeric, location time black vertical line figure, yearStart < vert2 < yearEnd, default NA (vertical line drawn) horiz numeric, location discharge black horizontal line figure, qBottom<vert1<qTop, default NA (horizontal line drawn) flowDuration logical variable TRUE plot flow duration lines (5 95 flow percentiles), FALSE plot , default = TRUE yTicks vector yTick labels marks plotted log space. (example yTicks = c(3, 5, 10, 20, 50, 100, 200, 400). first last values determine range y axis. NA, tick marks automatically generated. tick.lwd line width axis ticks, default 2 lwd numeric, line width flowDuration curve, default 1 cex.main magnification used main titles relative current setting cex cex.axis magnification used axis annotation relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. color.palette function creates color palette contour plot. Default goes blue white red  using function colorRampPalette(c(\"blue\",\"white\",\"red\")). preset options heat.colors, topo.colors, terrain.colors. concLab object concUnit class, numeric represented short code,  character representing descriptive name. monthLab object monthLabel class, numeric represented short code,  character representing descriptive name. ... arbitrary functions sent generic plotting function.  See ?par details possible parameters","code":""},{"path":"/reference/plotDiffContours.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots the difference between two years from a contour plot created by plotContours — plotDiffContours","text":"","code":"year0 <- 1990 year1 <- 2009 qBottom <- 0.5 qTop <- 20 maxDiff<-0.5 eList <- Choptank_eList plotDiffContours(eList, year0, year1, qBottom, qTop, maxDiff = 0.5)  plotDiffContours(eList, year0, year1, qBottom, qTop, maxDiff = 50, plotPercent = TRUE)"},{"path":"/reference/plotFlowSingle.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","title":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","text":"part flowHistory system. index flow statistics istat.  statistics :  (1) 1-day minimum, (2) 7-day minimum, (3) 30-day minimum, (4) median (5) mean, (6) 30-day maximum, (7) 7-day maximum, (8) 1-day maximum Although lot optional arguments function, set logical default. Data come named list, contains Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotFlowSingle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","text":"","code":"plotFlowSingle(eList, istat, yearStart = NA, yearEnd = NA, qMax = NA,   printTitle = TRUE, tinyPlot = FALSE, customPar = FALSE,   runoff = FALSE, qUnit = 1, printStaName = TRUE, printPA = TRUE,   usgsStyle = FALSE, printIstat = TRUE, cex = 0.8, cex.axis = 1.1,   cex.main = 1.1, lwd = 2, col = \"black\", ...)"},{"path":"/reference/plotFlowSingle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","text":"eList named list least Daily INFO dataframes istat numeric value flow statistic graphed (possible values 1 8) yearStart numeric value year graph start, default NA, indicates graph start first annual value yearEnd numeric value year graph end, default NA, indicates graph end last annual value qMax numeric value maximum value used y-axis graph, default NA means graph self-scaling printTitle logical variable, TRUE title printed, FALSE title printed, default TRUE tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. runoff logical variable, TRUE streamflow data converted runoff values mm/day qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. printStaName logical variable, TRUE station name printed title, FALSE printed, default TRUE printPA logical variable, TRUE Period Analysis information printed title, FALSE printed, default TRUE usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. printIstat logical variable, TRUE print statistic name printed title, FALSE printed, default TRUE cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex lwd number line width col color points plot, see ?par 'Color Specification' ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":"/reference/plotFlowSingle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","text":"curve plotted graph loess smooth data.   smooth computed logs data transformed back plot. width smoothing window 20 years either side year plotted However, window width can adjusted using setPA function.","code":""},{"path":[]},{"path":"/reference/plotFlowSingle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a plot of a time series of a particular flow statistic and a loess smooth of that flow statistic — plotFlowSingle","text":"","code":"eList <- Choptank_eList # Water year: plotFlowSingle(eList, 1)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotFlowSingle(eList, 1)"},{"path":"/reference/plotFluxHist.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph of annual flux and flow normalized flux versus year — plotFluxHist","title":"Graph of annual flux and flow normalized flux versus year — plotFluxHist","text":"annual results reported specified \"period analysis\" can  entire water year, calendar, season even individual month.  user specifies period analysis call setupYears. Values plotted express flux rate, thousand kg per year period analysis less year, equal mass transported period analysis Although lot optional arguments function, set logical default. Data come named list (eList), contains Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotFluxHist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph of annual flux and flow normalized flux versus year — plotFluxHist","text":"","code":"plotFluxHist(eList, yearStart = NA, yearEnd = NA, fluxUnit = 9,   fluxMax = NA, printTitle = TRUE, usgsStyle = FALSE,   plotFlowNorm = TRUE, plotAnnual = TRUE, plotGenFlux = FALSE,   tinyPlot = FALSE, col = \"black\", col.pred = \"green\", col.gen = \"red\",   cex = 0.8, cex.axis = 1.1, cex.main = 1.1, lwd = 2,   customPar = FALSE, ...)"},{"path":"/reference/plotFluxHist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph of annual flux and flow normalized flux versus year — plotFluxHist","text":"eList named list least Daily INFO dataframes yearStart numeric calendar year containing first estimated annual value plotted, default NA (allows set automatically data) yearEnd numeric calendar year just last estimated annual value plotted, default NA (allows set automatically data) fluxUnit number representing entry pre-defined fluxUnit class array. printFluxUnitCheatSheet fluxMax number specifying maximum value used vertical axis, default NA (allows set automatically data) printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. plotFlowNorm logical variable TRUE flow normalized line plotted, FALSE plotted plotAnnual logical variable TRUE annual flux points plotted, FALSE plotted plotGenFlux logical variable. TRUE, annual flux points WRTDS_K output plotted, FALSE plotted tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE col color points plot, see ?par 'Color Specification' col.pred color flow normalized line plot, see ?par 'Color Specification' col.gen color points WRTDS_K output plot, see ?par 'Color Specification' cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex lwd number line width customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFluxHist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph of annual flux and flow normalized flux versus year — plotFluxHist","text":"","code":"yearStart <- 2001 yearEnd <- 2010 eList <- Choptank_eList # Water year: # \\donttest{ plotFluxHist(eList)  plotFluxHist(eList, yearStart, yearEnd, fluxUnit = 1)  plotFluxHist(eList, yearStart, yearEnd, fluxUnit = 'kgDay')  # }"},{"path":"/reference/plotFluxPred.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph of observed versus estimated flux — plotFluxPred","title":"Graph of observed versus estimated flux — plotFluxPred","text":"Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata. Although lot optional arguments function, set logical default.","code":""},{"path":"/reference/plotFluxPred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph of observed versus estimated flux — plotFluxPred","text":"","code":"plotFluxPred(eList, fluxUnit = 3, fluxMax = NA, printTitle = TRUE,   oneToOneLine = TRUE, customPar = FALSE, col = \"black\", lwd = 1,   cex = 0.8, cex.axis = 1.1, cex.main = 1.1, tinyPlot = FALSE,   usgsStyle = FALSE, logScale = FALSE, randomCensored = FALSE, ...)"},{"path":"/reference/plotFluxPred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph of observed versus estimated flux — plotFluxPred","text":"eList named list least Sample INFO dataframes fluxUnit number representing entry pre-defined fluxUnit class array. printFluxUnitCheatSheet fluxMax number specifying maximum value used vertical axis, default NA (allows set automatically data) printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) oneToOneLine inserts 1:1 line customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex tinyPlot logical variable TRUE plot designed small, FALSE designed page size, default FALSE (fully implemented yet) usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. logScale logical TRUE x y plotted log axis randomCensored logical. Show censored values randomized. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFluxPred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph of observed versus estimated flux — plotFluxPred","text":"","code":"eList <- Choptank_eList # Water year: plotFluxPred(eList)  plotFluxPred(eList, fluxUnit = 'poundsDay')  plotFluxPred(eList, logScale=TRUE)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotFluxPred(eList)"},{"path":"/reference/plotFluxQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data plot: observed log flux vs log discharge — plotFluxQ","title":"Sample data plot: observed log flux vs log discharge — plotFluxQ","text":"Concentration discharge data used compute flux come data frame named Sample contains sample data. metadata come data frame named INFO. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotFluxQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample data plot: observed log flux vs log discharge — plotFluxQ","text":"","code":"plotFluxQ(eList, qUnit = 2, logScale = TRUE, fluxUnit = 3,   tinyPlot = FALSE, fluxMax = NA, fluxMin = NA, col = \"black\",   lwd = 1, printTitle = TRUE, usgsStyle = FALSE, cex = 0.8,   cex.axis = 1.1, cex.main = 1.1, customPar = FALSE, ...)"},{"path":"/reference/plotFluxQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample data plot: observed log flux vs log discharge — plotFluxQ","text":"eList named list least Sample INFO dataframes qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. logScale logical, default TRUE, TRUE creates log-log scale, FALSE creates arithmatic scale. fluxUnit object fluxUnit class. printFluxUnitCheatSheet, numeric represented short code, character representing descriptive name. tinyPlot logical variable TRUE plot designed fit multi-plot array, default FALSE fluxMax numeric specifying maximum value used vertical axis, default NA (allows set automatically data) fluxMin numeric specifying minimum value used vertical axis, default NA (allows set automatically data) col color points plot, see ?par 'Color Specification' lwd number line width printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFluxQ.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample data plot: observed log flux vs log discharge — plotFluxQ","text":"","code":"eList <- Choptank_eList # Water year: plotFluxQ(eList, qUnit = 1, fluxUnit = 1)  plotFluxQ(eList, fluxUnit = 'kgDay') plotFluxQ(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotFluxQ(eList)"},{"path":"/reference/plotFluxTimeDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the time series of daily flux estimates and the sample values for the days that were sampled — plotFluxTimeDaily","title":"Plot of the time series of daily flux estimates and the sample values for the days that were sampled — plotFluxTimeDaily","text":"plot useful visual examination ability WRTDS, model, fit  data, seen time-series perspective. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotFluxTimeDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the time series of daily flux estimates and the sample values for the days that were sampled — plotFluxTimeDaily","text":"","code":"plotFluxTimeDaily(eList, yearStart = NA, yearEnd = NA, tinyPlot = FALSE,   fluxUnit = 3, fluxMax = NA, randomCensored = FALSE,   printTitle = TRUE, usgsStyle = FALSE, cex = 0.8, cex.axis = 1.1,   cex.main = 1.1, customPar = FALSE, col = \"black\", lwd = 1,   prettyDate = TRUE, ...)"},{"path":"/reference/plotFluxTimeDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the time series of daily flux estimates and the sample values for the days that were sampled — plotFluxTimeDaily","text":"eList named list least Daily, Sample, INFO dataframes yearStart numeric specifying starting date (expressed decimal years, example 1989.0) plot yearEnd numeric specifiying ending date plot tinyPlot logical variable, TRUE plot designed short wide, default FALSE. fluxUnit number representing pre-defined fluxUnit class array. printFluxUnitCheatSheet fluxMax number specifying maximum value used vertical axis, default NA (allows set automatically data) randomCensored logical, TRUE plot random value censored data.  Default FALSE. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. col color points plot, see ?par 'Color Specification' lwd number line width prettyDate logical use 'pretty' limits date axis TRUE, force yearStart/yearEnd limits FALSE ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFluxTimeDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the time series of daily flux estimates and the sample values for the days that were sampled — plotFluxTimeDaily","text":"","code":"eList <- Choptank_eList # Water year: plotFluxTimeDaily(eList)  plotFluxTimeDaily(eList, 2001,2009)"},{"path":"/reference/plotFour.html","id":null,"dir":"Reference","previous_headings":"","what":"Makes four graphs of streamflow statistics on a single page — plotFour","title":"Makes four graphs of streamflow statistics on a single page — plotFour","text":"Part flowHistory system.  four statistics 1-day maximum, annual mean, annual 7-day minimum, running standard deviation log daily discharge values. Although lot optional arguments function, set logical default. Data come named list, contains Daily dataframe daily flow data, INFO dataframe metadata. graph shows loess smooth data plotted.","code":""},{"path":"/reference/plotFour.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Makes four graphs of streamflow statistics on a single page — plotFour","text":"","code":"plotFour(eList, yearStart = NA, yearEnd = NA, printTitle = TRUE,   runoff = FALSE, qUnit = 1, window = 15, cex = 0.8, cex.axis = 1.2,   cex.main = 1.2, col = \"black\", lwd = 1, ...)"},{"path":"/reference/plotFour.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Makes four graphs of streamflow statistics on a single page — plotFour","text":"eList named list least Daily INFO dataframes yearStart numeric value year graph start, default NA, indicates graph start first annual value yearEnd numeric value year graph end, default NA, indicates graph end last annual value printTitle logical variable, TRUE title printed, FALSE title printed, default TRUE runoff logical variable, TRUE streamflow data converted runoff values mm/day qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. window numeric full width, years, time window standard deviation computed, default = 15 cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex col color points plot, see ?par 'Color Specification' lwd number line width. Default 1. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFour.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Makes four graphs of streamflow statistics on a single page — plotFour","text":"","code":"eList <- Choptank_eList # \\donttest{ #Water year: plotFour(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList,paStart=6,paLong=3) plotFour(eList)  # }"},{"path":"/reference/plotFourStats.html","id":null,"dir":"Reference","previous_headings":"","what":"Makes four graphs of annual streamflow statistics on a single page — plotFourStats","title":"Makes four graphs of annual streamflow statistics on a single page — plotFourStats","text":"Part flowHistory system.  four statistics 1-day maximum, annual mean, annual median, annual 7-day minimum.  Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  Daily dataframe daily flow data, INFO dataframe metadata. graph shows loess smooth data plotted.","code":""},{"path":"/reference/plotFourStats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Makes four graphs of annual streamflow statistics on a single page — plotFourStats","text":"","code":"plotFourStats(eList, yearStart = NA, yearEnd = NA, printTitle = TRUE,   runoff = FALSE, cex.main = 1.2, qUnit = 1, cex.axis = 1.2,   cex = 0.8, col = \"black\", lwd = 1, ...)"},{"path":"/reference/plotFourStats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Makes four graphs of annual streamflow statistics on a single page — plotFourStats","text":"eList named list least Daily INFO dataframes yearStart numeric value year graph start, default NA, indicates graph start first annual value yearEnd numeric value year graph end, default NA, indicates graph end last annual value printTitle logical variable, TRUE title printed, FALSE title printed, default TRUE runoff logical variable, TRUE streamflow data converted runoff values mm/day cex.main magnification used main titles relative current setting cex qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. cex.axis magnification used axis annotation relative current setting cex cex numerical value giving amount plotting symbols magnified col color points plot, see ?par 'Color Specification' lwd number line width. Default 1. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotFourStats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Makes four graphs of annual streamflow statistics on a single page — plotFourStats","text":"","code":"eList <- Choptank_eList # \\donttest{ # Water year: plotFourStats(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList,paStart=6,paLong=3) plotFourStats(eList)  # }"},{"path":"/reference/plotMonthTrend.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot monthly trend result from runPairs — plotMonthTrend","title":"Plot monthly trend result from runPairs — plotMonthTrend","text":"Plot monthly trend result runPairs. change concentration flux calculated runPairs function. plotting function shows arrow month. trend year1 year2  increasing, arrow red pointing . trend decreasing, arrow black pointing .","code":""},{"path":"/reference/plotMonthTrend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot monthly trend result from runPairs — plotMonthTrend","text":"","code":"plotMonthTrend(pairResults, yMax = NA, arrowFactor = 1, flux = TRUE,   printTitle = TRUE, concLab = 1, monthLab = 1)"},{"path":"/reference/plotMonthTrend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot monthly trend result from runPairs — plotMonthTrend","text":"pairResults results runPairs. yMax numeric. Upper limit plot. Default NA, use maximum data. arrowFactor numeric. Scaling factor size arrows. arrows automatically scaled overall trend. scaling  factor helps adjust big/small . flux logical. TRUE flux, FALSE concentration. Default TRUE. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) concLab object concUnit class, numeric represented short code,  character representing descriptive name. monthLab object monthLabel class, numeric represented short code,  character representing descriptive name.","code":""},{"path":"/reference/plotMonthTrend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot monthly trend result from runPairs — plotMonthTrend","text":"Base R plot monthly trends","code":""},{"path":"/reference/plotMonthTrend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot monthly trend result from runPairs — plotMonthTrend","text":"","code":"eList <- Choptank_eList year1 <- 1985 year2 <- 2010  # \\donttest{  pairOut_1 <- runPairs(eList, year1, year2, windowSide = 0) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.429 mg/L #>  expressed as Percent Change is  42 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.0342 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  29 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.429 0.429   0 1.01 1.01 1.44 1.44 #> Flux       0.034 0.034   0 0.12 0.12 0.15 0.15  plotMonthTrend(pairOut_1)  plotMonthTrend(pairOut_1, flux = FALSE)   eList <- setPA(eList, paStart = 12, paLong = 3) pairOut_2 <- runPairs(eList, year1, year2, windowSide = 0) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Season Consisting of Dec Jan Feb  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.369 mg/L #>  expressed as Percent Change is  31 % #>  #>  Concentration v. Q Trend Component  31 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.0403 million kg/year #>  expressed as Percent Change is  23 % #>  #>  Concentration v. Q Trend Component  23 % #>        Q Trend Component             0 %  #>  #>      TotalChange CQTC QTC  x10  x11  x20  x22 #> Conc        0.37 0.37   0 1.21 1.21 1.58 1.58 #> Flux        0.04 0.04   0 0.18 0.18 0.22 0.22  plotMonthTrend(pairOut_2)   eList <- setPA(eList, paStart = 1, paLong = 12) pairOut_3 <- runPairs(eList, year1, year2, windowSide = 0) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Calendar Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.433 mg/L #>  expressed as Percent Change is  42 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.034 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  29 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.433 0.433   0 1.02 1.02 1.45 1.45 #> Flux       0.034 0.034   0 0.12 0.12 0.15 0.15  plotMonthTrend(pairOut_3)   # }"},{"path":"/reference/plotQTimeDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the discharge time series — plotQTimeDaily","title":"Plot of the discharge time series — plotQTimeDaily","text":"Part flowHistory component. Allows discharge record show discharges given threshold Although lot optional arguments function, set logical default. Data come named list, contains Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotQTimeDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the discharge time series — plotQTimeDaily","text":"","code":"plotQTimeDaily(eList, yearStart = NA, yearEnd = NA, qLower = NA,   qUnit = 1, logScale = FALSE, tinyPlot = FALSE, printTitle = TRUE,   usgsStyle = FALSE, lwd = 3, col = \"red\", cex.main = 1.2,   cex.lab = 1.2, customPar = FALSE, prettyDate = TRUE, ...)"},{"path":"/reference/plotQTimeDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the discharge time series — plotQTimeDaily","text":"eList named list least Daily INFO dataframes yearStart numeric indicating starting year graph yearEnd numeric indicating ending year graph (time decimal years last observations plotted) qLower numeric specifying lower bound discharges plotted, must units specified qUnit, default NA (lower bound zero) qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name.  Default qUnit=1 (cubic feet per second) logScale logical whether use log scale y axis. Default FALSE. tinyPlot logical variable, TRUE plot designed short wide, default FALSE. printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure) usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels. lwd line width, positive number, defaulting 3 col specification default plotting color cex.main magnification used main titles relative current setting cex cex.lab magnification used x y labels relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. prettyDate logical use 'pretty' limits date axis TRUE, force yearStart/yearEnd limits FALSE ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotQTimeDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the discharge time series — plotQTimeDaily","text":"","code":"eList <- Choptank_eList # Water year: plotQTimeDaily(eList)  plotQTimeDaily(eList, yearStart=1990, yearEnd=2000,qLower=1500)  plotQTimeDaily(eList, prettyDate=FALSE)"},{"path":"/reference/plotResidPred.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the residuals from WRTDS versus the estimated values (all in log concentration units) — plotResidPred","title":"Plot of the residuals from WRTDS versus the estimated values (all in log concentration units) — plotResidPred","text":"function produces plot residuals WRTDS, expressed natural log concentration units versus estimated values, also natural log concentration units.  estimates log-space estimates prior bias-correction.   function provides alternative viewing standardized residuals, residual divided estimated standard error. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotResidPred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the residuals from WRTDS versus the estimated values (all in log concentration units) — plotResidPred","text":"","code":"plotResidPred(eList, stdResid = FALSE, tinyPlot = FALSE,   printTitle = TRUE, col = \"black\", lwd = 1, cex = 0.8,   cex.axis = 1.1, cex.main = 1.1, customPar = FALSE,   randomCensored = FALSE, concLab = 1, ...)"},{"path":"/reference/plotResidPred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the residuals from WRTDS versus the estimated values (all in log concentration units) — plotResidPred","text":"eList named list least Sample INFO dataframes stdResid logical variable, TRUE uses standardized residual, FALSE uses actual, default FALSE tinyPlot logical variable, TRUE plot designed plotted small part multipart figure, default FALSE. printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) col color points plot, see ?par 'Color Specification' lwd number line width cex numerical value giving amount plotting symbols magnified cex.axis magnification used x y labels relative current setting cex cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. randomCensored logical. Show censored residuals randomized. concLab object concUnit class, numeric represented short code,  character representing descriptive name. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotResidPred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the residuals from WRTDS versus the estimated values (all in log concentration units) — plotResidPred","text":"","code":"eList <- Choptank_eList # Water year: plotResidPred(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotResidPred(eList)"},{"path":"/reference/plotResidQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the residuals from WRTDS (in log concentration units) versus the discharge — plotResidQ","title":"Plot of the residuals from WRTDS (in log concentration units) versus the discharge — plotResidQ","text":"function produces plot residuals WRTDS, expressed natural log concentration units versus discharge shown log scale.  function also provides alternative viewing standardized residuals, residual divided estimated standard error Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotResidQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the residuals from WRTDS (in log concentration units) versus the discharge — plotResidQ","text":"","code":"plotResidQ(eList, qUnit = 2, tinyPlot = FALSE, stdResid = FALSE,   printTitle = TRUE, col = \"black\", lwd = 1, cex = 0.8,   cex.axis = 1.1, cex.main = 1.1, rmSciX = FALSE, customPar = FALSE,   randomCensored = FALSE, usgsStyle = FALSE, ...)"},{"path":"/reference/plotResidQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the residuals from WRTDS (in log concentration units) versus the discharge — plotResidQ","text":"eList named list least Sample INFO dataframes qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. tinyPlot logical variable, TRUE plot designed plotted small part multipart figure, default FALSE. stdResid logical variable, TRUE uses standardized residual, FALSE uses actual, default FALSE printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) col color points plot, see ?par 'Color Specification' lwd number line width cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex rmSciX logical defaults FALSE, changes x label scientific fixed customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. randomCensored logical. Show censored residuals randomized. usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS complience. change automatically generated labels. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotResidQ.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the residuals from WRTDS (in log concentration units) versus the discharge — plotResidQ","text":"","code":"eList <- Choptank_eList # Water year: plotResidQ(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotResidQ(eList)"},{"path":"/reference/plotResidTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the residuals from WRTDS (in log concentration units) versus time — plotResidTime","title":"Plot of the residuals from WRTDS (in log concentration units) versus time — plotResidTime","text":"function produces plot residuals WRTDS, expressed natural log concentration units versus time. also provides alternative viewing standardized residuals, residual divided estimated standard error. Although lot optional arguments function, set logical default. Data come named list, contains Sample dataframe sample data,  INFO dataframe metadata.","code":""},{"path":"/reference/plotResidTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the residuals from WRTDS (in log concentration units) versus time — plotResidTime","text":"","code":"plotResidTime(eList, stdResid = FALSE, printTitle = TRUE, hLine = TRUE,   tinyPlot = FALSE, col = \"black\", lwd = 1, cex = 0.8,   cex.axis = 1.1, cex.main = 1.1, customPar = FALSE,   randomCensored = FALSE, ...)"},{"path":"/reference/plotResidTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the residuals from WRTDS (in log concentration units) versus time — plotResidTime","text":"eList named list least Sample INFO dataframes stdResid logical variable, TRUE uses standardized residual, FALSE uses actual, default FALSE printTitle logical variable TRUE title printed, FALSE printed (best multi-plot figure) hLine inserts horizontal line zero tinyPlot logical variable, TRUE plot designed plotted small, part multipart figure, default FALSE col color points plot, see ?par 'Color Specification' lwd number line width cex numerical value giving amount plotting symbols magnified cex.axis magnification used axis annotation relative current setting cex cex.main magnification used main titles relative current setting cex customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. randomCensored logical. Show censored residuals randomized. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotResidTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the residuals from WRTDS (in log concentration units) versus time — plotResidTime","text":"","code":"eList <- Choptank_eList # Water year: plotResidTime(eList)  # Graphs consisting of Jun-Aug eList <- setPA(eList, paStart=6,paLong=3) plotResidTime(eList)"},{"path":"/reference/plotSDLogQ.html","id":null,"dir":"Reference","previous_headings":"","what":"Graph of the standard deviation of the log of daily discharge versus year — plotSDLogQ","title":"Graph of the standard deviation of the log of daily discharge versus year — plotSDLogQ","text":"Graph standard deviation log daily discharge versus year Although lot optional arguments function, set logical default. Data come named list, contains Daily dataframe daily flow data, INFO dataframe metadata.","code":""},{"path":"/reference/plotSDLogQ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graph of the standard deviation of the log of daily discharge versus year — plotSDLogQ","text":"","code":"plotSDLogQ(eList, yearStart = NA, yearEnd = NA, window = 15,   sdMax = NA, printTitle = TRUE, tinyPlot = FALSE, printStaName = TRUE,   printPA = TRUE, cex = 0.8, cex.main = 1.1, cex.axis = 1.1, lwd = 2,   customPar = FALSE, ...)"},{"path":"/reference/plotSDLogQ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graph of the standard deviation of the log of daily discharge versus year — plotSDLogQ","text":"eList named list least Daily INFO dataframes yearStart numeric calendar year first value included graph, default NA, plots start period record yearEnd numeric calendar year last value included graph, default NA, plots end period record window numeric full width, years, time window standard deviation computed, default = 15 sdMax numeric maximum value used vertical axis graph, default NA (allows set automatically data) printTitle logical variable TRUE title printed, FALSE title printed (best multi-plot figure), default TRUE tinyPlot logical variable TRUE plot designed small, FALSE designed page size, default FALSE (fully implemented yet) printStaName logical variable, TRUE print station name, FALSE , default TRUE printPA logical variable, TRUE print period analysis information plot title, FALSE leave , default TRUE cex numerical value giving amount plotting symbols magnified cex.main magnification used main titles relative current setting cex cex.axis magnification used axis annotation relative current setting cex lwd line width, positive number, defaulting 2 customPar logical defaults FALSE. TRUE, par() set user calling function  (example, adjusting margins par(mar=c(5,5,5,5))). customPar FALSE, EGRET chooses best margins depending tinyPlot. ... arbitrary graphical parameters passed genericEGRETDotPlot function (see ?par options)","code":""},{"path":[]},{"path":"/reference/plotSDLogQ.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graph of the standard deviation of the log of daily discharge versus year — plotSDLogQ","text":"","code":"eList <- Choptank_eList # \\donttest{ # Water year: plotSDLogQ(eList)   plotSDLogQ(eList, 1998, 2000)   # }"},{"path":"/reference/plotTimeSlice.html","id":null,"dir":"Reference","previous_headings":"","what":"plotTimeSlice — plotTimeSlice","title":"plotTimeSlice — plotTimeSlice","text":"Plot either concentration flux time showing WRTDS WRTDSKalman estimates.","code":""},{"path":"/reference/plotTimeSlice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plotTimeSlice — plotTimeSlice","text":"","code":"plotTimeSlice(eList, start = NA, end = NA, conc = TRUE, fluxUnit = 3,   usgsStyle = FALSE)"},{"path":"/reference/plotTimeSlice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plotTimeSlice — plotTimeSlice","text":"eList named list least Daily, Sample, INFO dataframes. eList must run WRTDSKalman. start numeric start DecYear plot. NA, plot start earliest date record. end numeric end DecYear plot. NA, plot end latest date record. conc logical. TRUE, plot concentration, otherwise plot flux. fluxUnit number representing entry pre-defined fluxUnit class array. printFluxUnitCheatSheet usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels","code":""},{"path":"/reference/plotTimeSlice.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plotTimeSlice — plotTimeSlice","text":"plot title, Ratio means mean WRTDSKalman estimates WRTDS Classic estimates.  Ratio calculated data shown figure, whole series. plot, red dots measured values, blue dots plotted reporting limit values censored.","code":""},{"path":"/reference/plotTimeSlice.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plotTimeSlice — plotTimeSlice","text":"","code":"eList <- Choptank_eList eList <- WRTDSKalman(eList, niter = 10) #> % complete: #> 10 \t #> 20 \t #> 30 \t #> 40 \t #> 50 \t #> 60 \t #> 70 \t #> 80 \t #> 90 \t #> 100 \t  plotTimeSlice(eList, start = 1990, end = 1991, conc = TRUE)   plotTimeSlice(eList, start = 1990, end = 1991, conc = FALSE)   plotTimeSlice(eList, start = NA, end = 1991, conc = FALSE)"},{"path":"/reference/plotWRTDSKalman.html","id":null,"dir":"Reference","previous_headings":"","what":"plotWRTDSKalman — plotWRTDSKalman","title":"plotWRTDSKalman — plotWRTDSKalman","text":"Two plots check flux estimates using WRTDS_K vs classic WRTDS. first annual flux time, two fluxes shown different colors. second WRTDS vs WRTDSKalman flux estimates. graphs can output either top , side side using sideBySide argument.","code":""},{"path":"/reference/plotWRTDSKalman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plotWRTDSKalman — plotWRTDSKalman","text":"","code":"plotWRTDSKalman(eList, sideBySide = FALSE, fluxUnit = 9,   usgsStyle = FALSE)"},{"path":"/reference/plotWRTDSKalman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plotWRTDSKalman — plotWRTDSKalman","text":"eList named list least Daily, Sample, INFO dataframes. eList must run WRTDSKalman. sideBySide logical. TRUE, two plots plotted side side, otherwise, one one vertically. fluxUnit number representing entry pre-defined fluxUnit class array. printFluxUnitCheatSheet usgsStyle logical option use USGS style guidelines. Setting option TRUE guarantee USGS compliance. change automatically generated labels","code":""},{"path":"/reference/plotWRTDSKalman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plotWRTDSKalman — plotWRTDSKalman","text":"","code":"eList <- Choptank_eList eList <- WRTDSKalman(eList, niter = 10) #> % complete: #> 10 \t #> 20 \t #> 30 \t #> 40 \t #> 50 \t #> 60 \t #> 70 \t #> 80 \t #> 90 \t #> 100 \t plotWRTDSKalman(eList)    plotWRTDSKalman(eList, sideBySide = TRUE)"},{"path":"/reference/populateConcentrations.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Concentration Columns — populateConcentrations","title":"Populate Concentration Columns — populateConcentrations","text":"Creates ConcLow, ConcHigh, Uncen (0 censored, 1 uncensored) columns  Sample data frame WRTDS analysis.","code":""},{"path":"/reference/populateConcentrations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Concentration Columns — populateConcentrations","text":"","code":"populateConcentrations(rawData)"},{"path":"/reference/populateConcentrations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Concentration Columns — populateConcentrations","text":"rawData vector value code columns","code":""},{"path":"/reference/populateConcentrations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Concentration Columns — populateConcentrations","text":"concentrationColumns dataframe","code":""},{"path":"/reference/populateConcentrations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Concentration Columns — populateConcentrations","text":"","code":"code <- c(\"\",\"<\",\"\") value <- c(1,2,3) dataInput <- data.frame(value, code, stringsAsFactors=FALSE) concentrationDF <- populateConcentrations(dataInput)"},{"path":"/reference/populateDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Daily data frame — populateDaily","title":"Populate Daily data frame — populateDaily","text":"Using raw data least dateTime, value, code, populates rest basic Daily data frame used EGRET analysis.","code":""},{"path":"/reference/populateDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Daily data frame — populateDaily","text":"","code":"populateDaily(rawData, qConvert, verbose = TRUE, interactive = NULL)"},{"path":"/reference/populateDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Daily data frame — populateDaily","text":"rawData dataframe contains least dateTime, value, code columns qConvert character conversion cubic meters per second verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead  true, user interaction error handling data checks.","code":""},{"path":"/reference/populateDaily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Daily data frame — populateDaily","text":"data frame 'Daily' following columns:","code":""},{"path":[]},{"path":"/reference/populateDaily.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Populate Daily data frame — populateDaily","text":"Robert M. Hirsch rhirsch@usgs.gov","code":""},{"path":"/reference/populateDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Daily data frame — populateDaily","text":"","code":"dateTime <- as.character(seq(as.Date(\"2001/1/1\"),           as.Date(\"2001/12/31\"), by = \"day\")) value <- 1:365 code <- rep(\"\",365) dataInput <- data.frame(dateTime, value, code, stringsAsFactors=FALSE) Daily <- populateDaily(dataInput, 2) #> There are 365 data points, and 365 days."},{"path":"/reference/populateDailySamp.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge concentration to Daily — populateDailySamp","title":"Merge concentration to Daily — populateDailySamp","text":"Used WRTDS Kalman set functions, function merges ConcAve Daily data frame, renaming \"trueConc\", calculates \"trueFlux\", \"stdResid\".","code":""},{"path":"/reference/populateDailySamp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge concentration to Daily — populateDailySamp","text":"","code":"populateDailySamp(eList)"},{"path":"/reference/populateDailySamp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge concentration to Daily — populateDailySamp","text":"eList named list INFO, Daily, Sample dataframes surfaces matrix","code":""},{"path":"/reference/populateDailySamp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge concentration to Daily — populateDailySamp","text":"","code":"eList <- Choptank_eList Daily2 <- populateDailySamp(eList)"},{"path":"/reference/populateDateColumns.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Date Columns — populateDateColumns","title":"Populate Date Columns — populateDateColumns","text":"Creates various date columns WRTDS study.","code":""},{"path":"/reference/populateDateColumns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Date Columns — populateDateColumns","text":"","code":"populateDateColumns(rawData)"},{"path":"/reference/populateDateColumns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Date Columns — populateDateColumns","text":"rawData vector dateTime","code":""},{"path":"/reference/populateDateColumns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Date Columns — populateDateColumns","text":"DateFrame dataframe","code":""},{"path":"/reference/populateDateColumns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Date Columns — populateDateColumns","text":"","code":"dateTime <- c('1984-02-28 13:56',               '1984-03-01 00:00',               '1986-03-01 00:00',               '1986-10-15 00:00')                expandedDateDF <- populateDateColumns(dateTime) expandedDateDF #>               Date   Julian Month Day  DecYear MonthSeq waterYear #> 1 1984-02-28 13:56 49000.58     2  59 1984.160     1610      1984 #> 2 1984-03-01 00:00 49002.00     3  61 1984.164     1611      1984 #> 3 1986-03-01 00:00 49732.00     3  61 1986.162     1635      1986 #> 4 1986-10-15 00:00 49960.00    10 289 1986.786     1642      1987  dateTime <- c('1984-02-28',                '1984-03-01',               '1986-03-01',               '1986-10-15') expandedDateDF <- populateDateColumns(dateTime) expandedDateDF #>         Date Julian Month Day  DecYear MonthSeq waterYear #> 1 1984-02-28  49000     2  59 1984.160     1610      1984 #> 2 1984-03-01  49002     3  61 1984.165     1611      1984 #> 3 1986-03-01  49732     3  61 1986.163     1635      1986 #> 4 1986-10-15  49960    10 289 1986.788     1642      1987"},{"path":"/reference/populateParameterINFO.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Parameter Information Columns — populateParameterINFO","title":"Populate Parameter Information Columns — populateParameterINFO","text":"Populates INFO data frame additional user-supplied information concerning measured parameter.","code":""},{"path":"/reference/populateParameterINFO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Parameter Information Columns — populateParameterINFO","text":"","code":"populateParameterINFO(parameterCd, INFO, interactive = TRUE)"},{"path":"/reference/populateParameterINFO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Parameter Information Columns — populateParameterINFO","text":"parameterCd character USGS parameter code INFO dataframe value code columns. Default INFO interactive logical Option interactive mode.  TRUE, user interaction error handling  data checks. Default TRUE. running batch, set FALSE.","code":""},{"path":"/reference/populateParameterINFO.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Parameter Information Columns — populateParameterINFO","text":"INFO dataframe","code":""},{"path":"/reference/populateParameterINFO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Parameter Information Columns — populateParameterINFO","text":"","code":"# \\donttest{ library(dataRetrieval) INFO <- readNWISsite('01594440') parameterCd <- \"01075\" parameterData <- readNWISpCode(parameterCd) INFO$param.nm <- parameterData$parameter_nm INFO$param.units <- parameterData$parameter_units INFO$paramShortName <- parameterData$srsname INFO$paramNumber <- parameterData$parameter_cd  INFO <- populateParameterINFO(parameterCd, INFO, interactive = FALSE) # }"},{"path":"/reference/populateSampleColumns.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Sample Columns — populateSampleColumns","title":"Populate Sample Columns — populateSampleColumns","text":"Creates ConcAve ConcLow based Uncen. Removes samples NA values ConcHigh.","code":""},{"path":"/reference/populateSampleColumns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Sample Columns — populateSampleColumns","text":"","code":"populateSampleColumns(rawData)"},{"path":"/reference/populateSampleColumns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Sample Columns — populateSampleColumns","text":"rawData dataframe dateTime, ConcLow, ConcHigh, Uncen","code":""},{"path":"/reference/populateSampleColumns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Sample Columns — populateSampleColumns","text":"Sample2 dataframe columns: Date, ConcLow, ConcHigh, Uncen, ConcAve, Julian,  Month, Day, DecYear, MonthSeq, waterYear, SinDY, CosDY (DY = decimal year)","code":""},{"path":"/reference/populateSampleColumns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Sample Columns — populateSampleColumns","text":"","code":"dateTime <- c('1985-01-01', '1985-01-02', '1985-01-03') ConcLow <- c(1,2,0) ConcHigh <- c(1,2,3) Uncen <- c(1,1,0) dataInput <- data.frame(dateTime, ConcLow, ConcHigh, Uncen, stringsAsFactors=FALSE) Sample <- populateSampleColumns(dataInput)"},{"path":"/reference/populateSiteINFO.html","id":null,"dir":"Reference","previous_headings":"","what":"Populate Site Information Columns — populateSiteINFO","title":"Populate Site Information Columns — populateSiteINFO","text":"Populates INFO data frame additional user-supplied information. Also removes fields related WRTDS study.","code":""},{"path":"/reference/populateSiteINFO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Populate Site Information Columns — populateSiteINFO","text":"","code":"populateSiteINFO(INFO, siteNumber, interactive = TRUE)"},{"path":"/reference/populateSiteINFO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Populate Site Information Columns — populateSiteINFO","text":"INFO dataframe value code columns siteNumber character USGS site number interactive logical Option interactive mode.  TRUE, user interaction error handling  data checks. Default TRUE. running batch, set FALSE.","code":""},{"path":"/reference/populateSiteINFO.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Populate Site Information Columns — populateSiteINFO","text":"INFO dataframe","code":""},{"path":"/reference/populateSiteINFO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Populate Site Information Columns — populateSiteINFO","text":"","code":"# \\donttest{ library(dataRetrieval) INFO <- readNWISsite('01594440') siteNumber <- \"01594440\" siteINFO <- populateSiteINFO(INFO, siteNumber, interactive = FALSE) # }"},{"path":"/reference/printFluxUnitCheatSheet.html","id":null,"dir":"Reference","previous_headings":"","what":"Reminder to user of flux unit properties  (such as kg/day, tons/year, etc). — printFluxUnitCheatSheet","title":"Reminder to user of flux unit properties  (such as kg/day, tons/year, etc). — printFluxUnitCheatSheet","text":"Cheat sheet print pre-defined flux unit properties fluxUnit class Flux units included:","code":""},{"path":"/reference/printFluxUnitCheatSheet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reminder to user of flux unit properties  (such as kg/day, tons/year, etc). — printFluxUnitCheatSheet","text":"","code":"printFluxUnitCheatSheet()"},{"path":"/reference/printFluxUnitCheatSheet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reminder to user of flux unit properties  (such as kg/day, tons/year, etc). — printFluxUnitCheatSheet","text":"","code":"printFluxUnitCheatSheet() #> The following codes apply to the fluxUnit list: #> 1 =  poundsDay  ( pounds/day ) #> 2 =  tonsDay  ( tons/day ) #> 3 =  kgDay  ( kg/day ) #> 4 =  thousandKgDay  ( thousands of kg/day ) #> 5 =  tonsYear  ( tons/year ) #> 6 =  thousandTonsYear  ( thousands of tons/year ) #> 7 =  millionTonsYear  ( millions of tons/year ) #> 8 =  thousandKgYear  ( thousands of kg/year ) #> 9 =  millionKgYear  ( millions of kg/year ) #> 10 =  billionKgYear  ( billions of kg/year ) #> 11 =  thousandTonsDay  ( thousands of tons/day ) #> 12 =  millionKgDay  ( millions of kg/day ) #> 13 =  kgYear  ( kg/year )"},{"path":"/reference/printGroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Print information about group analysis — printGroups","title":"Print information about group analysis — printGroups","text":"Prints information runGroups function. used save output text file.","code":""},{"path":"/reference/printGroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print information about group analysis — printGroups","text":"","code":"printGroups(eList, groupResults)"},{"path":"/reference/printGroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print information about group analysis — printGroups","text":"eList named list least Daily, Sample, INFO dataframes groupResults output runGroups.","code":""},{"path":"/reference/printGroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print information about group analysis — printGroups","text":"text console","code":""},{"path":"/reference/printGroups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print information about group analysis — printGroups","text":"","code":"eList <- Choptank_eList  # \\donttest{ groupOut_1 <- runGroups(eList,  windowSide = 0,                         group1firstYear = 1980, group1lastYear = 1990,                         group2firstYear = 1995, group2lastYear = 2005) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.226 mg/L #>  expressed as Percent Change is  22 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.022 million kg/year #>  expressed as Percent Change is  19 % #>  #>  Concentration v. Q Trend Component  19 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.226 0.226   0 1.02 1.02 1.24 1.24 #> Flux       0.022 0.022   0 0.12 0.12 0.14 0.14                         printGroups(eList, groupOut_1) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.226 mg/L #>  expressed as Percent Change is  22 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.022 million kg/year #>  expressed as Percent Change is  19 % #>  #>  Concentration v. Q Trend Component  19 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.226 0.226   0 1.02 1.02 1.24 1.24 #> Flux       0.022 0.022   0 0.12 0.12 0.14 0.14 # }"},{"path":"/reference/printPairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Print information about pairs analysis — printPairs","title":"Print information about pairs analysis — printPairs","text":"Prints information runPairs function. used save output text file.","code":""},{"path":"/reference/printPairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print information about pairs analysis — printPairs","text":"","code":"printPairs(eList, pairResults)"},{"path":"/reference/printPairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print information about pairs analysis — printPairs","text":"eList named list least Daily, Sample, INFO dataframes pairResults output runGroups.","code":""},{"path":"/reference/printPairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print information about pairs analysis — printPairs","text":"text console","code":""},{"path":"/reference/printPairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print information about pairs analysis — printPairs","text":"","code":"eList <- Choptank_eList year1 <- 1985 year2 <- 2010  # \\donttest{ pairOut_1 <- runPairs(eList,                        year1, year2,                       windowSide = 0) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.429 mg/L #>  expressed as Percent Change is  42 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.0342 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  29 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.429 0.429   0 1.01 1.01 1.44 1.44 #> Flux       0.034 0.034   0 0.12 0.12 0.15 0.15                         printPairs(eList, pairOut_1) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.429 mg/L #>  expressed as Percent Change is  42 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.0342 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  29 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.429 0.429   0 1.01 1.01 1.44 1.44 #> Flux       0.034 0.034   0 0.12 0.12 0.15 0.15 # }"},{"path":"/reference/printSeries.html","id":null,"dir":"Reference","previous_headings":"","what":"Print annual results for a given streamflow statistic — printSeries","title":"Print annual results for a given streamflow statistic — printSeries","text":"Part flowHistory system.   index flow statistics istat.  statistics :  (1) 1-day minimum, (2) 7-day minimum, (3) 30-day minimum, (4) median (5) mean, (6) 30-day maximum, (7) 7-day maximum, (8) 1-day maximum.","code":""},{"path":"/reference/printSeries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print annual results for a given streamflow statistic — printSeries","text":"","code":"printSeries(eList, istat, qUnit = 1, runoff = FALSE)"},{"path":"/reference/printSeries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print annual results for a given streamflow statistic — printSeries","text":"eList named list least Daily INFO dataframes istat numeric value flow statistic graphed (possible values 1 8) qUnit object qUnit class printqUnitCheatSheet, numeric represented  short code, character representing descriptive name. Default 1, cubic feet per second. runoff logical variable, TRUE streamflow data converted runoff values mm/day","code":""},{"path":"/reference/printSeries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print annual results for a given streamflow statistic — printSeries","text":"data frame :","code":""},{"path":"/reference/printSeries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print annual results for a given streamflow statistic — printSeries","text":"smoothing algorithm defined makeAnnualSeries.   smoothing window defined eList$INFO$window value (default = 20)","code":""},{"path":"/reference/printSeries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print annual results for a given streamflow statistic — printSeries","text":"","code":"eList <- Choptank_eList printReturn <- printSeries(eList, 5) #>  #>  Choptank River #>  Water Year #>     mean daily #>     Cubic Feet per Second #>    year   annual   smoothed #>            value    value #>  #>    1980    150.2      108 #>    1981     78.3      109 #>    1982    107.6      111 #>    1983    176.1      112 #>    1984    201.9      114 #>    1985     53.6      115 #>    1986     92.8      117 #>    1987    119.1      118 #>    1988     66.0      120 #>    1989    198.2      121 #>    1990    141.5      123 #>    1991     97.0      124 #>    1992     77.2      126 #>    1993    131.8      127 #>    1994    193.7      129 #>    1995     85.3      131 #>    1996    220.5      132 #>    1997    206.0      134 #>    1998    172.5      136 #>    1999    102.3      138 #>    2000    166.8      139 #>    2001    172.2      141 #>    2002     43.8      143 #>    2003    305.2      145 #>    2004    186.4      147 #>    2005    134.6      149 #>    2006    126.8      151 #>    2007    151.2      153 #>    2008     90.5      155 #>    2009    130.0      157 #>    2010    254.0      159 #>    2011    185.2      161"},{"path":"/reference/printqUnitCheatSheet.html","id":null,"dir":"Reference","previous_headings":"","what":"Reminder to user of flow Unit properties such as cubic meters per second or thousands of cubic feet per second. — printqUnitCheatSheet","title":"Reminder to user of flow Unit properties such as cubic meters per second or thousands of cubic feet per second. — printqUnitCheatSheet","text":"Cheat sheet print pre-defined qUnit properties qUnit class. Flow units included:","code":""},{"path":"/reference/printqUnitCheatSheet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reminder to user of flow Unit properties such as cubic meters per second or thousands of cubic feet per second. — printqUnitCheatSheet","text":"","code":"printqUnitCheatSheet()"},{"path":"/reference/printqUnitCheatSheet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reminder to user of flow Unit properties such as cubic meters per second or thousands of cubic feet per second. — printqUnitCheatSheet","text":"","code":"printqUnitCheatSheet() #> The following codes apply to the qUnit list: #> 1 =  cfs  ( Cubic Feet per Second ) #> 2 =  cms  ( Cubic Meters per Second ) #> 3 =  thousandCfs  ( Thousand Cubic Feet per Second ) #> 4 =  thousandCms  ( Thousand Cubic Meters per Second )"},{"path":"/reference/processQWData.html","id":null,"dir":"Reference","previous_headings":"","what":"Processing of Water Quality Data — processQWData","title":"Processing of Water Quality Data — processQWData","text":"Processes water quality data. function looks detection limit detection  conditions determine value left censored . Censored values given qualifier \"<\".  dataframe also converted long wide format.","code":""},{"path":"/reference/processQWData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Processing of Water Quality Data — processQWData","text":"","code":"processQWData(data, pCode = TRUE)"},{"path":"/reference/processQWData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Processing of Water Quality Data — processQWData","text":"data dataframe Water Quality Portal pCode logical TRUE, assume data came pCode search, FALSE, characteristic name.","code":""},{"path":"/reference/processQWData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Processing of Water Quality Data — processQWData","text":"data dataframe first column dateTime, least one qualifier value columns (subsequent qualifier/value columns follow depending number parameter codes)","code":""},{"path":[]},{"path":"/reference/processQWData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Processing of Water Quality Data — processQWData","text":"","code":"# \\donttest{ #library(dataRetrieval)   #rawWQP <- readWQPqw('21FLEECO_WQX-IMPRGR80','Phosphorus', '', '') #Sample2 <- processQWData(rawWQP, pCode=FALSE) # }"},{"path":"/reference/qUnit-class.html","id":null,"dir":"Reference","previous_headings":"","what":"qUnit class — qUnit-class","title":"qUnit class — qUnit-class","text":"details qUnit class","code":""},{"path":"/reference/qUnit-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"qUnit class — qUnit-class","text":"qshortName character specifying short name. qUnitFactor numeric representing conversion factor qUnitName character specifying full name. qUnitExpress expression specifying full name. unitUSGS character specifying flux full text. qUnitTiny expression specifying abbreviated name. shortCode number quick lookup prefix character specifying general type measurement.","code":""},{"path":"/reference/randomSubset.html","id":null,"dir":"Reference","previous_headings":"","what":"randomSubset — randomSubset","title":"randomSubset — randomSubset","text":"Calculates random subset data based repeated values specified column.","code":""},{"path":"/reference/randomSubset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"randomSubset — randomSubset","text":"","code":"randomSubset(df, colName)"},{"path":"/reference/randomSubset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"randomSubset — randomSubset","text":"df data frame. Must include column named argument colName. colName column name check duplicates","code":""},{"path":"/reference/randomSubset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"randomSubset — randomSubset","text":"","code":"df <- data.frame(Julian = c(1,2,2,3,4,4,4,6),                  y = 1:8) df #>   Julian y #> 1      1 1 #> 2      2 2 #> 3      2 3 #> 4      3 4 #> 5      4 5 #> 6      4 6 #> 7      4 7 #> 8      6 8 df_random <- randomSubset(df, \"Julian\") df_random #>   Julian y #> 1      1 1 #> 2      2 2 #> 4      3 4 #> 6      4 6 #> 8      6 8"},{"path":"/reference/readDataFromFile.html","id":null,"dir":"Reference","previous_headings":"","what":"Basic Data Import for Water Flow Data — readDataFromFile","title":"Basic Data Import for Water Flow Data — readDataFromFile","text":"Imports data user-supplied data file. Specifically used import water flow data use EGRET package. EGRET usage, first column expected dates. data daily data, next column  expected measured values. data sampled data, next column remark codes, third column values.","code":""},{"path":"/reference/readDataFromFile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Basic Data Import for Water Flow Data — readDataFromFile","text":"","code":"readDataFromFile(filePath, fileName, hasHeader = TRUE, separator = \",\")"},{"path":"/reference/readDataFromFile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Basic Data Import for Water Flow Data — readDataFromFile","text":"filePath character specifying path file fileName character name file open hasHeader logical true first row data column headers separator character character separates data cells","code":""},{"path":"/reference/readDataFromFile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Basic Data Import for Water Flow Data — readDataFromFile","text":"retval dataframe dateTime, value, code columns","code":""},{"path":"/reference/readDataFromFile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Basic Data Import for Water Flow Data — readDataFromFile","text":"","code":"filePath <- system.file(\"extdata\", package=\"EGRET\") fileName <- 'ChoptankRiverFlow.txt' ChopData <- readDataFromFile(filePath,fileName, separator=\"\\t\")"},{"path":"/reference/readNWISDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","title":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","text":"Imports daily data NWIS web service. function gets data : https://waterservices.usgs.gov/","code":""},{"path":"/reference/readNWISDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","text":"","code":"readNWISDaily(siteNumber, parameterCd = \"00060\", startDate = \"\",   endDate = \"\", verbose = TRUE, interactive = NULL, convert = TRUE)"},{"path":"/reference/readNWISDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","text":"siteNumber character USGS site number.  usually 8 digit number parameterCd character USGS parameter code.  usually 5 digit number. startDate character starting date data retrieval form YYYY-MM-DD. endDate character ending date data retrieval form YYYY-MM-DD. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead convert logical Option include conversion cfs cms (35.314667). default TRUE,  appropriate using NWIS data EGRET package.  Set FALSE include conversion. parameter code 00060 (NWIS discharge), conversion applied.","code":""},{"path":"/reference/readNWISDaily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","text":"data frame 'Daily' following columns:","code":""},{"path":[]},{"path":"/reference/readNWISDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import NWIS Daily Data for EGRET analysis — readNWISDaily","text":"","code":"# \\donttest{  Daily <- readNWISDaily('01594440','00060', '1985-01-01', '1985-03-31') #> There are 90 data points, and 90 days. DailySuspSediment <- readNWISDaily('01594440','80154', '1985-01-01', '1985-03-31',convert=FALSE) #> There are 90 data points, and 90 days. # }"},{"path":"/reference/readNWISSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Import NWIS Sample Data for EGRET analysis — readNWISSample","title":"Import NWIS Sample Data for EGRET analysis — readNWISSample","text":"Imports data NWIS web service.  list parameter statistic codes can found : https://help.waterdata.usgs.gov/codes--parameters raw data, use readNWISqw dataRetrieval package.  function retrieve raw data, compress (summing constituents). See section 3.2.4 vignette details.","code":""},{"path":"/reference/readNWISSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import NWIS Sample Data for EGRET analysis — readNWISSample","text":"","code":"readNWISSample(siteNumber, parameterCd, startDate = \"\", endDate = \"\",   verbose = TRUE, interactive = NULL)"},{"path":"/reference/readNWISSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import NWIS Sample Data for EGRET analysis — readNWISSample","text":"siteNumber character USGS site number.  usually 8 digit number parameterCd character USGS parameter code.  usually 5 digit number. startDate character starting date data retrieval form YYYY-MM-DD. endDate character ending date data retrieval form YYYY-MM-DD. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/readNWISSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import NWIS Sample Data for EGRET analysis — readNWISSample","text":"data frame 'Sample' following columns:","code":""},{"path":[]},{"path":"/reference/readNWISSample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import NWIS Sample Data for EGRET analysis — readNWISSample","text":"","code":"# \\donttest{ # These examples require an internet connection to run  Sample_01075 <- readNWISSample('01594440','01075', '1985-01-01', '1985-03-31') #> Warning: NWIS qw web services are being retired. #> Please see vignette('qwdata_changes', package = 'dataRetrieval') #> for more information. #> https://cran.r-project.org/web/packages/dataRetrieval/vignettes/qwdata_changes.html # }"},{"path":"/reference/readUserDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Import user daily data for EGRET analysis — readUserDaily","title":"Import user daily data for EGRET analysis — readUserDaily","text":"Imports data user-supplied file, converts Daily data frame, appropriate WRTDS calculations.","code":""},{"path":"/reference/readUserDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import user daily data for EGRET analysis — readUserDaily","text":"","code":"readUserDaily(filePath, fileName, hasHeader = TRUE, separator = \",\",   qUnit = 1, verbose = TRUE, interactive = NULL)"},{"path":"/reference/readUserDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import user daily data for EGRET analysis — readUserDaily","text":"filePath character specifying path file fileName character name file open hasHeader logical true first row data column headers separator character character separates data cells qUnit number 1 cubic feet per second, 2 cubic meters per second, 3 10^3 cubic feet per second, 4 10^3 cubic meters per second verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/readUserDaily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import user daily data for EGRET analysis — readUserDaily","text":"data frame 'Daily' following columns:","code":""},{"path":"/reference/readUserDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import user daily data for EGRET analysis — readUserDaily","text":"","code":"filePath <- system.file(\"extdata\", package=\"EGRET\") fileName <- \"ChoptankRiverFlow.txt\" Daily <- readUserDaily(filePath,fileName,separator=\"\\t\") #> The input discharge are assumed to be in cubic feet per second, if they are in cubic meters per second, then the call to readUserDaily should specify qUnit=2 #> There are 4383 data points, and 4383 days."},{"path":"/reference/readUserSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Import user-supplied sample data for EGRET analysis — readUserSample","title":"Import user-supplied sample data for EGRET analysis — readUserSample","text":"Imports data user-supplied file, converts Sample data frame  (including summing multiple constituents), appropriate EGRET analysis.  First column date, second remark code, third value. multiple constituents  combined interval censoring, additional pairs columns can inserted, pair starting remark code (specifically looking <), followed values.","code":""},{"path":"/reference/readUserSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import user-supplied sample data for EGRET analysis — readUserSample","text":"","code":"readUserSample(filePath, fileName, hasHeader = TRUE, separator = \",\",   verbose = TRUE, interactive = NULL)"},{"path":"/reference/readUserSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import user-supplied sample data for EGRET analysis — readUserSample","text":"filePath character specifying path file fileName character name file open hasHeader logical true first row data column headers separator character character separates data cells. , default \",\" separator used .csv file. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/readUserSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import user-supplied sample data for EGRET analysis — readUserSample","text":"data frame 'Sample' following columns:","code":""},{"path":[]},{"path":"/reference/readUserSample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import user-supplied sample data for EGRET analysis — readUserSample","text":"","code":"filePath <- system.file(\"extdata\", package=\"EGRET\") fileName <- 'ChoptankRiverNitrate.csv' Sample <- readUserSample(filePath,fileName, separator=\";\",verbose=FALSE)"},{"path":"/reference/readWQPSample.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","title":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","text":"Imports data Water Quality Portal, STORET, USGS, USDA data.  function gets data : https://www.waterqualitydata.us raw data, use readWQPdata.  function retrieve raw data,  compress (summing constituents), converts Sample dataframe structure. See chapter 7 EGRET user guide details.","code":""},{"path":"/reference/readWQPSample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","text":"","code":"readWQPSample(siteNumber, characteristicName, startDate, endDate,   verbose = TRUE, interactive = NULL)"},{"path":"/reference/readWQPSample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","text":"siteNumber character site number.  USGS, form :'USGS-XXXXXXXXX...' characteristicName character startDate character starting date data retrieval form YYYY-MM-DD. endDate character ending date data retrieval form YYYY-MM-DD. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/readWQPSample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","text":"data frame 'Sample' following columns:","code":""},{"path":[]},{"path":"/reference/readWQPSample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Sample Data from the Water Quality Portal for WRTDS — readWQPSample","text":"","code":"# These examples require an internet connection to run # \\donttest{ # Sample_All <- readWQPSample('WIDNR_WQX-10032762','Specific conductance', '', '') # }"},{"path":"/reference/removeDuplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove duplicates values from Sample data frame. — removeDuplicates","title":"Remove duplicates values from Sample data frame. — removeDuplicates","text":"Removes observations data frame Sample observation identical date value another observation","code":""},{"path":"/reference/removeDuplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove duplicates values from Sample data frame. — removeDuplicates","text":"","code":"removeDuplicates(Sample)"},{"path":"/reference/removeDuplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove duplicates values from Sample data frame. — removeDuplicates","text":"Sample dataframe least DecYear ConcHigh, default name Sample","code":""},{"path":"/reference/removeDuplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove duplicates values from Sample data frame. — removeDuplicates","text":"data frame 'Sample' following columns:","code":""},{"path":"/reference/removeDuplicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove duplicates values from Sample data frame. — removeDuplicates","text":"","code":"DecYear <- c('1985.01', '1985.01', '1985.02', '1985.02', '1985.03') ConcHigh <- c(1,2,3,3,5) dataInput <- data.frame(DecYear, ConcHigh, stringsAsFactors=FALSE) Sample <- removeDuplicates(dataInput)"},{"path":"/reference/runGroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a comparison of any group of years in the record. — runGroups","title":"Runs a comparison of any group of years in the record. — runGroups","text":"runGroups provides comparisons results, terms  flow-normalized concentration flow-normalized flux groups years years water quality record.  Comparison involve  use \"wall\" /use \"generalized flow-normalization\".   two concepts described detail vignette: vignette(\"Enhancements\", package = \"EGRET\").","code":""},{"path":"/reference/runGroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a comparison of any group of years in the record. — runGroups","text":"","code":"runGroups(eList, windowSide, group1firstYear, group1lastYear, group2firstYear,   group2lastYear, surfaceStart = NA, surfaceEnd = NA, flowBreak = FALSE,   Q1EndDate = NA, QStartDate = NA, QEndDate = NA, wall = FALSE,   oldSurface = FALSE, fractMin = 0.75, sample1EndDate = NA,   sampleStartDate = NA, sampleEndDate = NA, paStart = NA, paLong = NA,   minNumObs = 100, minNumUncen = 50, windowY = 7, windowQ = 2,   windowS = 0.5, edgeAdjust = TRUE, verbose = TRUE, saveOutput = FALSE,   fileName = \"temp.txt\")"},{"path":"/reference/runGroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a comparison of any group of years in the record. — runGroups","text":"eList named list least Daily, Sample, INFO dataframes windowSide integer. width flow normalization window side year estimated. common value 11, default specified.  stationary flow normalization used, windowSide = 0 (means  flow-normalization period years ). group1firstYear decimal year. Starting year first group. group1lastYear decimal year. Ending year first group. group2firstYear decimal year. Starting year second group. group2lastYear decimal year. Ending year second group. surfaceStart Date (character YYYY-MM-DD) start WRTDS model estimated first  daily outputs generated. Default NA, means surfaceStart based date first sample. surfaceEnd Date (character YYYY-MM-DD) end WRTDS model estimated last daily outputs  generated.  Default NA, means surfaceEnd based date last sample. flowBreak logical. abrupt break discharge record, default FALSE. Q1EndDate Date (character YYYY-MM-DD) last day, just flowBreak. QStartDate first Date (character YYYY-MM-DD) used  flow normalization method.  Default  NA, makes QStartDate become first Date eList$Daily. QEndDate last Date (character YYYY-MM-DD) used flow normalization method.  Default NA,  makes QEndDate become last Date eList$Daily. wall logical. Whether abrupt break concentration versus discharge relationship due major change  pollution control water management.  Default FALSE. oldSurface logical specifying whether use original surface, create new one. Default FALSE. fractMin numeric specifying minimum fraction observations required run weighted regression, default 0.75. minimum number maximum minNumObs fractMin multiplied total number observations. sample1EndDate Date (character YYYY-MM-DD) last date just wall. Default = NA.  date must specified wall = TRUE. sampleStartDate Date (character YYYY-MM-DD) first sample used. Default NA sets  first Date eList$Sample. sampleEndDate Date (character YYYY-MM-DD) last sample used.  Default NA sets last Date eList$Sample. paStart numeric integer specifying starting month period analysis, 1<=paStart<=12. Default NA, use paStart eList$INFO data frame. See also setPA. paLong numeric integer specifying length period analysis, months, 1<=paLong<=12.  Default NA, use paLong eList$INFO data frame. See also setPA. minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 edgeAdjust logical specifying whether use modified method calculating windows edge record. edgeAdjust method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether display progress message saveOutput logical. TRUE, text file saved working directory printout console output. Default FALSE. fileName character. Name save output file saveOutput=TRUE.","code":""},{"path":"/reference/runGroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs a comparison of any group of years in the record. — runGroups","text":"Dataframe 7 columns 2 rows.  first row trends concentration (mg/L), second column trends flux (million kg/year). data frame number attributes.","code":""},{"path":"/reference/runGroups.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Runs a comparison of any group of years in the record. — runGroups","text":"using generalized flow-normalization, best Daily data frame extend well beyond years Sample data frame.  Ideally,  Daily data frame start windowSide years start Sample data set, data exist provide . Generally possible end record Sample data may end close present. extent possible therefore, better include discharge data end Sample record.  Also note case run examples ,  data set needs appropriate stationary flow  normalization well (package size considerations make difficult include specialized examples).","code":""},{"path":"/reference/runGroups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Runs a comparison of any group of years in the record. — runGroups","text":"","code":"eList <- Choptank_eList # \\donttest{  #Option 1:  Use all years for group flow normalization. groupOut_1 <- runGroups(eList,  windowSide = 0,                        group1firstYear = 1980, group1lastYear = 1990,                        group2firstYear = 1995, group2lastYear = 2005) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.226 mg/L #>  expressed as Percent Change is  22 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.022 million kg/year #>  expressed as Percent Change is  19 % #>  #>  Concentration v. Q Trend Component  19 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.226 0.226   0 1.02 1.02 1.24 1.24 #> Flux       0.022 0.022   0 0.12 0.12 0.14 0.14  # Option 2: Use sliding window. #                In each case it is a 23 year window (23 = 1 + 2 * 11)  groupOut_2 <- runGroups(eList,  windowSide = 11,                        group1firstYear = 1980, group1lastYear = 1990,                        group2firstYear = 1995, group2lastYear = 2005) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.212 mg/L #>  expressed as Percent Change is  21 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             -1.4 %  #>  #>  #>  For flux: total change is  0.0316 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  20 % #>        Q Trend Component             8.8 %  #>  #>      TotalChange  CQTC     QTC  x10  x11  x20  x22 #> Conc       0.212 0.226 -0.0140 1.02 1.03 1.24 1.24 #> Flux       0.032 0.022  0.0097 0.12 0.11 0.14 0.14  # Option 3: Flow normalization is based on splitting the flow record at 1990-09-30 #                But in years before the break it uses all flow data from before the break, #                and years after the break uses all flow data after the break  groupOut_3 <- runGroups(eList,  windowSide = 0,                        group1firstYear = 1980, group1lastYear = 1990,                        group2firstYear = 1995, group2lastYear = 2005,                        flowBreak = TRUE,                         Q1EndDate = \"1990-09-30\") #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.207 mg/L #>  expressed as Percent Change is  20 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             -1.9 %  #>  #>  #>  For flux: total change is  0.0371 million kg/year #>  expressed as Percent Change is  35 % #>  #>  Concentration v. Q Trend Component  21 % #>        Q Trend Component             14 %  #>  #>      TotalChange  CQTC    QTC  x10  x11  x20  x22 #> Conc       0.207 0.226 -0.019 1.02 1.03 1.24 1.24 #> Flux       0.037 0.022  0.015 0.12 0.11 0.14 0.14  # Option 4: Flow normalization is based on splitting the flow record at 1990-09-30 #                but before the break uses a 23 year window of years before the break #                after the break uses a 23 year window of years after the break groupOut_4 <- runGroups(eList,  windowSide = 11,                        group1firstYear = 1980, group1lastYear = 1990,                        group2firstYear = 1995, group2lastYear = 2005,                        flowBreak = TRUE,                         Q1EndDate = \"1990-09-30\") #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates for #>  average of 1995  through 2005  minus average of 1980  through 1990  #>  #>  For concentration: total change is  0.207 mg/L #>  expressed as Percent Change is  20 % #>  #>  Concentration v. Q Trend Component  22 % #>        Q Trend Component             -1.9 %  #>  #>  #>  For flux: total change is  0.0371 million kg/year #>  expressed as Percent Change is  35 % #>  #>  Concentration v. Q Trend Component  21 % #>        Q Trend Component             14 %  #>  #>      TotalChange  CQTC    QTC  x10  x11  x20  x22 #> Conc       0.207 0.226 -0.019 1.02 1.03 1.24 1.24 #> Flux       0.037 0.022  0.015 0.12 0.11 0.14 0.14  # }"},{"path":"/reference/runPairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a comparison of any two years in the record. — runPairs","title":"Runs a comparison of any two years in the record. — runPairs","text":"runPairs provides comparisons results, terms  flow-normalized concentration flow-normalized flux pair  years water quality record.  Comparison involve  use \"wall\" /use \"generalized flow normalization\".   two concepts described detail vignette: vignette(\"Enhancements\", package = \"EGRET\").","code":""},{"path":"/reference/runPairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a comparison of any two years in the record. — runPairs","text":"","code":"runPairs(eList, year1, year2, windowSide, flowBreak = FALSE,   Q1EndDate = NA, QStartDate = NA, QEndDate = NA, wall = FALSE,   oldSurface = FALSE, sample1EndDate = NA, sampleStartDate = NA,   sampleEndDate = NA, paStart = NA, paLong = NA, minNumObs = 100,   minNumUncen = 50, fractMin = 0.75, windowY = 7, windowQ = 2,   windowS = 0.5, edgeAdjust = TRUE, saveOutput = FALSE,   fileName = \"temp.txt\", verbose = TRUE)"},{"path":"/reference/runPairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a comparison of any two years in the record. — runPairs","text":"eList named list least Daily, Sample, INFO dataframes year1 integer ending year first year pair year2 integer ending year second year pair windowSide integer. width flow normalization window side year estimated. common value 11, default specified.  stationary flow normalization used, windowSide = 0 (means  flow-normalization period years ). flowBreak logical. abrupt break discharge record, default FALSE. Q1EndDate Date (character YYYY-MM-DD) last day, just flowBreak. QStartDate first Date (character YYYY-MM-DD) used  flow normalization method.  Default  NA, makes QStartDate become first Date eList$Daily. QEndDate last Date (character YYYY-MM-DD) used flow normalization method.  Default NA,  makes QEndDate become last Date eList$Daily. wall logical. Whether abrupt break concentration versus discharge relationship due major change  pollution control water management.  Default FALSE. oldSurface logical specifying whether use original surface, create new one. Default FALSE. sample1EndDate Date (character YYYY-MM-DD) last date just wall. Default = NA.  date must specified wall = TRUE. sampleStartDate Date (character YYYY-MM-DD) first sample used. Default NA sets  first Date eList$Sample. sampleEndDate Date (character YYYY-MM-DD) last sample used.  Default NA sets last Date eList$Sample. paStart numeric integer specifying starting month period analysis, 1<=paStart<=12. Default NA, use paStart eList$INFO data frame. See also setPA. paLong numeric integer specifying length period analysis, months, 1<=paLong<=12.  Default NA, use paLong eList$INFO data frame. See also setPA. minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 fractMin numeric specifying minimum fraction observations required run weighted regression, default 0.75. minimum number maximum minNumObs fractMin multiplied total number observations. windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 edgeAdjust logical specifying whether use modified method calculating windows edge record. edgeAdjust method tends reduce curvature near start end record.  Default TRUE. saveOutput logical. TRUE, text file saved working directory printout console output. Default FALSE. fileName character. Name save output file saveOutput=TRUE. verbose logical specifying whether display progress message","code":""},{"path":"/reference/runPairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs a comparison of any two years in the record. — runPairs","text":"Data frame 7 columns 2 rows.  first row trends concentration (mg/L),  second column trends flux (million kg/year).   data frame number attributes. Additionally, attribute data frame \"\", containing list includes minNumObs=minNumObs, minNumUncen, windowY, windowQ, siteName, windowS, wall, edgeAdjust, QStartDate, QEndDate, PercentChangeConc, PercentChangeFlux. PercentChangeConc, PercentChangeFlux vectors : Total Percent Change Total Change divided x11 CQTC Percent CQTC divided x11 QTC Percent  QTC divided x11 Another attribute \"byMonth\". data frame flux concentration changes month.","code":""},{"path":"/reference/runPairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Runs a comparison of any two years in the record. — runPairs","text":"using generalized flow-normalization, best Daily data frame extend well beyond years Sample data frame.  Ideally,  Daily data frame start windowSide years start Sample data set, data exist provide . Generally possible end record Sample data may end close present. extent possible therefore, better include discharge data end Sample record.  Also note case run examples ,  data set needs appropriate stationary flow  normalization well (package size considerations make difficult include specialized examples).","code":""},{"path":"/reference/runPairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Runs a comparison of any two years in the record. — runPairs","text":"","code":"eList <- Choptank_eList year1 <- 1985 year2 <- 2010  # \\donttest{ # Automatic calculations based on windowSide = 11 # four possible ways to do generalized flow normalization:  #Option 1: Use all years for flow normalization.  pairOut_1 <- runPairs(eList, year1, year2, windowSide = 0) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.429 mg/L #>  expressed as Percent Change is  42 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             0 %  #>  #>  #>  For flux: total change is  0.0342 million kg/year #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  29 % #>        Q Trend Component             0 %  #>  #>      TotalChange  CQTC QTC  x10  x11  x20  x22 #> Conc       0.429 0.429   0 1.01 1.01 1.44 1.44 #> Flux       0.034 0.034   0 0.12 0.12 0.15 0.15  # Option 2:  Use different windows for flow normalization for year1 versus year2 #            In each case it is a 23 year window (23 = 1 + 2*11)  pairOut_2 <- runPairs(eList, year1, year2, windowSide = 11) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.407 mg/L #>  expressed as Percent Change is  40 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             -2.2 %  #>  #>  #>  For flux: total change is  0.0476 million kg/year #>  expressed as Percent Change is  43 % #>  #>  Concentration v. Q Trend Component  31 % #>        Q Trend Component             12 %  #>  #>      TotalChange  CQTC    QTC  x10  x11  x20  x22 #> Conc       0.407 0.429 -0.022 1.01 1.02 1.44 1.43 #> Flux       0.048 0.034  0.013 0.12 0.11 0.15 0.16  # Option 3: Flow normalization is based on splitting the flow record at 1990-09-30 #          But year1 uses all flow data from before the break,  #          year2 uses all flow data after the break  pairOut_3 <- runPairs(eList, year1, year2,                        windowSide = 0, flowBreak = TRUE,                       Q1EndDate = \"1990-09-30\") #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.408 mg/L #>  expressed as Percent Change is  40 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             -2 %  #>  #>  #>  For flux: total change is  0.0491 million kg/year #>  expressed as Percent Change is  46 % #>  #>  Concentration v. Q Trend Component  32 % #>        Q Trend Component             14 %  #>  #>      TotalChange  CQTC    QTC  x10  x11  x20  x22 #> Conc       0.408 0.429 -0.021 1.01 1.03 1.44 1.43 #> Flux       0.049 0.034  0.015 0.12 0.11 0.15 0.16  # Option 4: Flow normalization is based on splitting the flow record at 1990-09-30 #           but year1 uses a 23 year window before the break #           year2 uses a 23 year window after the break  pairOut_4 <- runPairs(eList, year1, year2,                        windowSide = 11, flowBreak = TRUE,                       Q1EndDate = \"1990-09-30\") #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.408 mg/L #>  expressed as Percent Change is  40 % #>  #>  Concentration v. Q Trend Component  42 % #>        Q Trend Component             -2 %  #>  #>  #>  For flux: total change is  0.0491 million kg/year #>  expressed as Percent Change is  46 % #>  #>  Concentration v. Q Trend Component  32 % #>        Q Trend Component             14 %  #>  #>      TotalChange  CQTC    QTC  x10  x11  x20  x22 #> Conc       0.408 0.429 -0.021 1.01 1.03 1.44 1.43 #> Flux       0.049 0.034  0.015 0.12 0.11 0.15 0.16                        monthly_trends <- attr(pairOut_4, \"byMonth\")   plotMonthTrend(pairOut_4)   eList <- setPA(eList, paLong = 3, paStart = 12) pairOut_5 <- runPairs(eList, year1, year2,                       windowSide = 11) #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #> Sample1 has 606 Samples and 605 are uncensored #> Sample2 has 606 Samples and 605 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Season Consisting of Dec Jan Feb  #>  #>  Change estimates  2010  minus  1985  #>  #>  For concentration: total change is  0.356 mg/L #>  expressed as Percent Change is  29 % #>  #>  Concentration v. Q Trend Component  30 % #>        Q Trend Component             -1.1 %  #>  #>  #>  For flux: total change is  0.0564 million kg/year #>  expressed as Percent Change is  33 % #>  #>  Concentration v. Q Trend Component  24 % #>        Q Trend Component             9.6 %  #>  #>      TotalChange CQTC    QTC  x10  x11  x20  x22 #> Conc       0.356 0.37 -0.013 1.21 1.22 1.58 1.57 #> Flux       0.056 0.04  0.016 0.18 0.17 0.22 0.23 monthly_trends <- attr(pairOut_5, \"byMonth\")  plotMonthTrend(pairOut_5)                         # }"},{"path":"/reference/runSeries.html","id":null,"dir":"Reference","previous_headings":"","what":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"runSeries provides annual series flow-normalized concentration flow-normalized flux water quality record.   Computations involve use \"wall\" /use \"generalized flow  normalization\".  two concepts described detail vignette:   vignette(\"Enhancements\", package = \"EGRET\").","code":""},{"path":"/reference/runSeries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"","code":"runSeries(eList, windowSide, surfaceStart = NA, surfaceEnd = NA,   flowBreak = FALSE, Q1EndDate = NA, QStartDate = NA, QEndDate = NA,   wall = FALSE, oldSurface = FALSE, sample1EndDate = NA,   sampleStartDate = NA, sampleEndDate = NA, paStart = NA, paLong = NA,   fractMin = 0.75, minNumObs = 100, minNumUncen = 50, windowY = 7,   windowQ = 2, windowS = 0.5, edgeAdjust = TRUE, verbose = TRUE)"},{"path":"/reference/runSeries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"eList named list least Daily, Sample, INFO dataframes windowSide integer. width flow normalization window side year estimated. common value 11, default specified.  stationary flow normalization used, windowSide = 0 (means  flow-normalization period years ). surfaceStart Date (character YYYY-MM-DD) start WRTDS model estimated first  daily outputs generated.  Default NA, means surfaceStart based date first sample. surfaceEnd Date (character YYYY-MM-DD) end WRTDS model estimated last daily outputs  generated.  Default NA, means surfaceEnd based date last sample. flowBreak logical, abrupt break discharge record, default FALSE. Q1EndDate Date (character YYYY-MM-DD format) last day, just flowBreak. Required flowBreak = TRUE. QStartDate first Date (character YYYY-MM-DD format) used flow normalization.  Default NA, makes QStartDate become first Date eList$Daily. QEndDate last Date (character YYYY-MM-DD format) used flow normalization.  Default NA, makes QEndDate become last Date eList$Daily. wall logical. Whether abrupt break concentration versus discharge relationship due major change  pollution control water management.  Default FALSE. oldSurface logical, TRUE, use surface previously estimated using modelEstimation.  Default FALSE. sample1EndDate Date (character YYYY-MM-DD format) last day just wall.  Default = NA.  date must specified wall = TRUE. sampleStartDate Date (character YYYY-MM-DD format) first sample used.  Default NA sets first Date eList$Sample. sampleEndDate Date (character YYYY-MM-DD format) last sample used. Default NA sets last Date eList$Sample. paStart numeric integer specifying starting month period analysis, 1<=paStart<=12. Default NA, use paStart eList$INFO data frame. See also setPA. paLong numeric integer specifying length period analysis, months, 1<=paLong<=12.  Default NA, use paLong eList$INFO data frame. See also setPA. fractMin numeric specifying minimum fraction observations required run weighted regression, default 0.75. minimum number maximum minNumObs fractMin multiplied total number observations. minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 edgeAdjust logical specifying whether use modified method calculating windows edge record. edgeAdjust method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether output status messages.","code":""},{"path":"/reference/runSeries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"eList named list INFO, Daily, Sample dataframes, along surfaces matrix.","code":""},{"path":"/reference/runSeries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"using generalized flow-normalization, best Daily data frame extend well beyond years Sample data frame.  Ideally,  Daily data frame start windowSide years start Sample data set, data exist provide . Generally possible end record Sample data may end close present. extent possible therefore, better include discharge data end Sample record.  Also note case run examples ,  data set needs appropriate stationary flow  normalization well (package size considerations make difficult include specialized examples).","code":""},{"path":"/reference/runSeries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Annual series of flow-normalized concentration and flow-normalized flux — runSeries","text":"","code":"eList <- Choptank_eList  # \\donttest{ # Automatic calculations based on windowSide = 11 # four possible ways to do generalized flow normalization  #Option 1:  Use all years for flow normalization. seriesOut_1 <- runSeries(eList,  windowSide = 0) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done plotConcHist(seriesOut_1)  plotFluxHist(seriesOut_1)   # Option 2: Use sliding window throughout the whole flow normalization process. #                In each case it is a 15 year window (23 = 1 + 2*11) seriesOut_2 <- runSeries(eList, windowSide = 11) #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done  plotConcHist(seriesOut_2)  plotFluxHist(seriesOut_2)   # Option 3: Flow normalization is based on splitting the flow record at 1990-09-30 #                But in years before the break it uses all flow data from before the break,  #                and years after the break uses all flow data after the break seriesOut_3 <- runSeries(eList,                        windowSide = 0,                         flowBreak = TRUE,                        Q1EndDate = \"1990-09-30\") #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done                         plotConcHist(seriesOut_3)  plotFluxHist(seriesOut_3)   # Option 4: Flow normalization is based on splitting the flow record at 1990-09-30 #                but before the break uses a 23 year window of years before the break #                after the break uses a 23 year window of years after the break seriesOut_4 <- runSeries(eList,                        windowSide = 11, flowBreak = TRUE,                       Q1EndDate = \"1990-09-30\") #> Survival regression (% complete): #> 0 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t #> 11 \t12 \t13 \t14 \t15 \t16 \t17 \t18 \t19 \t20 \t #> 21 \t22 \t23 \t24 \t25 \t26 \t27 \t28 \t29 \t30 \t #> 31 \t32 \t33 \t34 \t35 \t36 \t37 \t38 \t39 \t40 \t #> 41 \t42 \t43 \t44 \t45 \t46 \t47 \t48 \t49 \t50 \t #> 51 \t52 \t53 \t54 \t55 \t56 \t57 \t58 \t59 \t60 \t #> 61 \t62 \t63 \t64 \t65 \t66 \t67 \t68 \t69 \t70 \t #> 71 \t72 \t73 \t74 \t75 \t76 \t77 \t78 \t79 \t80 \t #> 81 \t82 \t83 \t84 \t85 \t86 \t87 \t88 \t89 \t90 \t #> 91 \t92 \t93 \t94 \t95 \t96 \t97 \t98 \t99 \t #> Survival regression: Done                        plotConcHist(seriesOut_4)  plotFluxHist(seriesOut_4)   # }"},{"path":"/reference/runSurvReg.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","title":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","text":"function runs survival regression concentration estimation method WRTDS.  uses sample data data frame Sample.  estimation set data points defined two vectors: estPtYear estPtLQ.  returns array results estimation points.   array returned contains yHat, SE ConcHat (order). yHat expected value log(concentration), SE  standard error log(concentration) ConcHat expected value concentration.","code":""},{"path":"/reference/runSurvReg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","text":"","code":"runSurvReg(estPtYear, estPtLQ, DecLow, DecHigh, Sample, windowY = 7,   windowQ = 2, windowS = 0.5, minNumObs = 100, minNumUncen = 50,   verbose = TRUE, interactive = NULL, edgeAdjust = TRUE,   run.parallel = FALSE)  run_WRTDS(estY, estLQ, localSample, DecLow, DecHigh, minNumObs, minNumUncen,   windowY, windowQ, windowS, edgeAdjust)"},{"path":"/reference/runSurvReg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","text":"estPtYear numeric vector Decimal Year values estimation points estPtLQ numeric vector ln(Q) values estimation points, must length estPtYear DecLow number specifying minimum decimal year (left edge estimated surfaces). DecHigh number specifying maximum decimal year (right edge estimated surfaces). Sample dataframe created EGRET analysis windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead edgeAdjust logical specifying whether use modified method calculating windows edge record.  modified method tends reduce curvature near start end record.  Default TRUE. run.parallel logical run bootstrapping parallel estY numeric decimal year values estimation point estLQ numeric ln(Q) values estimation point localSample \"Sample\" data frame eList.","code":""},{"path":"/reference/runSurvReg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","text":"resultSurvReg numeric array containing yHat, SE, ConcHat values array dimensions (numEstPts,3)","code":""},{"path":"/reference/runSurvReg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run the weighted survival regression for a set of estimation points (defined by DecYear and Log(Q)) — runSurvReg","text":"","code":"eList <- Choptank_eList estPtYear<-c(2001.0,2005.0,2009.0) estPtLQ<-c(1,1,1) Sample <- getSample(eList) DecLow <- Sample$DecYear[1] DecHigh <- Sample$DecYear[nrow(Sample)] resultSurvReg <- runSurvReg(estPtYear,estPtLQ,                             DecLow,DecHigh,Sample,                             run.parallel = FALSE) #> Survival regression (% complete): #> 33 \t66 \t #> Survival regression: Done"},{"path":"/reference/sampleData.html","id":null,"dir":"Reference","previous_headings":"","what":"Example eList — Choptank_eList","title":"Example eList — Choptank_eList","text":"Example data representing data Choptank River Greensboro, MD,  USGS data Data named list Daily, Sample, INFO dataframes, surface matrix.","code":""},{"path":"/reference/sampleData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example eList — Choptank_eList","text":"","code":"head(Choptank_eList$Daily) #>         Date        Q Julian Month Day  DecYear MonthSeq Qualifier i      LogQ #> 1 1979-10-01 1.897229  47389    10 275 1979.750     1558         A 1 0.6403942 #> 2 1979-10-02 2.010496  47390    10 276 1979.753     1558         A 2 0.6983815 #> 3 1979-10-03 2.746734  47391    10 277 1979.755     1558         A 3 1.0104126 #> 4 1979-10-04 3.851091  47392    10 278 1979.758     1558         A 4 1.3483565 #> 5 1979-10-05 4.077626  47393    10 279 1979.761     1558         A 5 1.4055149 #> 6 1979-10-06 3.199804  47394    10 280 1979.764     1558         A 6 1.1630894 #>   Q7 Q30       yHat        SE   ConcDay  FluxDay    FNConc   FNFlux #> 1 NA  NA -0.1645456 0.2214490 0.8745462 143.3561 0.9727565 114.7660 #> 2 NA  NA -0.1802420 0.2209740 0.8597670 149.3474 0.9828022 112.1125 #> 3 NA  NA -0.3044300 0.2170166 0.7641524 181.3470 0.9889741 109.7710 #> 4 NA  NA -0.4642075 0.2118471 0.6544177 217.7472 0.9940480 109.4190 #> 5 NA  NA -0.4872318 0.2110424 0.6383146 224.8826 1.0034610 108.3759 #> 6 NA  NA -0.3675283 0.2149243 0.7209948 199.3284 1.0084551 106.1974 head(Arkansas_eList$Daily) #>            Date     Q Julian Month Day  DecYear MonthSeq    i     LogQ       Q7 #> 9132 1989-10-01 37600  51042    10 275 1989.749     1678 9132 10.53476 38071.43 #> 9133 1989-10-02 34400  51043    10 276 1989.752     1678 9133 10.44581 37071.43 #> 9134 1989-10-03 37200  51044    10 277 1989.755     1678 9134 10.52406 36400.00 #> 9135 1989-10-04 30200  51045    10 278 1989.758     1678 9135 10.31560 35571.43 #> 9136 1989-10-05 28100  51046    10 279 1989.760     1678 9136 10.24352 35185.71 #> 9137 1989-10-06 27100  51047    10 280 1989.763     1678 9137 10.20729 33642.86 #>           Q30 waterYear      yHat        SE ConcDay FluxDay FNConc FNFlux #> 9132 51670.00      1990 -3.184867 0.7173803      NA      NA     NA     NA #> 9133 51710.00      1990 -3.188835 0.7257386      NA      NA     NA     NA #> 9134 51533.33      1990 -3.167081 0.7156364      NA      NA     NA     NA #> 9135 51116.67      1990 -3.187290 0.7368824      NA      NA     NA     NA #> 9136 51093.33      1990 -3.187121 0.7431933      NA      NA     NA     NA #> 9137 51033.33      1990 -3.181600 0.7455803      NA      NA     NA     NA"},{"path":"/reference/saveResults.html","id":null,"dir":"Reference","previous_headings":"","what":"A utility program for saving the contents of the workspace\n  \n This function saves the workspace. Future versions of EGRET will not include this function,\n use saveRDS to save individual eList objects.\n It assigns the file a name using the abbreviations for station and constituent. — saveResults","title":"A utility program for saving the contents of the workspace\n  \n This function saves the workspace. Future versions of EGRET will not include this function,\n use saveRDS to save individual eList objects.\n It assigns the file a name using the abbreviations for station and constituent. — saveResults","text":"utility program saving contents workspace function saves workspace. Future versions EGRET include function,  use saveRDS save individual eList objects.  assigns file name using abbreviations station constituent.","code":""},{"path":"/reference/saveResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A utility program for saving the contents of the workspace\n  \n This function saves the workspace. Future versions of EGRET will not include this function,\n use saveRDS to save individual eList objects.\n It assigns the file a name using the abbreviations for station and constituent. — saveResults","text":"","code":"saveResults(savePath, eList)"},{"path":"/reference/saveResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A utility program for saving the contents of the workspace\n  \n This function saves the workspace. Future versions of EGRET will not include this function,\n use saveRDS to save individual eList objects.\n It assigns the file a name using the abbreviations for station and constituent. — saveResults","text":"savePath character specifying full pathname folder file saved ending final slash eList named list least INFO dataframe","code":""},{"path":"/reference/selectDays.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","title":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","text":"function uses user-defined 'period analysis', subsets Daily data frame,  effect Sample data frame. want examine data set time series water years,  period analysis October September.   want examine data set calendar years period analysis January December.   might want examine winter season, define December February,  3 months become period analysis. constraints definition period analysis  : must defined terms whole months; must set contiguous months (like March-April-May),  length less 1 month 12 months.   Define PA using two arguments: paLong paStart. paLong length period analysis, paStart starting month.","code":""},{"path":"/reference/selectDays.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","text":"","code":"selectDays(df, paLong, paStart)"},{"path":"/reference/selectDays.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","text":"df dataframe must contain column named Month (month calendar year, typically  Daily data frame. paLong numeric value length period analysis, must integer 1 12 paStart numeric value starting month period analysis, must integer 1 12","code":""},{"path":"/reference/selectDays.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","text":"localDaily data frame containing daily data period analysis (months)","code":""},{"path":"/reference/selectDays.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a subset Daily data frame that only contains daily estimates for the specified period of analysis — selectDays","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) DailySubset <- selectDays(Daily, 4, 11)"},{"path":"/reference/setPA.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","title":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","text":"Period analysis defined starting month (paStart) length months (paLong).  paStart paLong constrained integers 1 12. example, water year paStart = 10 paLong = 12. example, winter season, defined Dec,Jan,Feb paStart = 12 paLong = 3.","code":""},{"path":"/reference/setPA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","text":"","code":"setPA(eList, paStart = 10, paLong = 12, window = 20)"},{"path":"/reference/setPA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","text":"eList named list least INFO dataframe paStart numeric value starting month Period Analysis, default 10 paLong numeric value length Period Analysis months, default 12 window numeric value half-width smoothing window annual streamflow values, default 20","code":""},{"path":"/reference/setPA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","text":"eList named list least INFO dataframe.  values can NA, EGRET functions work missing parts named list eList.","code":""},{"path":"/reference/setPA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up the period of analysis (the portion of the year being evaluated). — setPA","text":"","code":"eList <- Choptank_eList eList <- setPA(eList, paStart = 12, paLong = 3)"},{"path":"/reference/setSeasonLabel.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","title":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","text":"period analysis can length 1 month 12 months.  period analysis can starting month 1 (January) 12 (December).  function produces character character describes period analysis.  example \"water year\", \"calendar year\", \"year starting April\",  \"Season consisting April, May, June\".  alternative version function case AnnualResults exist.  might arise call plotConcTime plotLogConcTime.  function called setSeasonLabelByUser.","code":""},{"path":"/reference/setSeasonLabel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","text":"","code":"setSeasonLabel(localAnnualResults, monthLab = 1)"},{"path":"/reference/setSeasonLabel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","text":"localAnnualResults data frame contains annual results, default AnnualResults monthLab object monthLabel class, numeric represented short code,  character representing descriptive name.","code":""},{"path":"/reference/setSeasonLabel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","text":"periodName character describes period analysis","code":""},{"path":"/reference/setSeasonLabel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a character variable that describes the period of analysis, when period of analysis has already been set in AnnualResults — setSeasonLabel","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) AnnualResults <- setupYears(Daily) setSeasonLabel(AnnualResults) #> [1] \"Water Year\"  AnnualResultsWinter <- setupYears(Daily,                                    paLong = 3,                                   paStart = 12) setSeasonLabel(AnnualResultsWinter) #> [1] \"Season Consisting of Dec Jan Feb\""},{"path":"/reference/setSeasonLabelByUser.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","title":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","text":"period analysis can length 1 month 12 months.  period analysis can starting month 1 (January) 12 (December).  function produces character describes period analysis.  example \"water year\", \"calendar year\", \"year starting April\",  \"Season consisting April, May, June\".  alternative version function case AnnualResults exists.  want use period analysis defined .  function called setSeasonLabel.","code":""},{"path":"/reference/setSeasonLabelByUser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","text":"","code":"setSeasonLabelByUser(paStartInput = 10, paLongInput = 12, monthLab = 1)"},{"path":"/reference/setSeasonLabelByUser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","text":"paStartInput numeric month start period  analysis, default 10 case period analysis  water year paLongInput numeric length period analysis,  months, default 12 case period analysis  water year monthLab object monthLabel class, numeric represented short code,  character representing descriptive name.","code":""},{"path":"/reference/setSeasonLabelByUser.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","text":"periodName character describes period analysis","code":""},{"path":"/reference/setSeasonLabelByUser.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a character variable that describes the period of analysis, when the period of analysis is being set by the user and not from AnnualResults — setSeasonLabelByUser","text":"","code":"setSeasonLabelByUser(paStartInput=1,paLongInput=12) #> [1] \"Calendar Year\" setSeasonLabelByUser(paStartInput=4,paLongInput=3) #> [1] \"Season Consisting of Apr May Jun\""},{"path":"/reference/setUpEstimation.html","id":null,"dir":"Reference","previous_headings":"","what":"setUpEstimation — setUpEstimation","title":"setUpEstimation — setUpEstimation","text":"Set INFO data frame modelEstimation","code":""},{"path":"/reference/setUpEstimation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"setUpEstimation — setUpEstimation","text":"","code":"setUpEstimation(eList, windowY = 7, windowQ = 2, windowS = 0.5,   minNumObs = 100, minNumUncen = 50, edgeAdjust = TRUE, verbose = TRUE,   interactive = NULL)"},{"path":"/reference/setUpEstimation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"setUpEstimation — setUpEstimation","text":"eList named list least Daily, Sample, INFO dataframes windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 edgeAdjust logical specifying whether use modified method calculating windows edge record. modified method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether display progress message interactive logical deprecated. Use 'verbose' instead","code":""},{"path":"/reference/setUpEstimation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"setUpEstimation — setUpEstimation","text":"eList named list Daily, Sample, INFO dataframes.","code":""},{"path":"/reference/setUpEstimation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"setUpEstimation — setUpEstimation","text":"","code":"eList <- Choptank_eList eList <- setUpEstimation(eList)"},{"path":"/reference/setupYears.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates the AnnualResults data frame from the Daily data frame — setupYears","title":"Creates the AnnualResults data frame from the Daily data frame — setupYears","text":"function aggregates results stored daily basis Daily data frame   stores average values new data frame called AnnualResults.      Note flux values rates (kg/day) mass (kg).      \"annual values\" can full 12 months, can shorter.       See manual understand paLong paStart arguments.       simplest case, Water Year (October September),      paLong=12, paStart=10.       calendar year paLong=12 paStart=1.       winter season Dec, Jan, Feb paLong=3 paStart=12","code":""},{"path":"/reference/setupYears.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates the AnnualResults data frame from the Daily data frame — setupYears","text":"","code":"setupYears(localDaily, paLong = 12, paStart = 10)"},{"path":"/reference/setupYears.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates the AnnualResults data frame from the Daily data frame — setupYears","text":"localDaily data frame containing daily values, default Daily paLong numeric integer specifying length period analysis, months, 1<=paLong<=12, default 12 paStart numeric integer specifying starting month period analysis, 1<=paStart<=12, default 10","code":""},{"path":"/reference/setupYears.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates the AnnualResults data frame from the Daily data frame — setupYears","text":"data frame 'AnnualResults' numeric values following columns","code":""},{"path":"/reference/setupYears.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates the AnnualResults data frame from the Daily data frame — setupYears","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) AnnualResults <- setupYears(Daily, 4, 10)"},{"path":"/reference/startEnd.html","id":null,"dir":"Reference","previous_headings":"","what":"startEnd — startEnd","title":"startEnd — startEnd","text":"Returns two date variables representing starting date ending date combination paStart, paLong, year","code":""},{"path":"/reference/startEnd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"startEnd — startEnd","text":"","code":"startEnd(paStart, paLong, year)"},{"path":"/reference/startEnd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"startEnd — startEnd","text":"paStart numeric integer specifying starting month period analysis, 1<=paStart<=12, default 10 paLong numeric integer specifying length period analysis, months, 1<=paLong<=12, default 12 year integer year, calendar year period ends","code":""},{"path":"/reference/startEnd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"startEnd — startEnd","text":"Date list","code":""},{"path":"/reference/startEnd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"startEnd — startEnd","text":"","code":"paStart <- 10 paLong <- 12 year <- 1999 startEnd(paStart, paLong, year) #> $startDate #> [1] \"1998-10-01\" #>  #> $endDate #> [1] \"1999-09-30\" #>"},{"path":"/reference/stitch.html","id":null,"dir":"Reference","previous_headings":"","what":"stitch surfaces — stitch","title":"stitch surfaces — stitch","text":"function creates continuous surfaces object starts just  surfaceStart ends just surfaceEnd. made two surfaces  objects created wall specified analysis.  first  surfaces object based data prior wall second surfaces object  based data wall.  wall located just sample1EndDate. Daily data frame used set minimum maximum discharges used  construct indices discharges surfaces.","code":""},{"path":"/reference/stitch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"stitch surfaces — stitch","text":"","code":"stitch(eList, sample1StartDate, sample1EndDate, sample2StartDate,   sample2EndDate, surfaceStart = NA, surfaceEnd = NA, minNumObs = 100,   minNumUncen = 50, fractMin = 0.75, windowY = 7, windowQ = 2,   windowS = 0.5, edgeAdjust = TRUE, verbose = FALSE,   run.parallel = FALSE)"},{"path":"/reference/stitch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"stitch surfaces — stitch","text":"eList named list least Daily, Sample, INFO dataframes sample1StartDate Date (character YYYY-MM-DD) first sample used estimating first segment surfaces object. sample1EndDate Date (character YYYY-MM-DD) last sample used first segment surfaces object. sample2StartDate Date (character YYYY-MM-DD) first sample used second segment surfaces object. sample2EndDate Date (character YYYY-MM-DD) last sample used second segment surfaces object. surfaceStart Date (character YYYY-MM-DD) start WRTDS model estimated first  daily outputs generated. Default NA, means surfaceStart based date first sample. surfaceEnd Date (character YYYY-MM-DD) end WRTDS model estimated last daily outputs  generated.  Default NA, means surfaceEnd based date last sample. minNumObs numeric specifying miniumum number observations required run weighted regression, default 100 minNumUncen numeric specifying minimum number uncensored observations run weighted regression, default 50 fractMin numeric specifying minimum fraction observations required run weighted regression, default 0.75. minimum number maximum minNumObs fractMin multiplied total number observations. windowY numeric specifying half-window width time dimension, units years, default 7 windowQ numeric specifying half-window width discharge dimension, units natural log units, default 2 windowS numeric specifying half-window seasonal dimension, units years, default 0.5 edgeAdjust logical specifying whether use modified method calculating windows edge record. edgeAdjust method tends reduce curvature near start end record.  Default TRUE. verbose logical specifying whether display progress message run.parallel logical run bootstrapping parallel ","code":""},{"path":"/reference/stitch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"stitch surfaces — stitch","text":"","code":"eList <- Choptank_eList  surfaceStart <- \"1986-10-01\" surfaceEnd <- \"2010-09-30\"  # Surface skips a few years: sample1StartDate <- \"1986-10-01\" sample1EndDate <- \"1992-09-30\" sample2StartDate <- \"1996-10-01\" sample2EndDate <- \"2011-09-30\"  # \\donttest{ surface_skip <- stitch(eList,                           sample1StartDate, sample1EndDate,                           sample2StartDate, sample2EndDate,                          surfaceStart, surfaceEnd) #>  #>  Sample1 mean concentration 1.095 #>  #>  Sample2 mean concentration 1.217 #> Sample1 has 183 Samples and 183 are uncensored #> Sample2 has 259 Samples and 258 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50  # Surface overlaps a few years: sample1StartDate <- \"1986-10-01\" sample1EndDate <- \"1996-09-30\" sample2StartDate <- \"1992-10-01\" sample2EndDate <- \"2011-09-30\"  surface_overlap <- stitch(eList,                           sample1StartDate, sample1EndDate,                           sample2StartDate, sample2EndDate) #>  #>  Sample1 mean concentration 1.103 #>  #>  Sample2 mean concentration 1.193 #> Sample1 has 267 Samples and 267 are uncensored #> Sample2 has 343 Samples and 342 are uncensored #> minNumObs has been set to 100 minNumUncen has been set to 50 # }"},{"path":"/reference/surfaceIndex.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","title":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","text":"code repetition first part code estSurfaces","code":""},{"path":"/reference/surfaceIndex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","text":"","code":"surfaceIndex(Daily)"},{"path":"/reference/surfaceIndex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","text":"Daily data frame containing daily values, default Daily","code":""},{"path":"/reference/surfaceIndex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","text":"surfaceIndexParameters numeric vector length 6, defining grid surfaces","code":""},{"path":"/reference/surfaceIndex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the 6 parameters needed to lay out the grid for the surfaces computed in estSurfaces — surfaceIndex","text":"","code":"eList <- Choptank_eList Daily <- getDaily(eList) surfaceIndex(Daily) #> $bottomLogQ #> [1] -4.66412 #>  #> $stepLogQ #> [1] 0.7862231 #>  #> $nVectorLogQ #> [1] 14 #>  #> $bottomYear #> [1] 1979 #>  #> $stepYear #> [1] 0.0625 #>  #> $nVectorYear #> [1] 529 #>  #> $vectorYear #>   [1] 1979.000 1979.062 1979.125 1979.188 1979.250 1979.312 1979.375 1979.438 #>   [9] 1979.500 1979.562 1979.625 1979.688 1979.750 1979.812 1979.875 1979.938 #>  [17] 1980.000 1980.062 1980.125 1980.188 1980.250 1980.312 1980.375 1980.438 #>  [25] 1980.500 1980.562 1980.625 1980.688 1980.750 1980.812 1980.875 1980.938 #>  [33] 1981.000 1981.062 1981.125 1981.188 1981.250 1981.312 1981.375 1981.438 #>  [41] 1981.500 1981.562 1981.625 1981.688 1981.750 1981.812 1981.875 1981.938 #>  [49] 1982.000 1982.062 1982.125 1982.188 1982.250 1982.312 1982.375 1982.438 #>  [57] 1982.500 1982.562 1982.625 1982.688 1982.750 1982.812 1982.875 1982.938 #>  [65] 1983.000 1983.062 1983.125 1983.188 1983.250 1983.312 1983.375 1983.438 #>  [73] 1983.500 1983.562 1983.625 1983.688 1983.750 1983.812 1983.875 1983.938 #>  [81] 1984.000 1984.062 1984.125 1984.188 1984.250 1984.312 1984.375 1984.438 #>  [89] 1984.500 1984.562 1984.625 1984.688 1984.750 1984.812 1984.875 1984.938 #>  [97] 1985.000 1985.062 1985.125 1985.188 1985.250 1985.312 1985.375 1985.438 #> [105] 1985.500 1985.562 1985.625 1985.688 1985.750 1985.812 1985.875 1985.938 #> [113] 1986.000 1986.062 1986.125 1986.188 1986.250 1986.312 1986.375 1986.438 #> [121] 1986.500 1986.562 1986.625 1986.688 1986.750 1986.812 1986.875 1986.938 #> [129] 1987.000 1987.062 1987.125 1987.188 1987.250 1987.312 1987.375 1987.438 #> [137] 1987.500 1987.562 1987.625 1987.688 1987.750 1987.812 1987.875 1987.938 #> [145] 1988.000 1988.062 1988.125 1988.188 1988.250 1988.312 1988.375 1988.438 #> [153] 1988.500 1988.562 1988.625 1988.688 1988.750 1988.812 1988.875 1988.938 #> [161] 1989.000 1989.062 1989.125 1989.188 1989.250 1989.312 1989.375 1989.438 #> [169] 1989.500 1989.562 1989.625 1989.688 1989.750 1989.812 1989.875 1989.938 #> [177] 1990.000 1990.062 1990.125 1990.188 1990.250 1990.312 1990.375 1990.438 #> [185] 1990.500 1990.562 1990.625 1990.688 1990.750 1990.812 1990.875 1990.938 #> [193] 1991.000 1991.062 1991.125 1991.188 1991.250 1991.312 1991.375 1991.438 #> [201] 1991.500 1991.562 1991.625 1991.688 1991.750 1991.812 1991.875 1991.938 #> [209] 1992.000 1992.062 1992.125 1992.188 1992.250 1992.312 1992.375 1992.438 #> [217] 1992.500 1992.562 1992.625 1992.688 1992.750 1992.812 1992.875 1992.938 #> [225] 1993.000 1993.062 1993.125 1993.188 1993.250 1993.312 1993.375 1993.438 #> [233] 1993.500 1993.562 1993.625 1993.688 1993.750 1993.812 1993.875 1993.938 #> [241] 1994.000 1994.062 1994.125 1994.188 1994.250 1994.312 1994.375 1994.438 #> [249] 1994.500 1994.562 1994.625 1994.688 1994.750 1994.812 1994.875 1994.938 #> [257] 1995.000 1995.062 1995.125 1995.188 1995.250 1995.312 1995.375 1995.438 #> [265] 1995.500 1995.562 1995.625 1995.688 1995.750 1995.812 1995.875 1995.938 #> [273] 1996.000 1996.062 1996.125 1996.188 1996.250 1996.312 1996.375 1996.438 #> [281] 1996.500 1996.562 1996.625 1996.688 1996.750 1996.812 1996.875 1996.938 #> [289] 1997.000 1997.062 1997.125 1997.188 1997.250 1997.312 1997.375 1997.438 #> [297] 1997.500 1997.562 1997.625 1997.688 1997.750 1997.812 1997.875 1997.938 #> [305] 1998.000 1998.062 1998.125 1998.188 1998.250 1998.312 1998.375 1998.438 #> [313] 1998.500 1998.562 1998.625 1998.688 1998.750 1998.812 1998.875 1998.938 #> [321] 1999.000 1999.062 1999.125 1999.188 1999.250 1999.312 1999.375 1999.438 #> [329] 1999.500 1999.562 1999.625 1999.688 1999.750 1999.812 1999.875 1999.938 #> [337] 2000.000 2000.062 2000.125 2000.188 2000.250 2000.312 2000.375 2000.438 #> [345] 2000.500 2000.562 2000.625 2000.688 2000.750 2000.812 2000.875 2000.938 #> [353] 2001.000 2001.062 2001.125 2001.188 2001.250 2001.312 2001.375 2001.438 #> [361] 2001.500 2001.562 2001.625 2001.688 2001.750 2001.812 2001.875 2001.938 #> [369] 2002.000 2002.062 2002.125 2002.188 2002.250 2002.312 2002.375 2002.438 #> [377] 2002.500 2002.562 2002.625 2002.688 2002.750 2002.812 2002.875 2002.938 #> [385] 2003.000 2003.062 2003.125 2003.188 2003.250 2003.312 2003.375 2003.438 #> [393] 2003.500 2003.562 2003.625 2003.688 2003.750 2003.812 2003.875 2003.938 #> [401] 2004.000 2004.062 2004.125 2004.188 2004.250 2004.312 2004.375 2004.438 #> [409] 2004.500 2004.562 2004.625 2004.688 2004.750 2004.812 2004.875 2004.938 #> [417] 2005.000 2005.062 2005.125 2005.188 2005.250 2005.312 2005.375 2005.438 #> [425] 2005.500 2005.562 2005.625 2005.688 2005.750 2005.812 2005.875 2005.938 #> [433] 2006.000 2006.062 2006.125 2006.188 2006.250 2006.312 2006.375 2006.438 #> [441] 2006.500 2006.562 2006.625 2006.688 2006.750 2006.812 2006.875 2006.938 #> [449] 2007.000 2007.062 2007.125 2007.188 2007.250 2007.312 2007.375 2007.438 #> [457] 2007.500 2007.562 2007.625 2007.688 2007.750 2007.812 2007.875 2007.938 #> [465] 2008.000 2008.062 2008.125 2008.188 2008.250 2008.312 2008.375 2008.438 #> [473] 2008.500 2008.562 2008.625 2008.688 2008.750 2008.812 2008.875 2008.938 #> [481] 2009.000 2009.062 2009.125 2009.188 2009.250 2009.312 2009.375 2009.438 #> [489] 2009.500 2009.562 2009.625 2009.688 2009.750 2009.812 2009.875 2009.938 #> [497] 2010.000 2010.062 2010.125 2010.188 2010.250 2010.312 2010.375 2010.438 #> [505] 2010.500 2010.562 2010.625 2010.688 2010.750 2010.812 2010.875 2010.938 #> [513] 2011.000 2011.062 2011.125 2011.188 2011.250 2011.312 2011.375 2011.438 #> [521] 2011.500 2011.562 2011.625 2011.688 2011.750 2011.812 2011.875 2011.938 #> [529] 2012.000 #>  #> $vectorLogQ #>  [1] -4.66412050 -3.87789739 -3.09167428 -2.30545117 -1.51922806 -0.73300495 #>  [7]  0.05321816  0.83944127  1.62566438  2.41188749  3.19811060  3.98433371 #> [13]  4.77055682  5.55677993 #>"},{"path":"/reference/surfaceStartEnd.html","id":null,"dir":"Reference","previous_headings":"","what":"Surface date limits — surfaceStartEnd","title":"Surface date limits — surfaceStartEnd","text":"Sets Date limits surfaces estimated Sample data set.  start less  year prior first date (typically date first sample) end  less year last date (typically date last sample).  start  constrained first day period analysis end constrained  last day period analysis","code":""},{"path":"/reference/surfaceStartEnd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surface date limits — surfaceStartEnd","text":"","code":"surfaceStartEnd(paStart, paLong, Date1, Date2)"},{"path":"/reference/surfaceStartEnd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surface date limits — surfaceStartEnd","text":"paStart numeric integer specifying starting month period analysis, 1<=paStart<=12, default 10 paLong numeric integer specifying length period analysis, months, 1<=paLong<=12, default 12 Date1 Date set Date earliest data Sample. Date2 Date set Date latest data Sample.","code":""},{"path":"/reference/surfaceStartEnd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surface date limits — surfaceStartEnd","text":"","code":"eList <- Choptank_eList Date1 <- eList$Sample$Date[1] Date2 <- range(eList$Sample$Date)[2] surfaceStartEnd(10, 12, Date1, Date2) #> $surfaceStart #> [1] \"1979-10-01\" #>  #> $surfaceEnd #> [1] \"2011-09-30\" #>"},{"path":"/reference/tableChange.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","title":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","text":"tables describe trends flow-normalized concentration flow-normalized flux.  described changes real units percent slopes real units per year percent per year. computed pairs time points.  time points can user-defined can set program final year record set years multiples 5 years prior . tableChangeSingle version code produce output flow-normalized concentration flow-normalized flux, ","code":""},{"path":"/reference/tableChange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","text":"","code":"tableChange(eList, fluxUnit = 9, yearPoints = NA)  tableChangeSingle(eList, fluxUnit = 9, yearPoints = NA, flux = FALSE)"},{"path":"/reference/tableChange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","text":"eList named list least Daily INFO dataframes fluxUnit object fluxUnit class. printFluxUnitCheatSheet, numeric represented short code, character representing descriptive name. yearPoints numeric vector listing years change slope computations made, need chronological order.  example yearPoints=c(1975,1985,1995,2005), default NA (allows program set yearPoints automatically) flux logical TRUE results returned flux, FALSE concentration. Default set FALSE.","code":""},{"path":"/reference/tableChange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","text":"dataframe Year1, Year2, change[mg/L], slope[mg/L], change[percent], slope[percent] columns. data row change slope calculated Year1 Year2","code":""},{"path":"/reference/tableChange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a table of the changes in flow-normalized values between various points in time in the record — tableChange","text":"","code":"eList <- Choptank_eList # Water Year: # \\donttest{ tableChange(eList, fluxUnit = 8, yearPoints = c(1980, 1995, 2011)) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1980  to  1995       0.2     0.013        20       1.3 #>  1980  to  2011      0.45     0.015        45       1.5 #>  1995  to  2011      0.26     0.016        21       1.3 #>  #>  #>                  Flux Trends #>    time span          change        slope       change        slope #>                   10^3 kg/yr    10^3 kg/yr /yr      %         %/yr #>  1980  to  1995           27          1.8           26          1.7 #>  1980  to  2011           42          1.4           39          1.3 #>  1995  to  2011           15         0.92           11         0.69 tableChange(eList, fluxUnit = 5)  #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1981  to  1986     0.039    0.0079       3.9      0.79 #>  1981  to  1991      0.14     0.014        14       1.4 #>  1981  to  1996      0.21     0.014        21       1.4 #>  1981  to  2001      0.27     0.013        27       1.3 #>  1981  to  2006      0.36     0.015        36       1.5 #>  1981  to  2011      0.46     0.015        46       1.5 #>  1986  to  1991       0.1     0.021        10         2 #>  1986  to  1996      0.18     0.018        17       1.7 #>  1986  to  2001      0.23     0.015        22       1.5 #>  1986  to  2006      0.32     0.016        31       1.6 #>  1986  to  2011      0.42     0.017        40       1.6 #>  1991  to  1996      0.07     0.014       6.2       1.2 #>  1991  to  2001      0.13     0.013        11       1.1 #>  1991  to  2006      0.22     0.015        19       1.3 #>  1991  to  2011      0.31     0.016        27       1.4 #>  1996  to  2001     0.055     0.011       4.5      0.91 #>  1996  to  2006      0.15     0.015        12       1.2 #>  1996  to  2011      0.24     0.016        20       1.3 #>  2001  to  2006     0.094     0.019       7.4       1.5 #>  2001  to  2011      0.19     0.019        15       1.5 #>  2006  to  2011     0.095     0.019         7       1.4 #>  #>  #>                  Flux Trends #>    time span          change        slope       change        slope #>                   tons/yr      tons/yr   /yr      %         %/yr #>  1981  to  1986           12          2.4           10            2 #>  1981  to  1991           24          2.4           20            2 #>  1981  to  1996           29          1.9           24          1.6 #>  1981  to  2001           35          1.8           29          1.5 #>  1981  to  2006           43          1.7           36          1.4 #>  1981  to  2011           44          1.5           37          1.2 #>  1986  to  1991           12          2.5          9.4          1.9 #>  1986  to  1996           17          1.7           13          1.3 #>  1986  to  2001           23          1.5           18          1.2 #>  1986  to  2006           31          1.5           23          1.2 #>  1986  to  2011           32          1.3           24         0.97 #>  1991  to  1996          4.7         0.94          3.3         0.65 #>  1991  to  2001           11          1.1          7.5         0.75 #>  1991  to  2006           19          1.2           13         0.86 #>  1991  to  2011           20         0.98           14         0.68 #>  1996  to  2001          6.1          1.2          4.1         0.82 #>  1996  to  2006           14          1.4          9.4         0.94 #>  1996  to  2011           15            1           10         0.67 #>  2001  to  2006          7.9          1.6          5.1            1 #>  2001  to  2011          8.9         0.89          5.8         0.58 #>  2006  to  2011          1.1         0.21         0.65         0.13 # Winter: eList <- setPA(eList, paStart = 12, paLong = 3) tableChange(eList, fluxUnit = 8, yearPoints = c(1980, 1995, 2011)) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Season Consisting of Dec Jan Feb  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1980  to  1995       0.2     0.013        18       1.2 #>  1980  to  2011      0.46     0.015        42       1.3 #>  1995  to  2011      0.26     0.016        20       1.3 #>  #>  #>                  Flux Trends #>    time span          change        slope       change        slope #>                   10^3 kg/yr    10^3 kg/yr /yr      %         %/yr #>  1980  to  1995           37          2.5           24          1.6 #>  1980  to  2011           59          1.9           38          1.2 #>  1995  to  2011           22          1.4           12         0.72  # Water Year: eList <- setPA(eList, paStart = 10, paLong = 12) #This returns concentration ASCII table in the console: tableChangeSingle(eList, fluxUnit = 8, yearPoints = c(1980, 1995, 2011), flux = FALSE) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1980  to  1995       0.2     0.013        20       1.3 #>  1980  to  2011      0.45     0.015        45       1.5 #>  1995  to  2011      0.26     0.016        21       1.3 #Returns a data frame: change <- tableChangeSingle(eList, fluxUnit = 8, yearPoints=c(1980, 1995, 2011), flux = FALSE)  #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1980  to  1995       0.2     0.013        20       1.3 #>  1980  to  2011      0.45     0.015        45       1.5 #>  1995  to  2011      0.26     0.016        21       1.3 #This returns flux values as a data frame: df <- tableChangeSingle(eList, fluxUnit = 8, yearPoints=c(1980, 1995, 2011), flux = TRUE)   #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>  #>  #>                  Flux Trends #>    time span          change        slope       change        slope #>                  10^3 kg/yr   10^3 kg/yr/yr      %         %/yr #>  #>  1980  to  1995           27          1.8           26          1.7 #>  1980  to  2011           42          1.4           39          1.3 #>  1995  to  2011           15         0.92           11         0.69 # Winter Concentration only: eList <- setPA(eList, paStart = 12, paLong = 3) df.winter <- tableChangeSingle(eList, fluxUnit = 8, yearPoints=c(1980, 1995, 2011), flux = FALSE) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Season Consisting of Dec Jan Feb  #>  #>            Concentration trends #>    time span       change     slope    change     slope #>                      mg/L   mg/L/yr        %       %/yr #>  #>  1980  to  1995       0.2     0.013        18       1.2 #>  1980  to  2011      0.46     0.015        42       1.3 #>  1995  to  2011      0.26     0.016        20       1.3  # }"},{"path":"/reference/tableFlowChange.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","title":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","text":"Part flowHistory system. Provides measure change (real units percent per year) based smoothed values various streamflow statistics. Smoothing algorithm used plotFlowSingle.","code":""},{"path":"/reference/tableFlowChange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","text":"","code":"tableFlowChange(eList, istat, qUnit = 1, runoff = FALSE, yearPoints = NA)"},{"path":"/reference/tableFlowChange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","text":"eList named list least Daily INFO dataframes istat numeric value flow statistic graphed (possible values 1 8) qUnit object qUnit class printqUnitCheatSheet, numeric represented short code, character representing descriptive name. runoff logical variable, TRUE streamflow data converted runoff values mm/day yearPoints vector numeric values, specifying years change metrics calculated, default NA (allows function set automatically), yearPoints must ascending order","code":""},{"path":"/reference/tableFlowChange.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","text":"index flow statistics istat.  statistics :  (1) 1-day minimum, (2) 7-day minimum, (3) 30-day minimum, (4) median (5) mean, (6) 30-day maximum, (7) 7-day maximum, (8) 1-day maximum. Can also run statistics Period Analysis (individual months sequence months) using setPA. dataframe returned, well printout R console.","code":""},{"path":"/reference/tableFlowChange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prints table of change metrics for a given streamflow statistic — tableFlowChange","text":"","code":"eList <- Choptank_eList tableFlowChange(eList, istat = 5, yearPoints = c(1981, 1995, 2010)) #>  #>    Choptank River #>    Water Year #>     mean daily  #>  #>              Streamflow Trends #>    time span          change        slope       change        slope #>                         cfs         cfs/yr        %            %/yr #>  1981  to  1995           21          1.5           19          1.4 #>  1981  to  2010           49          1.7           45          1.6 #>  1995  to  2010           28          1.9           22          1.4 eList <- setPA(eList, paStart = 4, paLong = 12) tableFlowChange(eList, istat = 2, qUnit = 2, yearPoints = c(1981, 1995, 2010)) #>  #>    Choptank River #>    Year Starting With April #>     7-day minimum  #>  #>              Streamflow Trends #>    time span          change        slope       change        slope #>                         cms         cms/yr        %            %/yr #>  1981  to  1995       ---       ---       ---       --- #>  1981  to  2010       ---       ---       ---       --- #>  1995  to  2010       -0.036      -0.0024          -11        -0.72 #> Warning: NAs introduced by coercion #> Warning: NAs introduced by coercion #> Warning: NAs introduced by coercion #> Warning: NAs introduced by coercion eList <- setPA(eList, paStart = 9, paLong = 1) df <- tableFlowChange(eList, istat = 5, qUnit = 2, yearPoints = c(1981, 1995, 2010)) #>  #>    Choptank River #>    Season Consisting of Sep #>     mean daily  #>  #>              Streamflow Trends #>    time span          change        slope       change        slope #>                         cms         cms/yr        %            %/yr #>  1981  to  1995         0.33        0.024           46          3.3 #>  1981  to  2010          0.8        0.028          110          3.8 #>  1995  to  2010         0.47        0.031           45            3 df  #>   year1 year2 change[cms] slope[cms/yr] change[%] slope[%/yr] #> 1  1981  1995        0.33         0.024        46         3.3 #> 2  1981  2010        0.80         0.028       110         3.8 #> 3  1995  2010        0.47         0.031        45         3.0"},{"path":"/reference/tableResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Table of annual results for discharge, concentration and flux — tableResults","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"Produce ASCII table showing: year, mean discharge, mean concentration, flow-normalized concentration,  mean flux, flow-normalized flux. Note flux flow-normalized flux rates mass.  value period shorter full year  larger value full year.","code":""},{"path":"/reference/tableResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"","code":"tableResults(eList, qUnit = 2, fluxUnit = 9, localDaily = NA)"},{"path":"/reference/tableResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"eList named list least Daily INFO dataframes qUnit object qUnit class. printqUnitCheatSheet, numeric represented short code, character representing descriptive name. fluxUnit object fluxUnit class. printFluxUnitCheatSheet, numeric represented short code, character representing descriptive name. localDaily data frame override eList$Daily","code":""},{"path":"/reference/tableResults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"results dataframe, returnDataFrame=TRUE dataframe year, discharge, concentration, flow-normalized concentration, flux, flow-normalized concentration columns.  eList run WRTDSKalman, additional column generalized flux included.","code":""},{"path":"/reference/tableResults.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"Can also procude table Period Analysis (individual months sequence months) using setPA.","code":""},{"path":"/reference/tableResults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Table of annual results for discharge, concentration and flux — tableResults","text":"","code":"eList <- Choptank_eList # Water Year: # \\donttest{ tableResults(eList, fluxUnit = 8) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux #>              cms            mg/L             10^3 kg/yr  #>  #>    1980      4.25     0.949     1.003     115.4       106 #>    1981      2.22     1.035     0.999      67.5       108 #>    1982      3.05     1.036     0.993      98.5       110 #>    1983      4.99     1.007     0.993     132.9       112 #>    1984      5.72     0.990     1.002     159.7       114 #>    1985      1.52     1.057     1.017      48.9       116 #>    1986      2.63     1.062     1.038      90.3       119 #>    1987      3.37     1.079     1.062     114.2       122 #>    1988      1.87     1.120     1.085      66.0       125 #>    1989      5.61     1.055     1.105     163.8       127 #>    1990      4.01     1.115     1.125     134.9       129 #>    1991      2.75     1.172     1.143      98.0       130 #>    1992      2.19     1.203     1.159      81.0       132 #>    1993      3.73     1.215     1.173     130.6       132 #>    1994      5.48     1.144     1.187     163.4       133 #>    1995      2.41     1.266     1.201      92.8       134 #>    1996      6.24     1.134     1.213     198.0       135 #>    1997      5.83     1.180     1.221     188.4       136 #>    1998      4.88     1.236     1.229     159.3       137 #>    1999      2.90     1.277     1.238      91.9       138 #>    2000      4.72     1.213     1.253     162.7       139 #>    2001      4.88     1.251     1.268     165.5       140 #>    2002      1.24     1.321     1.285      48.3       141 #>    2003      8.64     1.140     1.303     266.4       143 #>    2004      5.28     1.274     1.321     183.2       144 #>    2005      3.81     1.360     1.341     144.4       146 #>    2006      3.59     1.382     1.362     140.9       147 #>    2007      4.28     1.408     1.382     159.3       149 #>    2008      2.56     1.477     1.401     100.8       149 #>    2009      3.68     1.409     1.419     132.8       149 #>    2010      7.19     1.323     1.438     223.6       149 #>    2011      5.24     1.438     1.457     155.4       148 df <- tableResults(eList, fluxUnit = 1) #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Water Year  #>  #>    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux #>              cms            mg/L             lbs/day    #>  #>    1980      4.25     0.949     1.003       697       642 #>    1981      2.22     1.035     0.999       407       654 #>    1982      3.05     1.036     0.993       594       663 #>    1983      4.99     1.007     0.993       802       674 #>    1984      5.72     0.990     1.002       964       688 #>    1985      1.52     1.057     1.017       295       702 #>    1986      2.63     1.062     1.038       545       720 #>    1987      3.37     1.079     1.062       690       739 #>    1988      1.87     1.120     1.085       399       756 #>    1989      5.61     1.055     1.105       989       768 #>    1990      4.01     1.115     1.125       814       779 #>    1991      2.75     1.172     1.143       592       787 #>    1992      2.19     1.203     1.159       489       794 #>    1993      3.73     1.215     1.173       788       797 #>    1994      5.48     1.144     1.187       986       801 #>    1995      2.41     1.266     1.201       560       806 #>    1996      6.24     1.134     1.213      1195       813 #>    1997      5.83     1.180     1.221      1137       818 #>    1998      4.88     1.236     1.229       962       824 #>    1999      2.90     1.277     1.238       555       831 #>    2000      4.72     1.213     1.253       982       840 #>    2001      4.88     1.251     1.268       999       846 #>    2002      1.24     1.321     1.285       291       853 #>    2003      8.64     1.140     1.303      1608       861 #>    2004      5.28     1.274     1.321      1106       870 #>    2005      3.81     1.360     1.341       871       879 #>    2006      3.59     1.382     1.362       850       889 #>    2007      4.28     1.408     1.382       961       897 #>    2008      2.56     1.477     1.401       608       902 #>    2009      3.68     1.409     1.419       801       900 #>    2010      7.19     1.323     1.438      1350       898 #>    2011      5.24     1.438     1.457       938       895 df #>    Year Discharge [cms] Conc [mg/L] FN Conc [mg/L] Flux [lbs/day] #> 1  1980            4.25       0.949          1.003            697 #> 2  1981            2.22       1.035          0.999            407 #> 3  1982            3.05       1.036          0.993            594 #> 4  1983            4.99       1.007          0.993            802 #> 5  1984            5.72       0.990          1.002            964 #> 6  1985            1.52       1.057          1.017            295 #> 7  1986            2.63       1.062          1.038            545 #> 8  1987            3.37       1.079          1.062            690 #> 9  1988            1.87       1.120          1.085            399 #> 10 1989            5.61       1.055          1.105            989 #> 11 1990            4.01       1.115          1.125            814 #> 12 1991            2.75       1.172          1.143            592 #> 13 1992            2.19       1.203          1.159            489 #> 14 1993            3.73       1.215          1.173            788 #> 15 1994            5.48       1.144          1.187            986 #> 16 1995            2.41       1.266          1.201            560 #> 17 1996            6.24       1.134          1.213           1195 #> 18 1997            5.83       1.180          1.221           1137 #> 19 1998            4.88       1.236          1.229            962 #> 20 1999            2.90       1.277          1.238            555 #> 21 2000            4.72       1.213          1.253            982 #> 22 2001            4.88       1.251          1.268            999 #> 23 2002            1.24       1.321          1.285            291 #> 24 2003            8.64       1.140          1.303           1608 #> 25 2004            5.28       1.274          1.321           1106 #> 26 2005            3.81       1.360          1.341            871 #> 27 2006            3.59       1.382          1.362            850 #> 28 2007            4.28       1.408          1.382            961 #> 29 2008            2.56       1.477          1.401            608 #> 30 2009            3.68       1.409          1.419            801 #> 31 2010            7.19       1.323          1.438           1350 #> 32 2011            5.24       1.438          1.457            938 #>    FN Flux [lbs/day] #> 1                642 #> 2                654 #> 3                663 #> 4                674 #> 5                688 #> 6                702 #> 7                720 #> 8                739 #> 9                756 #> 10               768 #> 11               779 #> 12               787 #> 13               794 #> 14               797 #> 15               801 #> 16               806 #> 17               813 #> 18               818 #> 19               824 #> 20               831 #> 21               840 #> 22               846 #> 23               853 #> 24               861 #> 25               870 #> 26               879 #> 27               889 #> 28               897 #> 29               902 #> 30               900 #> 31               898 #> 32               895 # Spring: eList <- setPA(eList, paStart = 3, paLong = 3) tableResults(eList, fluxUnit = 1, qUnit = \"cfs\") #>  #>    Choptank River  #>    Inorganic nitrogen (nitrate and nitrite) #>    Season Consisting of Mar Apr May  #>  #>    Year   Discharge    Conc    FN_Conc     Flux    FN_Flux #>              cfs            mg/L             lbs/day    #>  #>    1980     236.6     0.921     0.922      1104      1006 #>    1981     132.1     0.957     0.936       660      1028 #>    1982     165.2     0.972     0.941       873      1038 #>    1983     430.5     0.879     0.947      1804      1051 #>    1984     365.4     0.917     0.958      1604      1068 #>    1985      64.8     1.007     0.973       357      1086 #>    1986     115.7     1.030     0.993       662      1111 #>    1987     167.8     1.036     1.016       927      1138 #>    1988     129.1     1.065     1.038       724      1163 #>    1989     384.7     0.992     1.057      1886      1183 #>    1990     216.6     1.074     1.073      1142      1197 #>    1991     154.1     1.119     1.086       926      1204 #>    1992     141.2     1.134     1.096       856      1208 #>    1993     310.8     1.052     1.105      1634      1210 #>    1994     427.2     1.032     1.113      1962      1214 #>    1995     138.2     1.168     1.121       834      1221 #>    1996     303.3     1.078     1.130      1641      1230 #>    1997     241.2     1.124     1.137      1364      1239 #>    1998     272.6     1.113     1.145      1476      1247 #>    1999     151.9     1.203     1.154       955      1253 #>    2000     275.0     1.139     1.164      1465      1259 #>    2001     240.4     1.166     1.172      1356      1264 #>    2002      94.4     1.239     1.181       610      1269 #>    2003     356.6     1.082     1.192      1903      1276 #>    2004     207.7     1.229     1.205      1186      1286 #>    2005     283.1     1.181     1.219      1561      1298 #>    2006      80.4     1.362     1.234       586      1308 #>    2007     265.5     1.252     1.246      1415      1315 #>    2008     213.7     1.268     1.255      1267      1314 #>    2009     159.5     1.302     1.259      1027      1306 #>    2010     289.7     1.202     1.255      1534      1291 #>    2011     193.9     1.243     1.241      1218      1267 # }"},{"path":"/reference/triCube.html","id":null,"dir":"Reference","previous_headings":"","what":"Tricube weight function — triCube","title":"Tricube weight function — triCube","text":"Computes tricube weight function vector distance values (d), based half-window width h, returns vector weights range zero 1.","code":""},{"path":"/reference/triCube.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tricube weight function — triCube","text":"","code":"triCube(d, h)"},{"path":"/reference/triCube.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tricube weight function — triCube","text":"d numeric vector distances point estimation given sample value h numeric value, half-window width, measured units d","code":""},{"path":"/reference/triCube.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tricube weight function — triCube","text":"w numeric vector weights, 0<=w<=1","code":""},{"path":"/reference/triCube.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tricube weight function — triCube","text":"See Cleveland, W. S. (1979). Robust locally weighted regression smoothing scatterplots, JASA,  74, 829-836","code":""},{"path":"/reference/triCube.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tricube weight function — triCube","text":"","code":"h<-10  d<-c(-11,-10,-5,-1,-0.01,0,5,9.9,10,20)  triCube(d,h) #>  [1] 0.000000e+00 0.000000e+00 6.699219e-01 9.970030e-01 1.000000e+00 #>  [6] 1.000000e+00 6.699219e-01 2.620072e-05 0.000000e+00 0.000000e+00"},{"path":"/reference/wrtdsK.html","id":null,"dir":"Reference","previous_headings":"","what":"WRTDS-Kalman — WRTDSKalman","title":"WRTDS-Kalman — WRTDSKalman","text":"function uses autoregressive model produce accurate  estimates concentration flux","code":""},{"path":"/reference/wrtdsK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"WRTDS-Kalman — WRTDSKalman","text":"","code":"WRTDSKalman(eList, rho = 0.9, niter = 200, seed = NA, verbose = TRUE)"},{"path":"/reference/wrtdsK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"WRTDS-Kalman — WRTDSKalman","text":"eList named list INFO, Daily, Sample dataframes surfaces matrix rho numeric lag one autocorrelation. Default 0.9. niter number iterations. Default 200. seed integer value. Defaults NA, change current seed. Setting seed given value can used create repeatable output. verbose logical specifying whether display progress message","code":""},{"path":"/reference/wrtdsK.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"WRTDS-Kalman — WRTDSKalman","text":"function takes existing eList  Including estimated model (surfaces object eList) produces daily WRTDSKalman estimates concentration flux generated estimates called genConc genFlux","code":""},{"path":"/reference/wrtdsK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"WRTDS-Kalman — WRTDSKalman","text":"","code":"eList <- Choptank_eList eList <- WRTDSKalman(eList, niter = 10) #> % complete: #> 10 \t #> 20 \t #> 30 \t #> 40 \t #> 50 \t #> 60 \t #> 70 \t #> 80 \t #> 90 \t #> 100 \t summary(eList$Daily) #>       Date                  Q                 Julian          Month        #>  Min.   :1979-10-01   Min.   :  0.00991   Min.   :47389   Min.   : 1.000   #>  1st Qu.:1987-09-30   1st Qu.:  0.93446   1st Qu.:50311   1st Qu.: 4.000   #>  Median :1995-09-30   Median :  2.40693   Median :53232   Median : 7.000   #>  Mean   :1995-09-30   Mean   :  4.08658   Mean   :53232   Mean   : 6.523   #>  3rd Qu.:2003-09-30   3rd Qu.:  4.61565   3rd Qu.:56154   3rd Qu.:10.000   #>  Max.   :2011-09-30   Max.   :246.35656   Max.   :59076   Max.   :12.000   #>                                                                            #>       Day           DecYear        MonthSeq     Qualifier         #>  Min.   :  1.0   Min.   :1980   Min.   :1558   Length:11688       #>  1st Qu.: 93.0   1st Qu.:1988   1st Qu.:1654   Class :character   #>  Median :184.0   Median :1996   Median :1750   Mode  :character   #>  Mean   :183.8   Mean   :1996   Mean   :1749                      #>  3rd Qu.:275.0   3rd Qu.:2004   3rd Qu.:1845                      #>  Max.   :366.0   Max.   :2012   Max.   :1941                      #>                                                                   #>        i              LogQ                Q7                Q30           #>  Min.   :    1   Min.   :-4.61412   Min.   : 0.01808   Min.   : 0.09606   #>  1st Qu.: 2923   1st Qu.:-0.06779   1st Qu.: 0.98704   1st Qu.: 1.16949   #>  Median : 5844   Median : 0.87835   Median : 2.55661   Median : 2.86850   #>  Mean   : 5844   Mean   : 0.76616   Mean   : 4.08569   Mean   : 4.08160   #>  3rd Qu.: 8766   3rd Qu.: 1.52945   3rd Qu.: 4.93017   3rd Qu.: 5.69169   #>  Max.   :11688   Max.   : 5.50678   Max.   :84.00395   Max.   :25.47478   #>                                     NA's   :6          NA's   :29         #>       yHat                 SE            ConcDay          FluxDay         #>  Min.   :-1.790952   Min.   :0.1347   Min.   :0.1776   Min.   :   1.643   #>  1st Qu.:-0.004236   1st Qu.:0.2191   1st Qu.:1.0357   1st Qu.:  98.013   #>  Median : 0.130934   Median :0.2504   Median :1.1959   Median : 250.088   #>  Mean   : 0.120318   Mean   :0.2689   Mean   :1.1978   Mean   : 366.085   #>  3rd Qu.: 0.258944   3rd Qu.:0.3029   3rd Qu.:1.3551   3rd Qu.: 484.360   #>  Max.   : 0.661543   Max.   :0.6146   Max.   :1.9666   Max.   :5519.450   #>                                                                           #>      FNConc           FNFlux          GenFlux             GenConc        #>  Min.   :0.8352   Min.   : 77.55   Min.   :    1.706   Min.   :0.04929   #>  1st Qu.:1.0540   1st Qu.:169.71   1st Qu.:   98.027   1st Qu.:1.00000   #>  Median :1.2067   Median :318.61   Median :  247.235   Median :1.20403   #>  Mean   :1.2004   Mean   :362.71   Mean   :  376.600   Mean   :1.21798   #>  3rd Qu.:1.3314   3rd Qu.:538.44   3rd Qu.:  499.024   3rd Qu.:1.42762   #>  Max.   :1.6882   Max.   :943.75   Max.   :11927.056   Max.   :2.49179   #>                                                                           #All flux values in AnnualResults are expressed as a rate in kg/day AnnualResults <- setupYears(eList$Daily) head(AnnualResults) #>    DecYear        Q      Conc     Flux    FNConc   FNFlux   GenConc  GenFlux #> 1 1980.249 4.251937 0.9485403 316.0491 1.0027237 291.2176 0.9530652 313.1739 #> 2 1981.249 2.217248 1.0351962 184.6712 0.9988918 296.7260 1.0114198 173.4756 #> 3 1982.249 3.046039 1.0361327 269.6309 0.9931881 300.7424 1.0783729 281.9194 #> 4 1983.249 4.986713 1.0072716 363.8563 0.9931768 305.5898 1.0168358 366.2154 #> 5 1984.249 5.718146 0.9901927 437.3007 1.0017255 312.2260 1.0027022 432.4395 #> 6 1985.249 1.517457 1.0571854 133.9210 1.0165324 318.5007 1.0203548 127.7973 #>   PeriodLong PeriodStart #> 1         12          10 #> 2         12          10 #> 3         12          10 #> 4         12          10 #> 5         12          10 #> 6         12          10"},{"path":"/reference/yPretty.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","title":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","text":"Axis tick marks run zero specified maximum, creates 4 8 ticks marks.","code":""},{"path":"/reference/yPretty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","text":"","code":"yPretty(yMax)"},{"path":"/reference/yPretty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","text":"yMax numeric value maximum value plotted, must >0","code":""},{"path":"/reference/yPretty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","text":"yTicks numeric vector representing values tick marks","code":""},{"path":"/reference/yPretty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up tick marks for an axis for a graph with an arithmetic scale which starts at zero — yPretty","text":"","code":"yTicks <- yPretty(7.8) yTicks <- yPretty(125)"}]
