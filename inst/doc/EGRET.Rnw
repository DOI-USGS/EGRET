%\VignetteIndexEntry{Introduction to the EGRET package}
%\VignetteDepends{}
%\VignetteSuggests{}
%\VignetteImports{}
%\VignettePackage{}

\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{times}
\usepackage{hyperref}
\usepackage[numbers, round]{natbib}
\usepackage[american]{babel}
\usepackage{authblk}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{footnote}
\usepackage{tabularx}
\renewcommand\Affilfont{\itshape\small}
\usepackage{Sweave}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\usepackage{graphicx}

\textwidth=6.2in
\textheight=8.5in
\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}
\SweaveOpts{concordance=TRUE}

%------------------------------------------------------------
\title{Introduction to the EGRET package}
%------------------------------------------------------------
\author[1]{Robert Hirsch}
\author[1]{Laura De Cicco}
\affil[1]{United States Geological Survey}

\SweaveOpts{highlight=TRUE, tidy=TRUE, keep.space=TRUE, keep.blank.space=FALSE, keep.comment=TRUE, concordance=TRUE,keep.source=TRUE}

\maketitle
\tableofcontents

%------------------------------------------------------------
\section{Introduction to Exploration and Graphics for RivEr Trends (EGRET)}
%------------------------------------------------------------ 

For information on getting started in R, downloading and installing the package, see Appendix 1: (\ref{sec:appendix1}).

Exploration and Graphics for RivEr Trends (EGRET): An R-package for the analysis of long-term changes in water quality and streamflow. 

EGRET includes statistics and graphics for streamflow history, water quality trends, and the modeling algorithm Weighted Regressions on Time, Discharge, and Season (WRTDS). The best way to learn about the WRTDS approach and to see examples of its application to multiple large data sets is to read two journal articles.  Both are available, for free, from the journals in which they were published.

The first relates to nitrate and total phosphorus data for 9 rivers draining to Chesapeake Bay.  The URL is \cite{HirschII}: 
\url{http://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.2010.00482.x/full}

The second is an application to nitrate data for 8 monitoring sites on the Mississippi River or its major tributaries \cite{HirschIII}.  The URL is: \url{http://pubs.acs.org/doi/abs/10.1021/es201221s}

The manual available here assumes that the user understands the concepts underlying WRTDS.  Thus, reading at least the first of these papers is necessary to understanding the manual.  The method has been enhanced beyond what was published there.  The enhancement is that it now properly handles censored data by using survival regression rather than ordinary regression.  The details of that are in a manuscript currently in process by Doug Moyer and Bob Hirsch.

<<openLibrary, echo=FALSE>>=
library(xtable)
options(continue=" ")
options(width=60)
options(SweaveHooks=list(fig=function()
  par(mar=c(5.1,4.1,1.1,2.1),oma=c(0,0,0,0))))
@

This vignette will walk through the major functions provided by the EGRET package. The package dataRetrieval is required for importing data in a EGRET-friendly format. The dataRetrieval package, along with download and installation instructions can be found at:
\\
\url{https://github.com/USGS-R/dataRetrieval}
\\
Installing dataRetrieval will provide a vignette similar to this document, with complete working examples of the main dataRetrieval functions.

The vignette is divided into four sections: EGRET Dataframes, Flow History, WRTDS Analysis, and WRTDS Results. This document assumes the reader is familiar with the dataRetrieval package. The examples will follow an analysis of nitrate on the Choptank River at Greensboro, MD. Further details can be found in the user guide that can be found on gitHub: \url{https://github.com/USGS-R/EGRET/raw/Documentation/EGRET%2Bmanual_4.doc}


%------------------------------------------------------------ 
\section{EGRET Dataframes and Units}
\label{sec:dataframes}
%------------------------------------------------------------ 
The EGRET package uses 3 default dataframes throughout the calculations, analysis, and graphing. These dataframes are Daily (\ref{sec:dataframesDaily}), Sample (\ref{sec:dataframesSample}), and INFO (\ref{sec:dataframesINFO}). EGRET uses entirely SI units to store the data, but for purposes of output, it can report results in a wide variety of units, which will be discussed in (\ref{sec:units}). To start our exploration, the packages must be installed (check the appendix for detailed instructions (\ref{sec:appendix1})), then opened:
<<openlibraries, echo=TRUE,eval=TRUE>>=
library(EGRET)
library(dataRetrieval)
@

%------------------------------------------------------------ 
\subsection{Daily}
\label{sec:dataframesDaily}
%------------------------------------------------------------ 
The Daily dataframe initially is populated with the following columns by the dataRetrieval package.

<<label=colNamesDaily, echo=FALSE,results=tex>>=
ColumnName <- c("Date", "Q", "Julian","Month","Day","DecYear","MonthSeq","Qualifier","i","LogQ","Q7","Q30")
Type <- c("Date", "number", "number","integer","integer","number","integer","string","integer","number","number","number")
Description <- c("Date", "Discharge in cms", "Number of days since January 1, 1850", "Month of the year [1-12]", "Day of the year [1-366]", "Decimal year", "Number of months since January 1, 1850", "Qualifing code", "Index", "Natural logarithm of Q", "7 day running average of Q", "30 running average of Q")
Units <- c("date", "cms","days", "months","days","years","months", "character","days","numeric","cms","cms")

DF <- data.frame(ColumnName,Type,Description,Units)

data.table <- xtable(DF, caption="Daily dataframe",label="table:Daily1")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht")
@

After running the WRTDS calculations (as will be described in \ref{sec:wrtds}), the following columns are inserted into the Daily dataframe:

<<label=colNamesDaily2, echo=FALSE,results=tex>>=
ColumnName <- c("yHat", "SE", "ConcDay","FluxDay","FNConc","FNFlux")
Type <- c("number", "number", "number","number","number","number")
Description <- c("The WRTDS estimate of the log of concentration", "The WRTDS estimate of the standard error of yHat","The WRTDS estimate of concentration", "The WRTDS estimate of flux","Flow normalized estimate of concentration", "Flow Normalized estimate of flux")
Units <- c("numeric","numeric","mg/L","kg/day","mg/L","kg/day")

DF <- data.frame(ColumnName,Type,Description,Units)

data.table <- xtable(DF, caption="Daily dataframe, post-WRTDS",label="table:Daily2")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht")
@

\FloatBarrier

%------------------------------------------------------------ 
\subsection{Sample}
\label{sec:dataframesSample}
%------------------------------------------------------------ 
The Sample dataframe initially is populated with the following columns by the dataRetrieval package.

<<label=colNamesQW, echo=FALSE,results=tex>>=
ColumnName <- c("Date", "ConcLow", "ConcHigh", "Uncen", "ConcAve", "Julian","Month","Day","DecYear","MonthSeq","SinDY","CosDY","Q footnote","LogQ footnote")
Type <- c("Date", "number","number","integer","number", "number","integer","integer","number","integer","number","number","number","number")
Description <- c("Date", "Lower limit of concentration", "Upper limit of concentration", "Uncensored data (1=true, 0=false)", "Average concentration","Number of days since January 1, 1850", "Month of the year [1-12]", "Day of the year [1-366]", "Decimal year", "Number of months since January 1, 1850", "Sine of DecYear", "Cosine of DecYear", "Discharge", "Natural logarithm of flow")
Units <- c("date","mg/L","mg/L","integer","mg/L","days","months","days","years","months","numeric","numeric","cms", "numeric")

DF <- data.frame(ColumnName,Type,Description, Units)

data.table <- xtable(DF, caption="Sample dataframe", label="table:Sample1")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht",
      sanitize.text.function=function(str)gsub("footnote","\\footnotemark[1]",str,fixed=TRUE))
@
\footnotetext[1]{Flow columns are populated after calling the mergeReport function.}

After running the WRTDS calculations (as will be described in \ref{sec:wrtds}), the following columns are inserted into the Sample dataframe:

<<label=colNamesSample2, echo=FALSE,results=tex>>=
ColumnName <- c("yHat", "SE", "ConcHat")
Type <- c("number", "number", "number")
Description <- c("jack-knife estimate of the log of concentration", "jack-knife estimate of the standard error of yHat","jack-knife unbiased estimate of concentration")
Units <- c("numeric","numeric","mg/L")

DF <- data.frame(ColumnName,Type,Description,Units)

data.table <- xtable(DF, caption="Sample dataframe, post-WRTDS", label="table:Sample2")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht")
@

\FloatBarrier

%------------------------------------------------------------ 
\subsection{INFO}
\label{sec:dataframesINFO}
%------------------------------------------------------------ 
The INFO dataframe is used to store information about the measurements, such as station name, parameter name, drainage area, etc. There can be many additional, optional columns, but the following are required to initiate the EGRET analysis:


\begin{table}[!ht]
\begin{center}
\caption{INFO dataframe}
\label{table:Info1}
\begin{tabular}{lll}
  \hline
ColumnName & Type & Description \\ 
  \hline
shortName & string & Name of site, suitable for use in graphical headings \\ 
  staAbbrev & string & Abbreviation for station name, used in saveResults \\ 
  paramShortName & string & Name of constituent, suitable for use in graphical headings \\ 
  constitAbbrev & string & Abbreviation for constituent name, used in saveResults \\ 
  drainSqKm & numeric & Drainage area in  km\verb@^@2 \\ 
  paStart \footnotemark[2] & integer (1-12) & Starting month of period of analysis \\ 
  paLong \footnotemark[2] & integer (1-12) & Length of period of analysis in months \\ 
   \hline
\end{tabular}
\end{center}
\end{table}

\footnotetext[2]{paStart and paLong can be inserted using the setPA function}

After running the WRTDS calculations (as will be described in \ref{sec:wrtds}), the following columns are automatically inserted into the INFO dataframe (the values will be discussed further sections):

<<label=colNamesINFO2, echo=FALSE,results=tex>>=
ColumnName <- c("bottomLogQ","stepLogQ","nVectorLogQ","bottomYear","stepYear","nVectorYear","windowY","windowQ","windowS","minNumObs","minNumUncen")
Description <- c("Lowest discharge in prediction surfaces","Step size in discharge in prediction surfaces","Number of steps in discharge, prediction surfaces","Starting year in prediction surfaces","Step size in years in prediction surfaces","Number of steps in years in prediction surfaces","Half-window width in the time dimension","Half-window width in the log discharge dimension","Half-window width in the seasonal dimension","Minimum number of observations for regression", "Minimum number of uncensored observations")
Units <- c("numeric","numeric","numeric","numeric","numeric","numeric","years","numeric","years","integer","integer")

DF <- data.frame(ColumnName,Description,Units)

data.table <- xtable(DF, caption="INFO dataframe, post-WRTDS", label="table:Info2")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht")
@


\FloatBarrier

%------------------------------------------------------------ 
\subsection{Units}
\label{sec:units}
%------------------------------------------------------------ 
EGRET uses entirely SI units to store the data, but for purposes of output, it can report results in a wide variety of units. The default is that concentration is measured in mg/L, discharge is cubic meters per second (cms), flux is kg/day, and drainage area is km\verb@^@2. When discharge values are imported from USGS web services (using the dataRetrieval package), they are automatically converted from cubic feet per second (cfs) to cms unless the argument convet is set to FALSE.  This can cause confusion if not careful. 

Although the data is stored in the dataframes in SI, it is possible to report the results in a variety of units. For all functions that provide output, there are two arguments that can be defined to set the output units: qUnit and FluxUnit.  qUnit and FluxUnit can be defined by a numeric code or name.  There are two functions that can be called to see the options for qUnit and FluxUnit: printqUnitCheatSheet and printFluxUnitCheatSheet.


<<cheatSheets,echo=TRUE,eval=TRUE>>=
printqUnitCheatSheet()
@

When a function has an input argument qUnit, you can define the flow units with the index (1-6) as shown above. The choice should be based on the units that are customary for the audience, but also so that the discharge values don't have too many digits to the right or left of the decimal point.

<<cheatSheets2,echo=TRUE,eval=TRUE>>=
printFluxUnitCheatSheet()
@

When a function has an input argument FluxUnit, you can define the flux units with the index (1-12) as shown above. The choice should be based on the units that are customary for the audience, but also so that the flux values don't have too many digits to the right or left of the decimal point.


%------------------------------------------------------------ 
\section{Flow History}
\label{sec:flowHistory}
%------------------------------------------------------------ 
This section describes functions included in the EGRET package that provide a variety of table and graphical outputs looking only at flow statistics based on time-series smoothing. These functions were designed for studies of long-term streamflow change and work best for daily streamflow data sets of 50 years or longer. This type of analysis might be useful for studying 

At this point it is assumed that you have loaded the daily discharge record and created the Daily data frame, and also entered the required meta-data into the INFO data frame. We will walk through an example from the Rio Grande gaging station in Embodo, NM.  This is the first stream gage station in the USGS, established by John Wesley Powell in 1888.


<<flowHistory,echo=TRUE>>=
#Rio Grande at Embudo, NM
siteID <- "08279500"  
startDate <- ""
endDate <- ""

Daily <- getDVData(siteID,"00060",startDate,endDate,interactive=FALSE)
INFO <- getMetaData(siteID,"",interactive=FALSE)
INFO$shortName <- "Rio Grande at Embudo, NM"
@

The first choice you need to make is what 'period of analysis' to use (pa). What is the period of analysis?  If we want to examine our data set as a time series of water years, then the period of analysis is the water year.  If we want to examine the data set as calendar years then the period of analysis should be the calendar year.  We might want to examine the winter season, which we might want to define as December, January and February, then those 3 months become the period of analysis.  We might even want to examine September only then September becomes the period of analysis.  The only constraints on the definition of a period of analysis are these: It must be defined in terms of whole months.  It must be a set of contiguous months (like March-April-May).  And it must have a length that is no less than 1 month and no more than 12 months.  It can be uniquely defined by two arguments: paLong and paStart.  paLong is the length of the period of analysis, and paStart is the first month of the period of analysis. The following examples summarize paLong and paStart.

<<label=paINFO, echo=FALSE,results=tex>>=
PeriodOfAnalysis <- c("Calendar Year", "Water Year", "Winter", "September")
paStart <- c("1","10","12","9")
PaLong <- c("12","12","3","1")

DF <- data.frame(PeriodOfAnalysis,paStart,PaLong)

data.table <- xtable(DF, caption="Period of Analysis Information",label="table:paINFO")
print(data.table, caption.placement="top",include.rownames=FALSE,table.placement="!ht")
@

To set a period running from December through February:
<<newChunckWinter, echo=TRUE,eval=TRUE>>=
INFO <- setPA(paStart=12,paLong=3)
@

To set the default value (water year):
<<newChunck, echo=TRUE,eval=TRUE>>=
INFO <- setPA()
@

The next step is to create the annual series of flow statistics.  These will be stored in a matrix called annualSeries that contain the following statistics:

<<label=istat, echo=FALSE,results=tex>>=
istat <- c("1", "2", "3", "4","5","6","7","8")
Name <- c("1-day minimum flow","7-day minimum flow","30-day minimum flow","median flow","mean flow","30-day maximum flow", "7-day maximum flow", "1-day maximum flow")

DF <- data.frame(istat,Name)

data.table <- xtable(DF,  caption="Index of Statistics Information",label= "table:istat")

print(data.table, caption.placement="top", include.rownames=FALSE,table.placement="!ht")
@


To create the annualSeries matrix, using the function makeAnnualSeries:
<<newChunckAS, echo=TRUE,eval=TRUE>>=
annualSeries <- makeAnnualSeries()
@

Once the annualSeries matrix is created, the plots of any of the stored statistics can be generated with the plotFlowSingle function.

%------------------------------------------------------------ 
\subsection{Plotting Options}
\label{sec:plotOptions}
%------------------------------------------------------------ 
There are several plotting options available for studying flow history once the annualSeries has been created.

%------------------------------------------------------------ 
\subsubsection{plotFlowSingle}
\label{sec:plotFlowSingle}
%------------------------------------------------------------ 
The simplest way to look at these time series is with the function plotFlowSingle. The statistic index (istat) must be defined, but other input arguements can defined. To see a list of these optional arguments and other information about the function, type ?plotFlowSingle in the R console. In this example, we can plot the 7-day maximum over the water year in thousands of cfs (Figure \ref{fig:plotflow}):


<<plotFlow, echo=TRUE>>=
# plotFlowSingle(istat=5,qUnit=3)
#identical to:
plotFlowSingle(istat=7,qUnit="thousandCfs")
@

\setlength{\abovecaptionskip}{0pt}
\begin{figure}[ht]
\begin{center}
<<label=fig1, fig=TRUE,echo=FALSE>>=
<<plotFlow>>
@
\end{center}
\caption{7-day Maxiumum Flow (istat=7)}
\label{fig:plotflow}
\end{figure}

\FloatBarrier

%------------------------------------------------------------ 
\subsubsection{plotSDLogQ}
\label{sec:plotSDLogQ}
%------------------------------------------------------------ 
This function produces a graphic of the running standard deviation of the log of daily discharge over time.  The idea is to get some idea of how variability of daily discharge is changing over time.  By using the standard deviation of the log discharge the statistic becomes dimensionless.  It also means that it is a way of looking at variability quite aside from average values, so, in the case of a system where discharge might be increasing over a period of years, this provides a way of looking at the variability relative to that changing mean value.  It is much like a coefficient of variation, but it has sample properties that make it a smoother measure of variability.  There are often comments about how things like urbanization or enhanced greenhouse gases in the atmosphere are bringing about an increase in variability, this is one way to explore that idea.  In the simplest case the call is (Figure \ref{fig:SD1}):

<<plotSDtext, echo=TRUE,eval=FALSE>>=
INFO <- setPA()
plotSDLogQ()
@

If you were just interested in the variablility in spring (March-April-May), you could change paStart and paLong using the setPA function (Figure \ref{fig:SD2}). These figures show there is little change in variability on the Rio Grande between the water year and spring.  

<<plotSD2text, echo=TRUE,eval=FALSE>>=
INFO <- setPA(paStart=3, paLong=3)
plotSDLogQ()
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<plotSD, echo=FALSE,eval=TRUE>>=
INFO <- setPA()
plotSDLogQ(printStaName = FALSE)
@

<<label=fig2a, fig=TRUE,echo=FALSE>>=
<<plotSD>>
@
    \subcaption{Water Year}
    \label{fig:SD1}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<plotSD2, echo=FALSE,eval=TRUE>>=
INFO <- setPA(paStart=3, paLong=3)
plotSDLogQ(printStaName = FALSE)
@

<<label=fig2b, fig=TRUE,echo=FALSE>>=
<<plotSD2>>
@
    \subcaption{Spring (March-May)}
    \label{fig:SD2}
    \end{center}
  \end{minipage}
  \caption{Discharge variability on the Rio Grande}
\end{figure}

A more interesting comparison might be between spring and summer on the Red River of the North (Figure \ref{fig:red}).  This figure shows that there is generally more variability in discharge in the spring compared to the summer.

<<plotSDRed, echo=FALSE,eval=TRUE>>=
siteID <- "05082500"
DailyRed <- getDVData(siteID,"00060","","",interactive=FALSE)
INFORed <- getMetaData(siteID,"",interactive=FALSE)
INFORed$shortName <- "Red River, ND"
INFORed <- setPA(paStart=6, paLong=3,localINFO = INFORed)
plotSDLogQ(localDaily = DailyRed, localINFO = INFORed, printStaName = FALSE)
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<label=fig3a, fig=TRUE,echo=FALSE>>=
<<plotSDRed>>
@
    \subcaption{Summer (June-August)}
    \label{fig:SDRed1}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<plotSDRed2, echo=FALSE,eval=TRUE>>=
INFORed <- setPA(paStart=3, paLong=3)
plotSDLogQ(localDaily = DailyRed, localINFO = INFORed,printStaName = FALSE)
@

<<label=fig3b, fig=TRUE,echo=FALSE>>=
<<plotSDRed2>>
@
    \subcaption{Spring (March-May)}
    \label{fig:SDRed2}
    \end{center}
  \end{minipage}
  \caption{Discharge variability on the Red River of the North, ND}
  \label{fig:red}
\end{figure}

\FloatBarrier
%------------------------------------------------------------ 
\subsubsection{plotQTimeDaily}
\label{sec:plotQTimeDaily}
%------------------------------------------------------------ 
plotQTimeDaily is simply a time series plot of discharge.  But, it is most suited for showing events above some discharge threshold.  In the simplest case, it can plot the entire record, but given the line weight and use of an arithmetic scale it will primarily provide a visual focus on the higher values. plotQTimeDaily requires startYear and endYear, along with some other optional arguements (see ?plotQTimeDaily for more details).

Returning to our example concerning the Rio Grande (Figure \ref{fig:plotQTimeDaily}):
<<plotQTimeDaily, echo=TRUE,eval=TRUE>>=
plotQTimeDaily(1990,2000,qLower=2,qUnit=3)
@

\begin{figure}[ht]
\begin{center}

<<label=figplotQTimeDailyFig, fig=TRUE,echo=FALSE>>=
<<plotQTimeDaily>>
@
\end{center}
\caption{Discharge above a threshold}
\label{fig:plotQTimeDaily}
\end{figure}

\FloatBarrier
%------------------------------------------------------------ 
\subsubsection{plotFour}
\label{sec:plotFour}
%------------------------------------------------------------

<<plotFour, echo=TRUE,eval=TRUE>>=
annualSeries <- makeAnnualSeries()
plotFour(qUnit=3)
@

\begin{figure}[h]
\begin{center}

<<label=figplotFour, fig=TRUE,echo=FALSE>>=
<<plotFour>>
@
\end{center}
\caption{Default plotFour}
\label{fig:plotFour}
\end{figure}

\FloatBarrier
%------------------------------------------------------------ 
\subsubsection{plotFourStats}
\label{plotFourStats}
%------------------------------------------------------------
<<plotFourStats, echo=TRUE,eval=TRUE>>=
plotFourStats(qUnit=3)
@

\begin{figure}[ht]
\begin{center}

<<label=figplotFourStats, fig=TRUE,echo=FALSE>>=
<<plotFourStats>>
@
\end{center}
\caption{Default plotFourStats}
\label{fig:plotFourStats}
\end{figure}

\FloatBarrier
%------------------------------------------------------------ 
\subsection{Table Options}
\label{sec:tableOptions}
%------------------------------------------------------------ 
Rathar than graphically, it is sometimes easier to consider the results in table formats. 

%------------------------------------------------------------ 
\subsubsection{printSeries}
\label{sec:printSeries}
%------------------------------------------------------------
Similar to the function plotFlowSingle, the printSeries will print the requested flow statistics (Table \ref{table:istat}). A small sample of the output is printed below.

<<printSeries, eval=FALSE,echo=TRUE>>=
printSeries(istat=3, qUnit=3)
@

\begin{verbatim}
Rio Grande at Embudo, NM
 Water Year
    30-day minimum
    Thousand Cubic Feet per Second
   year   annual   smoothed
           value    value
   1899    0.280    0.296
   1900    0.208    0.285
   1901    0.169    0.277
   1902    0.320    0.272
...
   2011    0.252    0.248
   2012    0.257       NA
\end{verbatim}

\FloatBarrier
%------------------------------------------------------------ 
\subsubsection{tableFlowChange}
\label{sec:tableFlowChange}
%------------------------------------------------------------
Another way to look at the results is to consider how much the smoothed values change between various pairs of years.  These changes can be represented in four different ways.  
\begin{itemize}
  \item As a change between the first and last year of the pair, expressed in the flow units selected.
  \item As a change between the first and last year of the pair, expressed as a percentage of the value in the first year
  \item As a slope between the first and last year of the pair, expressed in terms of the flow units per year.
  \item As a slope between the first and last year of the pair, expressed as a percentage change per year (a percentage based on the value in the first year).
\end{itemize}

There is another argument that can be very useful in this function: yearPoints.  In the default case, the set of years that are compared are at 5 year intervals along the whole data set.  If the data set was quite long this can be a daunting number of comparisons.  For example, in an 80 year record, there would be 136 such pairs. Instead, we could look at changes for every 20 years starting in 1930: 

<<printSeries, eval=TRUE,echo=TRUE>>=
tableFlowChange(istat=3, qUnit=3,yearPoints=c(1930,1950,1970,1990,2010))
@


\FloatBarrier

%------------------------------------------------------------ 
\section{Water Quality Analysis (pre-WRTDS)}
\label{sec:wqa}
%------------------------------------------------------------ 
Before running the WRTDS model, it is very helpful to take a look at the measured data in a graphical way to understand its behavior and to identify things that might be errors in the data set or learn about the temporal distribution of the data (identify gaps) prior to running the model.  It is always best to clear up these issues before moving forward.

In this section and the next, we will use the Choptank River at Greensboro, MD as our example case. The Choptank River is a major tributary of the Chesapeake Bay. Inorganic nitrogen (nitrate and nitrite) has been measured from 1979. First, we need to get the streamflow and nitrate data into R, then use the mergeReport function to associate flow with the discrete measured water quality data.

<<wrtds1,eval=TRUE>>=
siteID <- "01491000" #Choptank River at Greensboro, MD
startDate <- "1979-10-01"
endDate <- "2011-09-30"
param<-"00631"
Daily <- getDVData(siteID,"00060",startDate,endDate)
INFO<- getMetaData(siteID,param,interactive=FALSE)
INFO$shortName <- "Choptank River"
Sample <- getSampleData(siteID,param,startDate,endDate)
Sample <- mergeReport()
@

%------------------------------------------------------------ 
\subsection{Water Quality Plotting Variables}
\label{sec:wqVariables}
%------------------------------------------------------------
The next section will cover the available plots in the EGRET package. This section will briefly summarize common input variables (arguments) for those functions.

\begin{table}
\caption{Variables used in water quality analysis plots  \label{tab:wqVariables}}
\begin{tabularx}{\textwidth}{lX}
\hline
  \textbf{Argument} & \textbf{Definition} \\
\hline
qUnit & Determines what units will be used for discharge, see \ref{sec:units}\\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption)\\
qLower & The lower bound on the discharge on the day of sampling that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in the units specified in qUnit.  If qLower = NA, then the lower bound is set to zero.\\
qUpper & The upper bound on the discharge on the day of sampling that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in the units specified in qUnit.  If qUpper = NA, then the lower bound is set to infinity.\\
paLong & The length of the time period that will be used in forming a subset of the sample data set that will be displayed in the graph, expressed in months. \\ 
paStart & The starting month for the time period that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in months (calendar months).\\
concMax & The upper limit on the vertical axis of graphs showing concentration values in mg/L (NA sets value to just above maximum).  \\
concMin & The lower limit on the vertical axis of graphs showing concentration values in mg/L (NA sets value to just below minimum for log scales, zero for linear).  \\
fluxUnit & Determines what units will be used for flux (see Section \ref{sec:units}).\\
fluxMax & The upper limit on the vertical axis of graphs showing flux values.  \\
\hline
\end{tabularx}

\end{table}

%------------------------------------------------------------ 
\subsection{Water Quality Plots}
\label{sec:wqPlots}
%------------------------------------------------------------
This section will give an example of the available plots appropriate for analyzing the data prior to performing a WRTDS analysis. The plots here will use the default values.  For any function, you can get a complete list of input variables (as described in the previous section) in a help file by typing a ? before the function name in the R console. 

One note about any of the plotting functions that show the sample data:  If a value in the data set is a non-detect. Then it is displayed on a graph as a vertical line.  The top of the line is the reporting limit and the bottom is either zero, or if the graph is plotting log concentration values, the minimum value on the y-axis.  This line is an 'honest' representation of what we know about that observation and doesn't involve us using a statistical model to fill in what we don't know. 


<<plotList, echo=TRUE,eval=FALSE>>=
boxConcMonth()
boxQTwice()
plotLogConcTime()
plotConcTime()
plotConcQ()
plotLogConcQ()
plotLogFluxQ()
multiPlotDataOverview()
@

<<boxConcMonth, echo=FALSE,eval=TRUE>>=
boxConcMonth()
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<label=figboxConcMonth, fig=TRUE,echo=FALSE>>=
<<boxConcMonth>>
@
    \subcaption{Default boxConcMonth}
    \label{fig:boxConcMonth}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<boxQTwice, echo=FALSE,eval=TRUE>>=
boxQTwice()
@

<<label=figboxQTwice, fig=TRUE,echo=FALSE>>=
<<boxQTwice>>
@
    \subcaption{Default boxQTwice}
    \label{fig:boxQTwice}
    \end{center}
  \end{minipage}
  \caption{Monthly sample distributions (left) and flow distributions (right)}
  \label{fig:boxConcMonthANDboxQTwice}
\end{figure}


<<plotConcTime, echo=FALSE,eval=TRUE>>=
plotConcTime()
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<label=figplotConcTime, fig=TRUE,echo=FALSE>>=
<<plotConcTime>>
@
    \subcaption{Default plotConcTime}
    \label{fig:plotConcTime}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<plotLogConcTime, echo=FALSE,eval=TRUE>>=
plotLogConcTime()
@

<<label=figplotLogConcTime, fig=TRUE,echo=FALSE>>=
<<plotLogConcTime>>
@
    \subcaption{Default plotLogConcTime}
    \label{fig:plotLogConcTime}
    \end{center}
  \end{minipage}
  \caption{Concentration vs. Time (Linear=left, Log=right)}
  \label{fig:plotLogConcTimeANDplotConcTime}
\end{figure}

<<plotConcQ, echo=FALSE,eval=TRUE>>=
plotConcQ()
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<label=figplotConcQ, fig=TRUE,echo=FALSE>>=
<<plotConcQ>>
@
    \subcaption{Default plotConcQ}
    \label{fig:plotConcQ}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<plotLogConcQ, echo=FALSE,eval=TRUE>>=
plotLogConcQ()
@

<<label=figplotLogConcQ, fig=TRUE,echo=FALSE>>=
<<plotLogConcQ>>
@
    \subcaption{Default plotLogConcQ}
    \label{fig:plotLogConcQ}
    \end{center}
  \end{minipage}
  \caption{Concentration vs. Discharge (Linear=left, Log=right) }
  \label{fig:plotLogConcQANDplotConcQ}
\end{figure}


<<plotLogFluxQ, echo=FALSE,eval=TRUE>>=
plotLogFluxQ()
@

\begin{figure}[htbp]
  \begin{minipage}[h]{0.5\linewidth}
    \begin{center}

<<label=figplotLogFluxQ, fig=TRUE,echo=FALSE>>=
<<plotLogFluxQ>>
@
    \subcaption{Default plotLogFluxQ}
    \label{fig:plotLogFluxQ}
    \end{center}
  \end{minipage}
  \hspace{0.5cm}
  
  \caption{Log flux vs. discharge}
  \label{fig:plotLogFluxQMain}
\end{figure}

<<multiPlotDataOverview, echo=TRUE,eval=TRUE>>=
multiPlotDataOverview()
@

\begin{figure}[ht]
\begin{center}

<<label=figmultiPlotDataOverview, fig=TRUE,echo=FALSE>>=
<<multiPlotDataOverview>>
@
\end{center}
\caption{Default multiPlotDataOverview}
\label{fig:multiPlotDataOverview}
\end{figure}

\FloatBarrier

Another useful tool for checking the data before running the WRTDS estimations is flowDuration. This is a utility function that can help define the flow ranges that we want to explore.  It prints out key points on the flow duration curve.  They are defined for a particular part of the year, although they can be done for the entire year.  

<<flowDuration, eval=TRUE, echo=TRUE>>=
flowDuration()
@

For all of these functions, please see the official WRTDS manual and help files for more information.

%------------------------------------------------------------ 
\section{WRTDS Analysis}
\label{sec:wrtds}
%------------------------------------------------------------ 
Weighted Regressions on Time, Discharge and Season (WRTDS) creates a model of long-term trends in river-water quality, seasonal components, and discharge-related components of the behavior of measured water-quality parameters. In this section, we will step though the process require for a WRTDS analysis. The following section (\ref{sec:wrtdsResults}) will detail the available methods to view and evaluate the model results. 

Once you have looked at your data using the tools described in section \ref{sec:wqa}, and have determined there is sufficient representative data, it is time to run the WRTDS model. There are a few inputs that can be defined before running the model:

\begin{table}
\caption{Variables in WRTDS  \label{tab:WRTDS}}
\begin{tabularx}{\textwidth}{lXl}
\hline
  \textbf{Argument} & \textbf{Definition} & \textbf{Default} \\
\hline
windowY & The half window width for the time weighting, measured in years.  Values much shorter than 10 usually result in a good deal of oscillations in the system that are likely not very realistic & 10\\
windowQ & The half window width for the weighting in terms of ln(Q).  For very large rivers (average discharge values in the range of many tens of thousands of cfs) a smaller value than 2 may be appropriate, but probably not less than 1 & 2 \\
windowS & The half window width for the seasonal weighting, measured in years.  Any value >0.5 will make data from all seasons have some weight.  Values should probably not be lower than 0.3 and there is no need to go higher than 0.5 & 0.5 \\
minNumObs & This is the minimum number of observations with non-zero weight that the individual regressions will require before they will be used.  If there too few observations the program will iterate, making the windows wider until the number increases above this minimum.  The only reason to lower this is in cases where the data set is rather small.  It should always be set to a number at least slightly smaller than the sample size.  Any value lower than about 60 is probably in the 'dangerous' range, in terms of the reliability of the regression & 100 \\ 
minNumUncen & This is the minimum number of uncensored observations with non-zero weight that the individual regressions will require before they will be used.  If there are too few uncensored observations the program will iterate, making the windows wider until the number increases above this minimum.  The only reason to lower this is in cases where the number of uncensored values is rather small.  The method has never been tested in situations where there are very few uncensored values & 50 \\
\hline
\end{tabularx}

\end{table}

\FloatBarrier

Assuming you are using the defaults, with dataframes called Daily, Sample, and INFO, the modelEstimation function will run the WRTDS modeling algorithm:

<<wrtds2, eval=FALSE, echo=TRUE>>=
modelEstimation()
@

This function is slow, and shows the progress in percent complete (as shown above). See the references and manual for more information. It's important to understand that this is the one function that will globally change your Daily, Sample, and INFO dataframes. It is unusual R programming, but was chosen to make it easy for the user.

The next step is for the user to select the period of analysis (see section \ref{sec:flowHistory}) to use in looking at the summary results from WRTDS. In the simplest case, where you would like to do the analysis by water years, the call would be:

<<wrtds3, eval=FALSE, echo=TRUE>>=
AnnualResults<-setupYears()
@

Finally, it is a good idea to save your results because of the computational time that has been invested in producing these results. Assuming that you have already created the object savePath, the command is just 

<<wrtds4, eval=FALSE, echo=TRUE>>=
savePath <- "C:/Users/ldecicco/WRTDS_Output"
saveResults(savePath) 
@

This will now save all of the objects in your workspace.  

%------------------------------------------------------------ 
\section{WRTDS Results}
\label{sec:wrtdsResults}
%------------------------------------------------------------ 
At this point (after having run modelEstimation and setupYears) we can start considering how to view the annual averages for the variables that have been calculated.  

%------------------------------------------------------------ 
\subsection{WRTDS Analysis Variables}
\label{sec:wqVariables}
%------------------------------------------------------------
The next section will cover the available plots to explore the WRTDS output in the EGRET package. This section will briefly summarize common input variables (arguments) for those functions.

\begin{table}
\caption{Variables used in WRTDS analysis plots  \label{tab:wrtdsVariables}}
\begin{tabularx}{\textwidth}{lX}
\hline
  \textbf{Argument} & \textbf{Definition} \\
\hline
qUnit & Determines what units will be used for discharge, see \ref{sec:units}\\
stdResid & This is an option.  If FALSE, it prints the regular residuals (they are in ln concentration units).  If TRUE, it is the standardized residuals.  These are the residuals divided by their estimated standard error (each residual has its own unique standard error).  In theory, the standardized residuals should have mean zero and standard deviation of 1 \\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption) \\
startYear & The starting date for the graph, expressed as decimal years, for example, 1989.0 \\
endYear & The ending date for the graph, expressed as decimal years, for example, 1996.0 \\
moreTitle & A character variable that adds additional information to the graphic title.  Typically used to indicate what the estimation method was (e.g. WRTDS or LOADEST).  Default is ' ' which indicates that nothing is added to title \\
\hline
\end{tabularx}

\end{table}

\FloatBarrier
%------------------------------------------------------------ 
\subsection{Graphical Results}
\label{sec:wrtdsPlotting}
%------------------------------------------------------------ 

%------------------------------------------------------------ 
\subsection{Tabular Results}
\label{sec:wrtdsTable}
%------------------------------------------------------------ 

\newpage
\appendix
%------------------------------------------------------------ 
\section{Appendix 1: Getting Started}
\label{sec:appendix1}
%------------------------------------------------------------ 
This section describes the options for downloading and installing the dataRetrieval package.

%------------------------------------------------------------
\subsection{New to R?}
%------------------------------------------------------------ 
If you are new to R, you will need to first install the latest version of R, which can be found here: \url{http://www.r-project.org/}.

There are many options for running and editing R code, one nice environment to learn R is RStudio. RStudio can be downloaded here: \url{http://rstudio.org/}. Once R and RStudio are installed, the environment package needs to be installed as described in the next section.

At any time, you can get information about any function in R by typing a question mark before the functions name.  This will open a file (in RStudio, in the Help window) that describes the function, the required arguments, and provides working examples.

<<helpFunc,eval = FALSE>>=
?getJulian
@

To see the raw code for a particular code, type the name of the function:
<<rawFunc,eval = TRUE>>=
getJulian
@


%------------------------------------------------------------
\subsection{R User: Installing EGRET}
%------------------------------------------------------------ 
To install the EGRET packages and it's dependencies:

<<installFromCran,eval = FALSE>>=
install.packages(c("zoo","survival","methods","fields","spam"))
install.packages("dataRetrieval", repos="http://usgs-r.github.com/", 
                 type="source")
install.packages("EGRET", repos="http://usgs-r.github.com/", 
                 type="source")
@

It is a good idea to re-start the R enviornment after installing the package, especially if installing an updated version (that is, restart RStudio). Some users have found it necessary to delete the previous version's package folder before installing newer version of EGRET. If you are experiencing issues after updating a package, trying deleting the package folder - the default location for Windows is something like this: C:/Users/userA/Documents/R/win-library/2.15/EGRET, and the default for a Mac: /Users/userA/Library/R/2.15/library/EGRET. Then, re-install the package using the directions above. Moving to CRAN should solve this problem.

After installing the package, you need to open the library each time you re-start R.  This is done with the simple command:
<<openLibraryTest, eval=FALSE>>=
library(dataRetrieval)
library(EGRET)
@
Using RStudio, you could alternatively click on the checkbox for dataRetrieval and EGRET in the Packages window.

%------------------------------------------------------------
\subsection{R Developers: Installing EGRET from gitHub}
%------------------------------------------------------------
Alternatively, R-developers can install the most recent (not-necessarily stable) version of EGRET directly from gitHub using the devtools package.  devtools is available on CRAN.  Simply type the following commands into R to install the latest version of EGRET available on gitHub.  Rtools (for Windows) and appropriate \LaTeX\ tools are required. Be aware that the version installed using this method isn't necessarily the same as the version in the stable release branch.  


<<gitInstal,eval = FALSE>>=
library(devtools)
install_github("dataRetrieval", "USGS-R")
install_github("EGRET", "USGS-R")
@
To then open the library, simply type:

<<openLibrary, eval=FALSE>>=
library(dataRetrieval)
library(EGRET)
@


%------------------------------------------------------------
% BIBLIO
%------------------------------------------------------------
\begin{thebibliography}{10}

\bibitem{HirschI}
Helsel, D.R. and R. M. Hirsch, 2002. Statistical Methods in Water Resources Techniques of Water Resources Investigations, Book 4, chapter A3. U.S. Geological Survey. 522 pages. \url{http://pubs.usgs.gov/twri/twri4a3/}

\bibitem{HirschII}
Hirsch, R. M., Moyer, D. L. and Archfield, S. A. (2010), Weighted Regressions on Time, Discharge, and Season (WRTDS), with an Application to Chesapeake Bay River Inputs. JAWRA Journal of the American Water Resources Association, 46: 857-880. doi: 10.1111/j.1752-1688.2010.00482.x \url{http://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.2010.00482.x/full}

\bibitem{HirschIII}
Sprague, L. A., Hirsch, R. M., and Aulenbach, B. T. (2011), Nitrate in the Mississippi River and Its Tributaries, 1980 to 2008: Are We Making Progress? Environmental Science \& Technology, 45 (17): 7209-7216. doi: 10.1021/es201221s \url{http://pubs.acs.org/doi/abs/10.1021/es201221s}

\end{thebibliography}

\end{document}

\end{document}
