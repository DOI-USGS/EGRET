%\VignetteIndexEntry{Introduction to the EGRET package}
%\VignetteEngine{knitr::knitr}
%\VignetteDepends{}
%\VignetteSuggests{xtable, dataRetrieval,extrafont}
%\VignetteImports{methods,survival, fields}
%\VignettePackage{EGRET}

\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{times}
\usepackage{hyperref}
\usepackage[numbers, round]{natbib}
\usepackage[american]{babel}
\usepackage{authblk}
\usepackage{subfig}
\usepackage{placeins}
\usepackage{footnote}
\usepackage{tabularx}
\usepackage{parskip}
\usepackage{threeparttable}
\renewcommand\Affilfont{\itshape\small}

\usepackage{csquotes}
\usepackage{setspace}

% \doublespacing

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\usepackage{graphicx}


\usepackage{mathptmx}% Times Roman font
\usepackage[scaled=.90]{helvet}% Helvetica, served as a model for arial

% \usepackage{indentfirst}
% \setlength\parindent{20pt}
\setlength{\parskip}{0pt}

\usepackage{courier}

\usepackage{titlesec}
\usepackage{titletoc}

\titleformat{\section}
  {\normalfont\sffamily\bfseries\LARGE}
  {\thesection}{0.5em}{}
\titleformat{\subsection}
  {\normalfont\sffamily\bfseries\Large}
  {\thesubsection}{0.5em}{}
\titleformat{\subsubsection}
  {\normalfont\sffamily\large}
  {\thesubsubsection}{0.5em}{}
  
\titlecontents{section}
[2.3em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}
  
\titlecontents{subsection}
[4.6em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}
  
\titlecontents{subsubsection}
[6.9em]                 % adjust left margin
{\sffamily}             % font formatting
{\contentslabel{2.3em}} % section label and offset
{\hspace*{-2.3em}}
{\titlerule*[0.25pc]{.}\contentspage}

\titlecontents{table}
[0em]                 % adjust left margin
{\sffamily}             % font formatting
{\textbf{Table}\hspace*{2em} \contentslabel {2em}} % section label and offset
{\hspace*{4em}}
{\titlerule*[0.25pc]{.}\contentspage}

\titlecontents{figure}
[0em]                 % adjust left margin
{\sffamily}             % font formatting
{\textbf{Figure}\hspace*{2em} \contentslabel {2em}} % section label and offset
{\hspace*{4em}}
{\titlerule*[0.25pc]{.}\contentspage}

%Italisize and change font of urls:
\urlstyle{sf}
\renewcommand\UrlFont\itshape

\usepackage{caption}
\captionsetup{
  font={sf},
  labelfont={bf,sf},
  labelsep=period,
  justification=justified,
  singlelinecheck=false
}



\textwidth=6.5in
\textheight=9.2in
\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}

\renewenvironment{knitrout}{\begin{singlespace}}{\end{singlespace}}
\renewcommand*\listfigurename{Figures}
\renewcommand*\listtablename{Tables}

<<openLibrary, echo=FALSE>>=
library(xtable)
options(continue=" ")
options(width=60)
library(knitr)

@


<<include=TRUE ,echo=FALSE,eval=TRUE>>=
opts_chunk$set(highlight=TRUE, tidy=TRUE, keep.space=TRUE, keep.blank.space=FALSE, keep.comment=TRUE, concordance=TRUE,tidy=FALSE,comment="")

knit_hooks$set(inline = function(x) {
   if (is.numeric(x)) round(x, 3)})
knit_hooks$set(crop = hook_pdfcrop)

bold.colHeaders <- function(x) {
  x <- gsub("\\^(\\d)","$\\^\\1$",x)
  x <- gsub("\\%","\\\\%",x)
  x <- gsub("\\_"," ",x)
  returnX <- paste("\\multicolumn{1}{c}{\\textbf{\\textsf{", x, "}}}", sep = "")
}

addSpace <- function(x) ifelse(x != "1", "[5pt]","")

@

%------------------------------------------------------------
\title{Introduction to the EGRET package}
%------------------------------------------------------------
\author[1]{Robert Hirsch}
\author[1]{Laura De Cicco}
\affil[1]{United States Geological Survey}

\noindent{\huge\textsf{\textbf{Introduction to the EGRET package}}}

\noindent\textsf{By Robert Hirsch and Laura De Cicco}

\noindent\textsf{\today}

% \maketitle
% 
% \newpage 

\tableofcontents
\listoffigures
\listoftables

\newpage


%------------------------------------------------------------
\section{Introduction to Exploration and Graphics for RivEr Trends (EGRET)}
%------------------------------------------------------------ 

EGRET includes statistics and graphics for streamflow history, water quality trends, and the modeling algorithm Weighted Regressions on Time, Discharge, and Season (WRTDS). \textbf{Please see the official EGRET manual:} (\url{http://dx.doi.org/10.3133/tm4A10}) \textbf{for more information on the EGRET package.} For information on getting started in R, downloading and installing the package, see section \ref{sec:appendix1}.

The best way to learn about the WRTDS approach and to see examples of its application to multiple large data sets is to read two journal articles.  They are available, for free, from the journals in which they were published. The first relates to nitrate and total phosphorus data for 9 rivers draining to Chesapeake Bay.  The URL is \cite{HirschII}: \url{http://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.2010.00482.x/full}. The second is an application  to nitrate data for 8 monitoring sites on the Mississippi River or its major tributaries \cite{HirschIII}.  The URL is: \url{http://pubs.acs.org/doi/abs/10.1021/es201221s}

This vignette assumes that you understand the concepts underlying WRTDS, and reading at least the first of these papers is necessary for that understanding.  The method has been enhanced beyond what was previously published, and it now properly handles censored data by using survival regression rather than ordinary regression.  The details of this change are in a report on Chesapeake Bay river input trends \cite{HirschIV}:\url{http://pubs.usgs.gov/sir/2012/5244/}.  The specific enhancements for handling censored data are on pages 9-11 of the report.

This vignette guides you through the major functions provided by the EGRET package. The package dataRetrieval is required for importing data in an EGRET-friendly format. The dataRetrieval package and installation instructions are at:
\url{https://github.com/USGS-R/dataRetrieval}. Installing dataRetrieval will provide a vignette similar to this document, with complete working examples of the main dataRetrieval functions. This document assumes you are familiar with the dataRetrieval package. Further details are in the user guide available on gitHub: \url{https://github.com/USGS-R/EGRET/raw/master/inst/doc/EGRET.pdf}

Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.

%------------------------------------------------------------
\section{EGRET Workflow}
%------------------------------------------------------------ 
Subsequent sections of this vignette discuss the EGRET workflow steps in greater detail. This section provides a handy cheat sheet for diving into an EGRET analysis. The first example is for a flow history analysis:


<<workflowFlowHistory, echo=TRUE,eval=FALSE>>=
library(dataRetrieval)
library(EGRET)

# Flow history analysis

############################
# Gather discharge data:
siteNumber <- "01491000" #Choptank River at Greensboro, MD
startDate <- "" # Get earliest date
endDate <- "" # Get latest date
Daily <- getNWISDaily(siteNumber,"00060",startDate,endDate)
# Gather site and parameter information:
# Here user must input some values for
# the default (interactive=TRUE)
INFO<- getNWISInfo(siteNumber,"00060")
INFO$shortName <- "Choptank River at Greensboro, MD"
############################

############################
# Check flow history data:
annualSeries <- makeAnnualSeries()
plotFlowSingle(istat=7,qUnit="thousandCfs")
plotSDLogQ()
plotQTimeDaily(qLower=1,qUnit=3)
plotFour(qUnit=3)
plotFourStats(qUnit=3)
############################

# modify this for your own computer file structure:
savePath<-"/Users/rhirsch/Desktop/" 
saveResults(savePath)

@

The second workflow example is for a water quality analysis. It includes data retrieval, merging of water quality and streamflow data, running the WRTDS estimation, and various plotting functions available in the EGRET package.


<<workflowWaterQuality, echo=TRUE,eval=FALSE>>=
library(dataRetrieval)
library(EGRET)

############################
# Gather discharge data:
siteNumber <- "01491000" #Choptank River at Greensboro, MD
startDate <- "" #Gets earliest date
endDate <- "2011-09-30"
# Gather sample data:
parameter_cd<-"00631" #5 digit USGS code
Sample <- getNWISSample(siteNumber,parameter_cd,startDate,endDate)
#Gets earliest date from Sample record:
#This is just one of many ways to assure the Daily record
#spans the Sample record
startDate <- min(as.character(Sample$Date)) 
# Gather discharge data:
Daily <- getNWISDaily(siteNumber,"00060",startDate,endDate)
# Gather site and parameter information:

# Here user must input some values for
# the default (interactive=TRUE)
INFO<- getNWISInfo(siteNumber,parameter_cd)
INFO$shortName <- "Choptank River at Greensboro, MD"

# Merge discharge with sample data:
Sample <- mergeReport(Daily, Sample)
############################

############################
# Check sample data:
boxConcMonth()
boxQTwice()
plotConcTime()
plotConcQ()
multiPlotDataOverview()
############################

############################
# Run WRTDS model:
modelEstimation()
############################

############################
#Check model results:

#Require Sample + INFO:
plotConcTimeDaily()
plotFluxTimeDaily()
plotConcPred()
plotFluxPred()
plotResidPred()
plotResidQ()
plotResidTime()
boxResidMonth()
boxConcThree()

#Require Daily + INFO:
plotConcHist()
plotFluxHist()

# Multi-line plots:
date1 <- "2000-09-01"
date2 <- "2005-09-01"
date3 <- "2009-09-01"
qBottom<-100
qTop<-5000
plotConcQSmooth(date1, date2, date3, qBottom, qTop, 
                   concMax=2,qUnit=1)
q1 <- 10
q2 <- 25
q3 <- 75
centerDate <- "07-01"
yearEnd <- 2009
yearStart <- 2000
plotConcTimeSmooth(q1, q2, q3, centerDate, yearStart, yearEnd)

# Multi-plots:
fluxBiasMulti()

#Contour plots:
clevel<-seq(0,2,0.5)
maxDiff<-0.8
yearStart <- 2000
yearEnd <- 2010

plotContours(yearStart,yearEnd,qBottom,qTop, 
             contourLevels = clevel,qUnit=1)
plotDiffContours(yearStart,yearEnd,
                 qBottom,qTop,maxDiff,qUnit=1)

# modify this for your own computer file structure:
savePath<-"/Users/rhirsch/Desktop/" 
saveResults(savePath)
@


%------------------------------------------------------------ 
\section{EGRET Dataframes and Units}
\label{sec:dataframes}
%------------------------------------------------------------ 
The EGRET package uses 3 default dataframes throughout the calculations, analysis, and graphing. These dataframes are Daily (\ref{sec:dataframesDaily}), Sample (\ref{sec:dataframesSample}), and INFO (\ref{sec:dataframesINFO}). EGRET uses entirely SI units to store the data, but for purposes of output, it can report results in a wide variety of units, which will be discussed in (\ref{sec:units}). To start our exploration, you must install the packages (check Section \ref{sec:appendix1} for detailed instructions), and then open EGRET with the following command:

<<openlibraries, echo=TRUE,eval=TRUE>>=
library(dataRetrieval)
library(EGRET)
@

%------------------------------------------------------------ 
\subsection{Daily}
\label{sec:dataframesDaily}
%------------------------------------------------------------ 
The Daily dataframe initially is populated with columns generated by the dataRetrieval package (Table \ref{table:Daily1}).  After you run the WRTDS calculations by using the function \texttt{modelEstimation} (as will be described in section \ref{sec:wrtds}), additional columns are inserted (Table \ref{table:Daily2}).

\begin{table}[!ht]
{\footnotesize
\caption{Daily dataframe} 
\label{table:Daily1}
\begin{tabular}{llll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Type}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Units}}} \\ 
  \hline
  Date & Date & Date & date \\ 
  [5pt]Q & number & Discharge in m\textsuperscript{3}/s & m\textsuperscript{3}/s \\ 
  [5pt]Julian & number & Number of days since January 1, 1850 & days \\ 
  [5pt]Month & integer & Month of the year [1-12] & months \\ 
  [5pt]Day & integer & Day of the year [1-366] & days \\ 
  [5pt]DecYear & number & Decimal year & years \\ 
  [5pt]MonthSeq & integer & Number of months since January 1, 1850 & months \\ 
  [5pt]Qualifier & string & Qualifying code & character \\ 
  [5pt]i & integer & Index of days, starting with 1 & days \\ 
  [5pt]LogQ & number & Natural logarithm of Q & numeric \\ 
  [5pt]Q7 & number & 7 day running average of Q & m\textsuperscript{3}/s \\ 
  [5pt]Q30 & number & 30 day running average of Q & m\textsuperscript{3}/s \\ 
   \hline
\end{tabular}
}
\end{table}

\begin{table}[!ht]
{\footnotesize
\caption{Columns added to Daily dataframe after running \texttt{modelEstimation} }
\label{table:Daily2}
\begin{tabular}{llll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Type}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Units}}} \\ 
  \hline
yHat & number & The WRTDS estimate of the log of concentration & numeric \\ 
  [5pt]SE & number & The WRTDS estimate of the standard error of yHat & numeric \\ 
  [5pt]ConcDay & number & The WRTDS estimate of concentration & mg/L \\ 
  [5pt]FluxDay & number & The WRTDS estimate of flux & kg/day \\ 
  [5pt]FNConc & number & Flow-normalized estimate of concentration & mg/L \\ 
  [5pt]FNFlux & number & Flow-normalized estimate of flux & kg/day \\ 
   \hline
\end{tabular}
}
\end{table}

\FloatBarrier

Notice that the \enquote{Day of the year} column can span from 1 to 366. The 366 accounts for leap years. Every day has a consistent day of the year. This means, February 28\textsuperscript{th} is always the 59\textsuperscript{th} day of the year, Feb. 29\textsuperscript{th} is always the 60\textsuperscript{th} day of the year, and March 1\textsuperscript{st} is always the 61\textsuperscript{st} day of the year whether or not it is a leap year.


%------------------------------------------------------------ 
\subsection{Sample}
\label{sec:dataframesSample}
%------------------------------------------------------------ 
The Sample dataframe initially is populated with columns generated by the dataRetrieval package (Table \ref{table:Sample1}). After you run the WRTDS calculations using the \texttt{modelEstimation} function (as described in section \ref{sec:wrtds}), additional columns are inserted (Table \ref{table:Sample2}):

\begin{table}[!ht]
{\footnotesize
  \begin{threeparttable}[b]
\caption{Sample dataframe} 
\label{table:Sample1}
\begin{tabular}{llll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Type}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Units}}} \\ 
  \hline
Date & Date & Date & date \\ 
  [5pt]ConcLow & number & Lower limit of concentration & mg/L \\ 
  [5pt]ConcHigh & number & Upper limit of concentration & mg/L \\ 
  [5pt]Uncen & integer & Uncensored data (1=true, 0=false) & integer \\ 
  [5pt]ConcAve & number & Average concentration & mg/L \\ 
  [5pt]Julian & number & Number of days since January 1, 1850 & days \\ 
  [5pt]Month & integer & Month of the year [1-12] & months \\ 
  [5pt]Day & integer & Day of the year [1-366] & days \\ 
  [5pt]DecYear & number & Decimal year & years \\ 
  [5pt]MonthSeq & integer & Number of months since January 1, 1850 & months \\ 
  [5pt]SinDY & number & Sine of DecYear & numeric \\ 
  [5pt]CosDY & number & Cosine of DecYear & numeric \\ 
  [5pt]Q \tnote{1} & number & Discharge & cms \\ 
  [5pt]LogQ \tnote{1} & number & Natural logarithm of discharge & numeric \\ 
   \hline
\end{tabular}
  \begin{tablenotes}
    \item[1] Populated after calling \texttt{mergeReport}.
  \end{tablenotes}
 \end{threeparttable}
}
\end{table}


\begin{table}[!ht]
{\footnotesize
\begin{threeparttable}[b]
\caption{Columns added to Sample dataframe after running \texttt{modelEstimation()}}
\label{table:Sample2}
\begin{tabular}{llll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Type}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Units}}} \\ 
  \hline
yHat\tnote{1} & number & estimate of the log of concentration & numeric \\ 
  [5pt]SE\tnote{1} & number & estimate of the standard error of yHat & numeric \\ 
  [5pt]ConcHat\tnote{1} & number & unbiased estimate of concentration & mg/L \\ 
   \hline
\end{tabular}

  \begin{tablenotes}
    \item[1] These estimates are \enquote{leave-one-out cross validation} estimates.  See the EGRET Manual for more details.
  \end{tablenotes}
 \end{threeparttable}
}
\end{table}



\FloatBarrier


%------------------------------------------------------------ 
\subsection{INFO}
\label{sec:dataframesINFO}
%------------------------------------------------------------ 
The INFO dataframe stores information about the measurements, such as station name, parameter name, drainage area, and so forth. There can be many additional, optional columns, but the columns in Table \ref{table:Info1} are required to initiate the EGRET analysis. After you run the WRTDS calculations (as described in section \ref{sec:wrtds}), additional columns (Table \ref{table:Info2}) are automatically inserted into the INFO dataframe (see the EGRET Manual for complete description of each term):

\begin{table}[!ht]
{\footnotesize
\begin{threeparttable}[b]
\caption{INFO dataframe}
\label{table:Info1}
\begin{tabular}{lll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Type}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} \\ 
  \hline
  shortName & string & Name of site, suitable for use in graphical headings \\ 
  [5pt]staAbbrev & string & Abbreviation for station name, used in saveResults \\ 
  [5pt]paramShortName & string & Name of constituent, suitable for use in graphical headings \\ 
  [5pt]constitAbbrev & string & Abbreviation for constituent name, used in saveResults \\ 
  [5pt]drainSqKm & numeric & Drainage area in  km\textsuperscript{2} \\ 
  [5pt]paStart \tnote{1} & integer (1-12) & Starting month of period of analysis \\ 
  [5pt]paLong \tnote{1} & integer (1-12) & Length of period of analysis in months \\ 
   \hline
\end{tabular}

\begin{tablenotes}
    \item[1] Inserted with the \texttt{setPA} function.
  \end{tablenotes}
 \end{threeparttable}
}
\end{table}


\begin{table}[!ht]
{\footnotesize
\caption{INFO dataframe after running \texttt{modelEstimation()}} 
\label{table:Info2}
\begin{tabular}{lll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{ColumnName}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Units}}} \\ 
  \hline
bottomLogQ & Lowest discharge in prediction surfaces & numeric \\ 
  [5pt]stepLogQ & Step size in log discharge in prediction surfaces & numeric \\ 
  [5pt]nVectorLogQ & Number of steps in discharge, prediction surfaces & numeric \\ 
  [5pt]bottomYear & Starting year in prediction surfaces & numeric \\ 
  [5pt]stepYear & Step size in years in prediction surfaces & numeric \\ 
  [5pt]nVectorYear & Number of steps in years in prediction surfaces & numeric \\ 
  [5pt]windowY & Half-window width in the time dimension & years \\ 
  [5pt]windowQ & Half-window width in the log discharge dimension & numeric \\ 
  [5pt]windowS & Half-window width in the seasonal dimension & years \\ 
  [5pt]minNumObs & Minimum number of observations for regression & integer \\ 
  [5pt]minNumUncen & Minimum number of uncensored observations & integer \\ 
   \hline
\end{tabular}
}
\end{table}


\FloatBarrier


%------------------------------------------------------------ 
\subsection{Units}
\label{sec:units}
%------------------------------------------------------------ 
EGRET uses entirely SI units to store the data, but for purposes of output, it can report results in a wide variety of units. The defaults are mg/L for concentration, cubic meters per second (m$^3$/s) for discharge, kg/day for flux, and km\textsuperscript{2} for drainage area. When discharge values are imported from USGS Web services (using the dataRetrieval package), they are automatically converted from cubic feet per second (cfs) to cms unless the argument \texttt{"}convert\texttt{"} in function \texttt{getNWISDaily} is set to FALSE.  This can cause confusion if you are not careful. 

For all functions that provide output, you can define two arguments to set the output units: qUnit and fluxUnit.  qUnit and fluxUnit are defined by either a numeric code or name.  You can call two functions that can be called to see the options: \texttt{printqUnitCheatSheet} and \texttt{printFluxUnitCheatSheet}.


<<cheatSheets,echo=TRUE,eval=TRUE,results='markup'>>=
printqUnitCheatSheet()
@

When a function has an input argument qUnit, you can define the discharge units that will be used in the figure or table that is generated by the function with the index (1-4) as shown above. Base your choice on the units that are customary for your intended audience, but also so that the discharge values don't have too many digits to the right or left of the decimal point.

<<cheatSheets2,echo=TRUE,eval=TRUE,results='markup'>>=
printFluxUnitCheatSheet()
@

When a function has an input argument fluxUnit, you can define the flux units with the index (1-12) as shown above. Base the choice on the units that are customary for your intended audience, but also so that the flux values don't have too many digits to the right or left of the decimal point. Tons are always \enquote{short tons} and not \enquote{metric tons}.

\FloatBarrier

%------------------------------------------------------------ 
\section{Flow History}
\label{sec:flowHistory}
%------------------------------------------------------------ 
This section describes functions included in the EGRET package that provide a variety of table and graphical outputs for examining discharge statistics based on time-series smoothing. These functions are designed for studies of long-term change and work best for daily discharge data sets of 50 years or longer. This type of analysis might be useful for studying issues such as the influence of land use change, water management change, or climate change on discharge conditions.  This includes potential impacts on average discharges, high discharges, and low discharges, at annual time scales as well as seasonal or monthly time scales. 

At this point it is assumed that you can load the daily discharge record into R, create the Daily dataframe, and enter the required metadata into the INFO dataframe. If not, see the dataRetrieval vignette:

<<vignette1, eval=FALSE, echo=TRUE>>=
vignette("dataRetrieval")
@

Consider this example from Columbia River at The Dalles, OR.

<<flowHistory,echo=TRUE,eval=TRUE>>=
siteNumber <- "14105700"  
startDate <- ""
endDate <- ""

Daily <- getNWISDaily(siteNumber,"00060",startDate,endDate)
INFO <- getNWISInfo(siteNumber,"",interactive=FALSE)
INFO$shortName <- "Columbia River at The Dalles, OR"
@

You first must determine the period of analysis to use (PA). What is the period of analysis?  If you want to examine your data set as a time series of water years, then the period of analysis is October through September.  If you want to examine the data set as calendar years then the period of analysis is January through December.  You might want to examine the winter season, which you could define as December through February, then those 3 months become the period of analysis. The only constraints on the definition of a period of analysis are these: it must be defined in terms of whole months; it must be a set of contiguous months (like March-April-May), and have a length that is no less than 1 month and no more than 12 months.  Define the PA by using two arguments: paLong and paStart.  paLong is the length of the PA, and paStart is the first month of the PA. Table \ref{table:paINFO} summarizes paLong and paStart.

\begin{table}[!ht]
{\footnotesize
\caption{Period of Analysis Information} 
\label{table:paINFO}
\begin{tabular}{lll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{Period of Analysis}}} &
\multicolumn{1}{c}{\textbf{\textsf{paStart}}} &
\multicolumn{1}{c}{\textbf{\textsf{paLong}}} \\ 
  \hline
Calendar Year & 1 & 12 \\ 
  [5pt]Water Year & 10 & 12 \\ 
  [5pt]Winter & 12 & 3 \\ 
  [5pt]September & 9 & 1 \\ 
   \hline
\end{tabular}
}
\end{table}

To set a period running from December through February:
<<newChunckWinter, echo=TRUE,eval=FALSE>>=
INFO <- setPA(paStart=12,paLong=3)
@

To set the default value (water year):
<<newChunck, echo=TRUE,eval=TRUE>>=
INFO <- setPA()
@

The next step is to create the annual series of discharge statistics.  These will be stored in a matrix called annualSeries that contain the statistics described in table \ref{table:istat}. The statistics are based on the period of analysis set with the \texttt{setPA} function.

\begin{table}[!ht]
{\footnotesize
\caption{Index of discharge statistics information} 
\label{table:istat}
\begin{tabular}{ll}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{istat}}} &
\multicolumn{1}{c}{\textbf{\textsf{Name}}} \\ 
  \hline
1 & minimum 1-day daily mean discharg \\ 
  [5pt]2 & minimum 7-day mean of the daily mean discharges \\ 
  [5pt]3 & minimum 30-day mean of the daily mean discharges \\ 
  [5pt]4 & median of the daily mean discharges \\ 
  [5pt]5 & mean of the daily mean discharges \\ 
  [5pt]6 & maximum 30-day mean of the daily mean discharges \\ 
  [5pt]7 & maximum 7-day mean of the daily mean discharges \\ 
  [5pt]8 & maximum 1-day daily mean discharge \\ 
   \hline
\end{tabular}
}
\end{table}

To create the annualSeries matrix, using the function \texttt{makeAnnualSeries}:
<<newChunckAS, echo=TRUE,eval=TRUE>>=
annualSeries <- makeAnnualSeries()
@

After you create the annualSeries matrix, you can generate the plots of any of the stored statistics by using the \texttt{plotFlowSingle} function.

\FloatBarrier

%------------------------------------------------------------ 
\subsection{Plotting Options}
\label{sec:plotOptions}
%------------------------------------------------------------ 

This section shows examples of the available plots appropriate for studying discharge history once the annualSeries has been created. The plots here use the default variable input options.  For any function, you can get a complete list of input variables (as described in section \ref{sec:flowHistoryVariables}) in a help file by typing a ? before the function name in the R console. The EGRET manual has more detailed information for each plot type (\href{https://github.com/USGS-R/EGRET/raw/Documentation/draft+user+guide+for+EGRET+and+dataRetrieval+2014-04-14.pdf}{link to download}). Finally, see section \ref{app:savingPlots} for information on saving plots.

The simplest way to look at these time series is with the function \texttt{plotFlowSingle}. The statistic index (istat) must be defined by the user, but for all other arguments there are default values so the user isn't required to specify anything else. To see a list of these optional arguments and other information about the function, type \text{?plotFlowSingle} in the R console. All of the graphs in \texttt{plotFlowSingle}, \texttt{plotFourStats}, and all but one of the graphs in plotFour, show both the individual annual values of the selected discharge statistic (e.g. the annual mean or 7-day minimum), but they also show a curve that is a smooth fit to those data.  The curve is a LOWESS (locally weighted scatterplot smooth).  The algorithm for computing it is provided in \cite{HirschV}:\url{http://pubs.usgs.gov/sir/2012/5151/}  (pages 6 and 7).  The default is that the annual values of the selected discharge statistics are smoothed with a \enquote{half-window width} of 30 years.  The smoothing window is an optional user-defined option. 

\texttt{plotSDLogQ} produces a graphic of the running standard deviation of the log of daily discharge over time to visualize how variability of daily discharge is changing over time.  By using the standard deviation of the log discharge the statistic becomes dimensionless.  The standard deviation plot is a way of looking at variability quite aside from average values, so, in the case of a system where discharge might be increasing over a period of years, this graphic provides a way of looking at the variability relative to that changing mean value.  The standard deviation is much like a coefficient of variation, but it has sample properties that make it a smoother measure of variability.  People often comment about how things like urbanization or enhanced greenhouse gases in the atmosphere are bringing about an increase in variability, and this analysis is one way to explore that idea. \texttt{plotFour}, \text{plotFourStats}, and \texttt{plot15} are all designed to plot several graphs from the other functions in a single figure. 

\newpage
\FloatBarrier
<<plotSingleandSD, echo=TRUE, fig.cap="Plots of discharge statistics",fig.subcap=c("plotFlowSingle(istat=5,qUnit='thousandCfs')","plotSDLogQ()"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotFlowSingle(istat=5,qUnit="thousandCfs")
plotSDLogQ()
@

\newpage
\FloatBarrier

Here is an example of looking at daily mean discharge for the full water year and then looking at mean daily discharge for the winter season only for the Merced River at Happy Isles Bridge in Yosemite National Park in California.  First, we look at the mean daily discharge for the full year (after having read in the data and metadata):


<<Merced, echo=TRUE,eval=TRUE,fig.cap="Merced River Winter Trend",fig.subcap=c("Water Year", "December - February"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
siteNumber<-"11264500"
Daily <-getNWISDaily(siteNumber,"00060",startDate="",endDate="")
INFO <- getNWISInfo(siteNumber,"",interactive=FALSE)
INFO$shortName <- "Merced River at Happy Isles Bridge, CA"
INFO <- setPA()
annualSeries <- makeAnnualSeries()
plotFlowSingle(istat=5)

# Then, we can run the same function, but first set 
# the pa to start in December and only run for 3 months.

INFO<-setPA(paStart=12,paLong=3)
annualSeries<-makeAnnualSeries()
plotFlowSingle(istat=5,qMax=200)

@

What these figures show us is that on an annual basis there is very little indication of a long-term trend in mean discharge, but for the winter months there is a pretty strong indication of an upward trend.  This could well be related to the climate warming in the Sierra Nevada, resulting in a general increase in the ratio of rain to snow in the winter and more thawing events.

\newpage
\FloatBarrier
<<plotFour, echo=TRUE, fig.cap="\\texttt{plotFour(qUnit=3)}",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
plotFour(qUnit=3)
@

\newpage
\FloatBarrier
<<plotFourStats,echo=TRUE, fig.cap="\\texttt{plotFourStats(qUnit=3)}",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
plotFourStats(qUnit=3)
@

\newpage
\FloatBarrier
<<Mississippi, echo=TRUE,eval=TRUE,fig.cap="Mississippi River at Keokuk Iowa",fig.subcap=c("Water Year", "Dec-Feb"),out.width='1\\linewidth',out.height='1\\linewidth',fig.show='hold',fig.pos="h">>=
siteNumber<-"05474500"
Daily <-getNWISDaily(siteNumber,"00060",startDate="",endDate="")
INFO <- getNWISInfo(siteNumber,"",interactive=FALSE)
INFO$shortName <- "Mississippi River at Keokuk Iowa"
INFO <- setPA()

plotQTimeDaily(qUnit=3,qLower=300)

@

\texttt{plotQTimeDaily} is simply a time series plot of discharge.  But, it is most suited for showing events above some discharge threshold.  In the simplest case, it can plot the entire record, but given the line weight and use of an arithmetic scale it primarily provides a visual focus on the higher values.

The example shown in Figure \ref{fig:Mississippi} illustrates a very long record with a long gap of more than 60 years with no discharges above 300,000 cfs, followed by the last 50 years with at least 5 events above that threshold. \texttt{plotQTimeDaily} requires startYear and endYear, along with some other optional arguements (see \texttt{?plotQTimeDaily} for more details).

\FloatBarrier

%------------------------------------------------------------ 
\subsection{Table Options}
\label{sec:tableOptions}
%------------------------------------------------------------ 
Sometimes it is easier to consider results in table formats rather than graphically. Similar to the function \texttt{plotFlowSingle}, the \texttt{printSeries} will print the requested discharge statistics (Table \ref{table:istat}), as well as return the results in a dataframe. A small sample of the output is printed below.


<<printSeries, eval=FALSE,echo=TRUE>>=
annualSeries<-makeAnnualSeries()
seriesResult <- printSeries(istat=3, qUnit=3)
@

\singlespacing
\begin{verbatim}
Mississippi River at Keokuk Iowa
 Water Year
    30-day minimum
    Thousand Cubic Feet per Second
   year   annual   smoothed
           value    value
   1879     22.6     30.1
   1880     31.7     28.7
   1881     23.0     27.5
...
   2011     51.0     32.4
   2012     34.3     32.1
   2013     16.2     31.8
\end{verbatim}
% \doublespacing


Another way to look at the results is to consider how much the smoothed values change between various pairs of years.  These changes can be represented in four different ways.  
\begin{itemize}
  \item As a change between the first and last year of the pair, expressed in the discharge units selected.
  \item As a change between the first and last year of the pair, expressed as a percentage of the value in the first year
  \item As a slope between the first and last year of the pair, expressed in terms of the discharge units per year.
  \item As a slope between the first and last year of the pair, expressed as a percentage change per year (a percentage based on the value in the first year).
\end{itemize}

Another argument can be very useful in this function: yearPoints.  In the default case, the set of years that are compared are at 5 year intervals along the whole data set.  If the data set was quite long this can be a daunting number of comparisons.  For example, in an 80 year record, there would be 136 such pairs. Instead, we could look at changes between only 3 year points: 1890, 1950, and 2010: 


<<tfc, eval=TRUE,echo=TRUE>>=
annualSeries <- makeAnnualSeries()
tableFlowChange(istat=3, qUnit=3,yearPoints=c(1890,1950,2010))
@

See section \ref{app:createWordTable} for instructions on converting an R dataframe to a table in Microsoft\textregistered\ software. Excel, Microsoft, PowerPoint, Windows, and Word are registered trademarks of Microsoft Corporation in the United States and other countries.

\FloatBarrier


%------------------------------------------------------------ 
\section{Summary of Water Quality Data (without using WRTDS)}
\label{sec:wqa}
%------------------------------------------------------------ 
\FloatBarrier

Before you run the WRTDS model, it is helpful to examine the measured water quality data graphically to better understand its behavior, identify possible data errors, and visualize the temporal distribution of the data (identify gaps).  It is always best to clear up these issues before moving forward.

The examples below use the Choptank River at Greensboro, MD. The Choptank River is a small tributary of the Chesapeake Bay. Inorganic nitrogen (nitrate and nitrite) has been measured from 1979 onward. First, we need to load the discharge and nitrate data into R. Before we can graph or use it for WRTDS analysis, we must bring the discharge data into the Sample dataframe.  We do this by using the \texttt{mergeReport} function which merges the discharge information and also provides a compact report about some major features of the data set.

<<wrtds1,eval=FALSE,echo=TRUE>>=
siteNumber <- "01491000" #Choptank River at Greensboro, MD
startDate <- "1979-10-01"
endDate <- "2011-09-30"
param<-"00631"
Daily <- getNWISDaily(siteNumber,"00060",startDate,endDate)
INFO<- getNWISInfo(siteNumber,param,interactive=FALSE)
INFO$shortName <- "Choptank River"

Sample <- getNWISSample(siteNumber,param,startDate,endDate)
Sample <- mergeReport(Daily, Sample)
@

<<wrtds2,eval=TRUE,echo=FALSE>>=
siteNumber <- "01491000" #Choptank River at Greensboro, MD
startDate <- "1979-10-01"
endDate <- "2011-09-30"
param<-"00631"
Daily <- ChopDaily
Sample <- ChopSample
INFO <- ChopINFO
annualSeries <- makeAnnualSeries()
@


%------------------------------------------------------------ 
\subsection{Plotting Options}
\label{sec:plotOptionsWQ}
%------------------------------------------------------------ 
\FloatBarrier

This section shows examples of the available plots appropriate for analyzing data prior to performing a WRTDS analysis. The plots here use the default variable input options.  For any function, you can get a complete list of input variables in a help file by typing a ? before the function name in the R console. See section \ref{sec:wqVariables} for information on the available input variables for these plotting functions.

Note that for any of the plotting functions that show the sample data, if a value in the data set is a non-detect (censored), it is displayed on the graph as a vertical line.  The top of the line is the reporting limit and the bottom is either zero, or if the graph is plotting log concentration values, or the minimum value on the y-axis.  This line is an \enquote{honest} representation of what we know about that observation and thus we need not become involved in using a statistical model to fill in what we don't know. 

\newpage
\FloatBarrier
<<plotBoxes, echo=TRUE, fig.cap="Concentration box plots",fig.subcap=c("\\texttt{boxConcMonth()}","\\texttt{boxQTwice(qUnit=1)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
boxConcMonth()
boxQTwice(qUnit=1)
@

Note that the statistics to create the boxplot in \texttt{boxQTwice} are performed after the data are log-transformed.

\newpage
\FloatBarrier
<<plotConcTime,echo=TRUE, fig.cap="The relation of concentration vs time or discharge",fig.subcap=c("\\texttt{plotConcTime()}","\\texttt{plotConcQ()}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotConcTime()
plotConcQ(qUnit=1)
@

It is interesting to note in Figure \ref{fig:plotConcTime} the change in the convention for rounding of data values that occurred around 1995.

\newpage
\FloatBarrier
<<plotFluxQ,echo=TRUE, fig.cap="The relation of flux vs discharge",out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotFluxQ(fluxUnit=4)
@

The \texttt{plotFluxQ} (Figure \ref{fig:plotFluxQ}) function only plots in a log-log scale.

\newpage
\FloatBarrier
<<multiPlotDataOverview, echo=TRUE, fig.cap="\\texttt{multiPlotDataOverview(qUnit=1)}",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
multiPlotDataOverview(qUnit=1)
@

The \texttt{multiPlotDataOverview} (Figure \ref{fig:multiPlotDataOverview}) function uses a log scale as default. To change the concentration axes to an arithmetic scale, use logScaleConc=FALSE in the \texttt{multiPlotDataOverview} function call.

\FloatBarrier

%------------------------------------------------------------ 
\subsection{Table Options}
\label{sec:tableOptionsWQ}
%------------------------------------------------------------ 
Another useful tool for checking the data before running the WRTDS estimations is \texttt{flowDuration}. This is a utility function that can help you define the discharge ranges that we want to explore.  It prints out key points on the discharge duration curve.  Define the points for a particular part of the year using the \texttt{"}centerDate\texttt{"} and \texttt{"}span\texttt{"} arguments, although the points can be defined for the entire year (default).  

<<flowDuration, eval=TRUE, echo=TRUE>>=
flowDuration(qUnit=1)

flowDuration(qUnit=1, centerDate="09-30", span=30)
@

\FloatBarrier
%------------------------------------------------------------ 
\section{Weighted Regressions on Time, Discharge and Season (WRTDS)}
\label{sec:wrtds}
%------------------------------------------------------------ 
WRTDS creates a model of the behavior of concentration as a function of three components: time trend, discharge, and season.  You can use WRTDS to estimate annual or seasonal mean concentrations and fluxes as well as describe long-term trends in the behavior of the system. In this section, we will step though the process required for a WRTDS analysis. Section (\ref{sec:wrtdsResults}) provides details about the available methods for viewing and evaluating the model results. 

Once you have looked at your data using the tools described in section \ref{sec:wqa}, and have determined there are sufficient representative data, it is time to run the WRTDS model. Assuming you are using the defaults, with dataframes called Daily, Sample, and INFO, the \texttt{modelEstimation} function runs the WRTDS modeling algorithm:

<<wrtds3, eval=FALSE, echo=TRUE>>=
modelEstimation()
@

Details of the options available when running \texttt{modelEstimation} can be found in Section \ref{sec:wrtdsInputVariables}. This function is slow, and shows the progress in percent complete. See the references and manual for more information. It's important to understand that this is the one function that will globally change your Daily, Sample, and INFO dataframes. It also creates a new matrix \texttt{"}surfaces\texttt{"}, and a new dataframe \texttt{"}AnnualResults\texttt{"}. It is unusual R programming behavior to create global variables, but global variables were chosen to make it easy for you.

Finally, it is a good idea to save your results because of the computational time that has been invested in producing these results. The workspace is saved to a directory that you designate savePath and the file name is determined by the abbreviations for station and constituent that were required entries when the \texttt{getNWISInfo} function was used. The command for saving the workspace is:

<<wrtds5, eval=FALSE, echo=TRUE>>=
savePath <- "C:/Users/egretUser/WRTDS_Output/" #An example directory name
saveResults(savePath) 
@

This saves all of the objects in your workspace. If you have saved workspaces from R versions earlier than 3.0, a warning will appear when you open them in R 3.0 (or later). Re-saving the workspace using R 3.0 (or later) should get rid of the warning.

Using \texttt{saveResults}, the workspace is saved with INFO\$staAbbrev and INFO\$constitAbbrev as the filename (separated by a period), and the extension .RData. So, if staAbbrev was \enquote{Chop} and the constitAbbrev was \enquote{NO3} the file name would be \enquote{Chop.NO3.RData}. To load the data in some future session the commands could be:

<<wrtds8, eval=FALSE, echo=TRUE>>=
loadPath <- "C:/Users/egretUser/WRTDS_Output/"
staAbbrev <- "Chop"
constitAbbrev <- "NO3"
pathToFile <- paste(loadPath,staAbbrev,".",
                    constitAbbrev,".RData",sep="")
load(pathToFile) 
@



\FloatBarrier

%------------------------------------------------------------ 
\section{WRTDS Results}
\label{sec:wrtdsResults}
%------------------------------------------------------------ 
At this point (after having run \texttt{modelEstimation}) we can start considering how to view the annual averages for the variables that have been calculated.  See section \ref{sec:wrtdsOutputVariables} for common input variables for these functions. Additionally, check the help files (in the R console, type ? followed by the function name). 

%------------------------------------------------------------ 
\subsection{Plotting Options}
\label{sec:wrtdsPlotting}
%------------------------------------------------------------ 

\FloatBarrier

Check the help files or manual for more details on the following functions.  See section \ref{app:savingPlots} for information on saving plots. In these examples, we will return to looking at the data in the water year by using the \texttt{setPA} function. Most plotting functions will use the period of analysis information in the INFO dataframe to determine what data are plotted. There are only four graph or table functions that don't allow the user to specify a Period of Analysis (PA). These are: \texttt{plotContour}, \texttt{plotDiffContour}, \texttt{plotConcTimeSmooth}, \texttt{plotConcQSmooth}.


<<getChopData1,echo=FALSE,eval=TRUE>>=
Sample <- ChopSample
Daily <- ChopDaily
INFO <- ChopINFO
surfaces <- exsurfaces
@

\clearpage
<<plotConcTimeDaily, echo=TRUE, fig.cap="Concentration and flux vs time",fig.subcap=c("\\texttt{plotConcTimeDaily(2008, 2010)}","\\texttt{plotFluxTimeDaily(2008, 2010)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
# Return to water year:
INFO <- setPA()

yearStart <- 2008
yearEnd <- 2010

plotConcTimeDaily(yearStart, yearEnd)
plotFluxTimeDaily(yearStart, yearEnd)
@

\clearpage
<<plotFluxPred, echo=TRUE, fig.cap="Concentration and flux predictions",fig.subcap=c('\\texttt{plotConcPred()}','\\texttt{plotFluxPred()}'),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotConcPred()
plotFluxPred()
@

\clearpage
<<plotResidQ, echo=TRUE, fig.cap="Residuals",fig.subcap=c("\\texttt{plotResidPred()}","\\texttt{plotResidQ(qUnit=1)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotResidPred()
plotResidQ(qUnit=1)
@

\clearpage
<<boxResidMonth, echo=TRUE, fig.cap="Residuals with respect to time",fig.subcap=c("\\texttt{plotResidTime()}","\\texttt{boxResidMonth()}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotResidTime()
boxResidMonth()
@

\clearpage
<<boxConcThree, echo=TRUE, fig.cap="Default \\texttt{boxConcThree()}",out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='asis',results='hide',fig.pos="h">>=
boxConcThree()
@

\clearpage
<<plotFluxHist, echo=TRUE, fig.cap="Concentration and flux history",fig.subcap=c("\\texttt{plotConcHist()}", "\\texttt{plotFluxHist()}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotConcHist()
plotFluxHist()
@

\clearpage

Figures \ref{fig:plotConcQSmooth} and \ref{fig:plotConcTimeSmooth} contain legends. The placement of the legend is controlled by legendLeft and legendTop. If both are set to 0 (the default values), the legend is placed near the lower left corner of the graphic. Otherwise, the value specified for legendLeft places the left edge of the legend, and legendTop specifies the top edge of the legend. The units for legendLeft and legendTop are discharge (in units specified by qUnit) and concentration, respectively. The legend can also be turned off with printLegend=FALSE. These are also functions that do not recognize the period of analysis in the INFO data frame. However, by choosing centering dates and appropriate half-windows, seasonal behavior can easily be observed in these plots. 

<<plotConcQSmooth, echo=TRUE, fig.cap="Concentration vs. discharge",fig.subcap=c("\\texttt{plotConcQSmooth}","\\texttt{plotConcQSmooth(logScale=TRUE)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
qBottom<-20
qTop<-700
date1 <- "2000-09-01"
date2 <- "2005-09-01"
date3 <- "2009-09-01"
plotConcQSmooth(date1, date2, date3,
                qBottom, qTop, qUnit=1)
plotConcQSmooth(date1, date2, date3,
                qBottom, qTop, qUnit=1,logScale=TRUE)
@

\clearpage
<<plotConcTimeSmooth, echo=TRUE, fig.cap="\\texttt{plotConcTimeSmooth())}",fig.subcap=c("\\texttt{plotConcTimeSmooth}","\\texttt{plotConcTimeSmooth(logScale=TRUE)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',results='hide',fig.pos="h">>=
q1 <- 10
q2 <- 25
q3 <- 75
centerDate <- "07-01"
plotConcTimeSmooth(q1, q2, q3, centerDate, 2000, 2010)
plotConcTimeSmooth(q1, q2, q3, centerDate, 
                   2000, 2010,logScale=TRUE)
@

Figure \ref{fig:fluxBiasMulti} shows a predefined multipanel graph using \texttt{fluxBiasMulti}.

<<fluxBiasMulti, echo=TRUE, fig.cap="\\texttt{fluxBiasMulti(qUnit=1)}",fig.show='asis',fig.width=8, fig.height=10,fig.pos="h">>=
fluxBiasMulti(qUnit=1)
@

\clearpage

The contour plot functions also do not recognize the PA from the INFO dataframe. They represent the overall results of the WRTDS analysis. To specify contourLevels in the contour plots use the \texttt{seq} function (type \texttt{?seq} for details).  In general, use of the \texttt{seq} function would look like this: \texttt{contourLevels = seq(from,to,by)}.  In the example shown above we are requesting contour levels that run from 0 to 2 in steps of 0.2.


<<plotContours, echo=TRUE,fig.cap="plotContours()",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
clevel<-seq(0,2,0.2)
plotContours(yearStart=2008,yearEnd=2010,qBottom=20,qTop=1000, 
             contourLevels = clevel,qUnit=1,
             flowDuration=FALSE)
@

\clearpage

The function \texttt{plotDiffContours} plots the difference between two selected years (year0 and year1). It can help clarify what combinations of seasons and flow conditions have been showing increases and decreases over the period covered.


<<plotDiffContours, echo=TRUE, fig.cap="plotDiffContours()",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
plotDiffContours(year0=2000,year1=2010,
                 qBottom=20,qTop=1000,maxDiff=0.6,qUnit=1,
             flowDuration=FALSE)
@

\clearpage

%------------------------------------------------------------ 
\subsection{Table Options}
\label{sec:wrtdsTable}
%------------------------------------------------------------ 
Sometimes it is easier to consider the results in table form rather than graphically. The function \texttt{tableResults} produces a simple text table that contains the annual values for the results.  Each row of the output represents a year and includes: year, average discharge, average concentration, flow-normalized concentration, average flux, and flow-normalized flux.  A small sample of the output is printed below. This function can also return a data frame if returnDataFrame is set to TRUE.

<<tableResults1, echo=TRUE, eval=FALSE>>=
tableResults()
returnDF <- tableResults(returnDataFrame=TRUE)
@

\singlespacing
\begin{verbatim}
   Choptank River 
   Inorganic nitrogen (nitrate and nitrite)
   Water Year 

   Year   Discharge    Conc    FN_Conc     Flux    FN_Flux
             cms            mg/L             10^6 kg/yr 
   1980      4.25     0.949     1.003    0.1154     0.106
   1981      2.22     1.035     0.999    0.0675     0.108
...
   2010      7.19     1.323     1.438    0.2236     0.149
   2011      5.24     1.438     1.457    0.1554     0.148
\end{verbatim}
% \doublespacing

<<tableResults2, echo=FALSE, eval=TRUE,results='hide'>>=
returnDF <- tableResults(returnDataFrame=TRUE)
@

<<tableResultshead, echo=FALSE, results='asis'>>=
print(xtable(head(returnDF),
       label="table:tableChangeHead",
       caption="Table created from \\texttt{head(returnDF)}",
       digits=c(0,0,2,3,3,3,3)),
       caption.placement="top",
       size = "\\footnotesize",
       latex.environment=NULL,
       sanitize.text.function = function(x) {x},
       sanitize.colnames.function =  bold.colHeaders,
       sanitize.rownames.function = addSpace
      )
@


The other table option is \texttt{tableChange}. This is a function that provides for the computation of changes or slopes between any selected pairs of time points.  These computations are made only on the flow-normalized results. A detailed explaination of \enquote{flow-normalized} result is in the official EGRET manual.


<<tableChange1, eval=TRUE, echo=TRUE>>=
tableChange(yearPoints=c(2000,2005,2010))
@

Finally, \texttt{tableChangeSingle} (Table \ref{table:tableChangeSingle}) operates exactly the same as \texttt{tableChange} except for the addition of two arguments: returnDataFrame and flux. This function provides either concentration results or flux results, but not both.  This can be useful when you are producing many output tables for a report that is entirely focused on concentration or one that is entirely focused on flux.  The arguments are identical to those for tableChange, except for the final two arguments.  The first, \texttt{"}returnDataFrame\texttt{"} is a logical argument to indicate if a dataframe of output should be returned (for later manipulation or printing through other programs such as Excel), and its default is FALSE.  The second argument is \texttt{"}flux\texttt{"}, and the default is TRUE.  When flux=TRUE the output is only for flux, and when flux=FALSE the output is only for concentration.  See section \ref{app:createWordTable} for instructions on converting an R dataframe to a table in Microsoft\textregistered\ software.

<<tableChangeSingleR, eval=TRUE, echo=TRUE,results='hide'>>=
returnDF <- tableChangeSingle(yearPoints=c(2000,2005,2010), 
                              returnDataFrame=TRUE)
@

<<tableResultsShow, echo=FALSE, results='asis'>>=
print(xtable(returnDF,
       label="tableChangeSingle",
       caption="Table created from \\texttt{tableChangeSingle} function",
       digits=c(0,0,0,3,2,1,1)),
       caption.placement="top",
       size = "\\footnotesize",
       latex.environment=NULL,
       sanitize.text.function = function(x) {x},
       sanitize.colnames.function =  bold.colHeaders,
       sanitize.rownames.function = addSpace
      )
@


% \begin{table}[ht]
% {\footnotesize
% \begin{tabular}{rrrrrrr}
%   \hline
% \multicolumn{1}{c}{\textbf{\textsf{Year1}}} &
% \multicolumn{1}{c}{\textbf{\textsf{Year2}}} &
% \multicolumn{1}{c}{\textbf{\textsf{change [mg/L]}}} &
% \multicolumn{1}{c}{\textbf{\textsf{slope [mg/L/yr]}}} &
% \multicolumn{1}{c}{\textbf{\textsf{change[\%]}}} &
% \multicolumn{1}{c}{\textbf{\textsf{slope [\%/yr]}}} \\ 
%   \hline
% 2000 & 2005 & 0.09 & 0.02 & 7.00 & 1.40 \\ 
% [5pt]2000 & 2010 & 0.19 & 0.02 & 15.00 & 1.50 \\ 
% [5pt]2005 & 2010 & 0.10 & 0.02 & 7.30 & 1.50 \\ 
%    \hline
% \end{tabular}
% \caption{Table created from \texttt{tableChangeSingle} function using Microsoft Excel (see section \ref{app:createWordTable})} 
% \label{table:tableChangeSingle}
% }
% \end{table}


\clearpage


%------------------------------------------------------------ 
\section{Extending Plots Past Defaults}
\label{sec:extendedPlots}
%------------------------------------------------------------ 

The basic plotting options were shown in the section \ref{sec:wrtdsResults}.  This section demonstrates some ways to extend the capabilities of the EGRET plots. EGRET plots use R's basic plotting options. You set many of the formatting details of plotting routines in R by using \enquote{Graphical Parameters}.  To read about all of these graphical parameters see \texttt{?par}.  When the graphical functions in EGRET are coded, a set of default values for many of these parameters are chosen, but you can override all of these default values. Additionally, you can add features to a plot after calling the plot function. To change the plot margins (mar), font, or other graphical parameters initially assigned, set the argument customPar to TRUE.

A few of R's base graphical parameters are especially useful within the plot functions. These are shown in Table \ref{table:tableChangeSingle}.

\begin{table}[ht]
{\footnotesize
\begin{tabular}{rrr}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}} &
\multicolumn{1}{c}{\textbf{\textsf{Values}}}  \\ 
  \hline
cex &  Size of data point symbols, relative to default & decimal number \\ 
[5pt]cex.main & Size of font for plot title, relative to default & decimal number \\ 
[5pt]cex.lab &  Size of font for axis label text, relative to default & decimal number \\ 
[5pt]cex.axis & Size of font for axis annotation (numbers), relative to default & decimal number\\
[5pt]col & Color of data point symbols or lines & color name in \texttt{"}\texttt{"} \\
[5pt]lwd & Width of lines, relative to default & decimal number\\
[5pt]pch & Type of symbol to use for data points & integer values\\
[5pt]lty & Line type number (such as dash or dot) & integer values\\
   \hline
\end{tabular}
\caption{Useful plotting parameters to adjust in EGRET plotting functions.  For details of any of these see ?par.} 
\label{table:tableChangeSingle}
}
\end{table}

After the plot is made, many other functions that might be useful to call, such as to add text, legend, lines, etc. Table \ref{table:addOns} lists a few common options.

\begin{table}[ht]
{\footnotesize
\begin{tabular}{rr}
  \hline
\multicolumn{1}{c}{\textbf{\textsf{Function}}} &
\multicolumn{1}{c}{\textbf{\textsf{Description}}}  \\ 
  \hline
mtext & add text based on specified side of plot\\
[5pt]text & add text to a specific point on plot\\
[5pt]legend & add a legend \\ 
[5pt]grid & add grid\\ 
[5pt]abline & add line \\
[5pt]arrows & add arrow \\ 
   \hline
\end{tabular}
\caption{Useful functions to add on to default plots. Type ? then the function name to get help on the individual function.} 
\label{table:addOns}
}
\end{table}

Some basic examples are shown below.

Figure \ref{fig:adjustSize} shows a larger title and axis number (left), and larger axis labels and point size (right).
<<adjustSize,echo=TRUE,eval=TRUE,fig.cap="Modifying text and point size", fig.subcap=c("\\texttt{plotConcQ(cex.axis=2,cex.main=1.5,logScale=TRUE)}","\\texttt{plotConcQ(cex.lab=2,cex=2,logScale=TRUE)}"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotConcQ(cex.axis=2,cex.main=1.5,logScale=TRUE)
plotConcQ(cex.lab=2,cex=2,logScale=TRUE)
@

\clearpage

Figure \ref{fig:plotConcQComparison} shows the default on the left, and several features on the right. First, the margin is adjusted to c(8,8,8,8), requiring customPar set to TRUE. The margin vector represents the margin spacing of the 4 \texttt{"}sides\texttt{"} of a plot in the order: bottom, left, top, right. Next, the text labels were adjusted, color set to \texttt{"}blue\texttt{"}, point and line size increased, and the point type changed form a solid circle(pch=20) to solid diamond (pch=18). A grid, legend, arrow, and text are added after the plot is produced.
<<plotConcQComparison,echo=TRUE,eval=TRUE,fig.cap="Modified plotConcQ", fig.subcap=c("Default","Modified"),out.width='.5\\linewidth',out.height='.5\\linewidth',fig.show='hold',fig.pos="h">>=
plotConcQ(logScale=TRUE)
par(mar=c(8,8,8,8))
plotConcQ(customPar=TRUE,col="blue",cex=1.1,
          cex.axis=1.4,cex.main=1.5,cex.lab=1.2,
          pch=18,lwd=2,logScale=TRUE)
grid(lwd=2)
legend(4.5,.09,"Choptank Nitrogen", pch=18, col="blue",bg="white")
arrows(3, 0.14, 1, .05,lwd=2)
text(12,.14,"Censored Value")
@

\clearpage

Only a few fonts are consistent on all operating systems. Figure \ref{fig:easyFontChange} shows how to change to the Serif font, as well as how to use the mtext function. To see the available fonts for pdf output on your computer, type \texttt{names(pdfFonts())}.The available fonts are quite limited in base R. To expand the font choices, a useful R library, \enquote{extrafont} can help.

<<easyFontChange,echo=TRUE,eval=TRUE,fig.cap="Serif font",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth', fig.pos="h">>=
# Switching to serif font:
par(family="serif")
plotFluxPred(customPar=TRUE)
mtext(side=3,line=-3,"Serif font example",cex=3)
@

\clearpage

You can also extend the contour plots. The default y-axis is determined from qTop and qBottom. Occasionally, you may need to use a custom axis by specifying yTicks. It is also nice to be able to adjust the color scheme of the contour plots. There are some color schemes built into base R such as heat.colors, topo.colors, terrain.colors, and cm.colors. Alternatively, you can set colors by using the \texttt{colorRampPalette} function. For example, a black and white color scheme might be required. In another example, the \texttt{plotDiffContours} might make more sense to go from yellow to white for the negative values, and white to blue for the positive values. Examples are shown below for modifying a contour plot in Figure \ref{fig:modifiedContour1} and modifying a difference contour plot in Figure \ref{fig:modifiedDiffContour}. 

\clearpage

<<modifiedContour1,echo=TRUE,eval=TRUE,fig.cap="Contour plot with modified axis and color scheme",fig.show='hold',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
colors <- colorRampPalette(c("white","black"))
yTicksModified <- c(.5,1,10,25)
plotContours(2001,2010,0.5,50, 
             contourLevels = seq(0,2.5,0.5),qUnit=2,
             yTicks=yTicksModified,
             color.palette=colors,
             flowDuration=FALSE,
             tcl=0.2,tick.lwd=2.5)  
@

\clearpage

<<modifiedDiffContour,echo=TRUE,eval=TRUE,fig.cap="Difference contour plot with modified color scheme",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
colors <- colorRampPalette(c("yellow","white","blue"))
maxDiff<-0.6
par(oma=c(1,1,1,1))
plotDiffContours(year0=2001,year1=2010,qBottom=0.5,qTop=50, 
             maxDiff,lwd=2,qUnit=2,
             color.palette=colors,
             flowDuration=FALSE, customPar=TRUE)
@


\clearpage

It is also possible to create custom multi-panel plots. In the simplest example (figure \ref{fig:tinyPlot1}), you can use the \texttt{"tinyPlot=TRUE"} option.

<<tinyPlot1,echo=TRUE,eval=TRUE,fig.cap="Custom multipanel plot using tinyPlot",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
par(mfcol = c(2, 2), oma = c(0, 1.7, 6, 1.7))

plotFluxQ(tinyPlot=TRUE,printTitle=FALSE,
          fluxUnit=9,logScale=FALSE,fluxMax=1)
plotConcQ(tinyPlot=TRUE,printTitle=FALSE)
plotFluxHist(tinyPlot=TRUE,printTitle=FALSE,fluxMax=1)
plotConcHist(tinyPlot=TRUE,printTitle=FALSE,concMax=3)
mtext("Custom multi-pane graph using tinyPlot=TRUE", outer=TRUE, font=2)
@

\clearpage

Finally, figure \ref{fig:customPanel} shows a method to create a panel of plots with a finer control.


<<customPanel,echo=TRUE,eval=TRUE,fig.cap="Custom multipanel plot",fig.show='asis',out.width='1\\linewidth',out.height='1\\linewidth',fig.pos="h">>=
par(mar=c(3.5,3.5,0.2,0.2), # whitespace around the plots
    oma=c(1,1,3,1), # outer margin
    mgp=c(2,0.5,0), # spacing between the label numbers and plots
    mfcol = c(2,2)) # rows/columns

plotFluxQ(tinyPlot=TRUE,printTitle=FALSE,
          fluxUnit=9,logScale=FALSE,fluxMax=1,
          showXLabels=FALSE,showXAxis=FALSE, 
          showYLabels=TRUE,customPar=TRUE)

plotConcQ(tinyPlot=TRUE,printTitle=FALSE, customPar=TRUE,
          removeLastY=TRUE,removeLastX=TRUE,
          showYLabels=TRUE)

plotFluxHist(tinyPlot=TRUE,printTitle=FALSE,fluxMax=1,
          showYLabels=FALSE,showYAxis=FALSE,
          showXLabels=FALSE,showXAxis=FALSE, customPar=TRUE)
plotConcHist(tinyPlot=TRUE,printTitle=FALSE,concMax=3,
          showYLabels=FALSE, showYAxis=FALSE, customPar=TRUE)
mtext("Custom multi-pane graph using customPar", outer=TRUE, font=2)
@


\clearpage

%------------------------------------------------------------ 
\section{Getting Started in R}
\label{sec:appendix1}
%------------------------------------------------------------ 
This section describes the options for installing the EGRET package.

%------------------------------------------------------------
\subsection{New to R?}
%------------------------------------------------------------ 
If you are new to R, you will need to first install the latest version of R, which can be found here: \url{http://www.r-project.org/}.

At any time, you can get information about any function in R by typing a question mark before the function's name.  This opens a file that describes the function, the required arguments, and provides working examples.

<<helpFunc,eval = FALSE>>=
?getJulian
@

To see the raw code for a particular function, type the name of the function, without parentheses:
<<rawFunc,eval = FALSE>>=
getJulian
@


%------------------------------------------------------------
\subsection{R User: Installing EGRET}
%------------------------------------------------------------ 
To install the EGRET packages and its dependencies:

<<installFromCran,eval = FALSE>>=
install.packages(c("dataRetrieval","EGRET"), 
repos=c("http://usgs-r.github.com","http://cran.us.r-project.org"),
dependencies=TRUE,
type="both")
@

It is a good idea to re-start R after installing the package if installing an updated version. 

After installing the package, you need to open the library each time you re-start R.  This is done with the simple command:
<<openLibraryTest, eval=FALSE>>=
library(dataRetrieval)
library(EGRET)
@

\newpage
\FloatBarrier
%------------------------------------------------------------ 
\section{Common Function Variables}
\label{sec:appendixPlot}
%------------------------------------------------------------ 
This section describes variables that are common for a variety of function types. 

%------------------------------------------------------------ 
\subsection{flowHistory Plotting Input}
\label{sec:flowHistoryVariables}
%------------------------------------------------------------
\begin{table}[ht]
{\footnotesize
  \begin{threeparttable}[b]
\caption{Variables used in flow history plots (\texttt{plot15}, \texttt{plotFour}, \texttt{plotFourStats}, \texttt{plotQTimeDaily}, \texttt{plotSDLogQ}) 
\label{tab:flowHistoryVariables}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Default}}} \\
\hline
istat & The discharge statistic to be plotted: 1-8.  Must be specified, see Table \ref{table:istat}. & \\
yearStart\tnote{1} & The decimal year (decYear) value where you want the graph to start & NA\\
yearEnd\tnote{1} & The decimal year (decYear) value where you want the graph to end & NA\\
qMax & User specified upper limit on y axis (can be used when we want several graphs to all share the same scale). Value is specified in the discharge units that the user selects. & NA\\
printTitle & can be TRUE or FALSE, you may want FALSE if it is going to be a figure with a caption or if it is a part of a multipanel plot. & TRUE\\
tinyPlot & Can be TRUE or FALSE, the TRUE option assures that there will be a small number of tick marks, consistent with printing in a small space & FALSE\\
runoff & Can be TRUE or FALSE.  If true then discharge values are reported as runoff in mm/day.  This can be very useful in multi-site analyses. & FALSE\\
qUnit & An index indicating what discharge units to use.  Options run from 1 to 6 (see section \ref{sec:units}).  The choice should be based on the units that are customary for the audience but also, the choice should be made so that the discharge values don't have too many digits to the right or left of the decimal point. & 1\\
printStaName\tnote{2} & Can be TRUE or FALSE, if TRUE the name of the streamgage is stated in the plot title. & TRUE\\
printPA\tnote{2} & Can be TRUE or FALSE, if TRUE the period of analysis is stated in the plot title. & TRUE\\
printIstat\tnote{2} & Can be TRUE or FALSE, if TRUE the name of the statistic (e.g. 7-day minimum discharge) is stated in the plot title. & TRUE\\

\hline
\end{tabularx}
  \begin{tablenotes}
    \item[1] Setting yearStart and yearEnd will determine where the graphs start and end, but they don't determine where the smoothing analysis starts and ends.  There are situations, typically where many sites are be analyzed together, where you may want to run the smoothing on a consistent period of record across all sites, which requires subsetting the Daily data frame before running \texttt{makeAnnualSeries} (see \texttt{?subset}).
    \item[2] If the printTitle argument is set to FALSE, then it really makes no difference what you do with printSta, printPA, or printIstat.  They can all be left as their default values and thus there is no need to include them in the call for the function.
  \end{tablenotes}
 \end{threeparttable}
}
\end{table}

\FloatBarrier
\clearpage

%------------------------------------------------------------ 
\subsection{Water Quality Plotting Input}
\label{sec:wqVariables}
%------------------------------------------------------------

\begin{table}[ht]
{\footnotesize
\caption{Selected variables used in water quality analysis plots  \label{tab:wqVariables}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Default}}} \\
\hline
qUnit & Determines what units will be used for discharge, see section \ref{sec:units} & 2\\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption) & TRUE\\
qLower & The lower bound on the discharge on the day of sampling that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in the units specified in qUnit.  If qLower = NA, then the lower bound is set to zero. & \\
qUpper & The upper bound on the discharge on the day of sampling that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in the units specified in qUnit.  If qUpper = NA, then the upper bound is set to infinity. & \\
% paLong & The length of the time period that will be used in forming a subset of the sample data set that will be displayed in the graph, expressed in months. & 12\\ 
% paStart & The starting month for the time period that will be used in forming a subset of the sample data set that will be displayed in the graph.  It is expressed in months (calendar months). & 10\\
concMax & The upper limit on the vertical axis of graphs showing concentration values in mg/L (NA sets value to just above maximum).  & NA\\
concMin & The lower limit on the vertical axis of graphs showing concentration values in mg/L (NA sets value to just below minimum for log scales, zero for linear). & NA\\
fluxUnit & Determines what units will be used for flux (see Section \ref{sec:units}). & 9\\
fluxMax & The upper limit on the vertical axis of graphs showing flux values. & \\
\hline
\end{tabularx}
}
\end{table}

\FloatBarrier
\clearpage


%------------------------------------------------------------ 
\subsection{WRTDS Estimation Input}
\label{sec:wrtdsInputVariables}
%------------------------------------------------------------
\begin{table}[ht]
{\footnotesize
\caption{Selected variables in WRTDS  \label{tab:WRTDS}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Default}}} \\
\hline
windowY & The half window width for the time weighting, measured in years.  Values much shorter than 7 usually result in a good deal of oscillations in the system that are likely not very realistic & 7\\
windowQ & The half window width for the weighting in terms of ln(Q).  For very large rivers (average discharge values in the range of many tens of thousands of cfs) a smaller value than 2 may be appropriate, but probably not less than 1 & 2 \\
windowS & The half window width for the seasonal weighting, measured in years.  Any value \texttt{>}0.5 will make data from all seasons have some weight.  Values should probably not be lower than 0.3 & 0.5 \\
minNumObs & This is the minimum number of observations with non-zero weight that the individual regressions will require before they will be used.  If there too few observations the program will iterate, making the windows wider until the number increases above this minimum.  The only reason to lower this is in cases where the data set is rather small.  It should always be set to a number at least slightly smaller than the sample size.  Any value less than about 60 is probably in the \enquote{dangerous} range, in terms of the reliability of the regression & 100 \\ 
minNumUncen & This is the minimum number of uncensored observations with non-zero weight that the individual regressions will require before they will be used.  If there are too few uncensored observations the program will iterate, making the windows wider until the number increases above this minimum.  The only reason to lower this is in cases where the number of uncensored values is rather small.  The method has never been tested in situations where there are very few uncensored values & 50 \\
\hline
\end{tabularx}
}
\end{table}

\FloatBarrier
\clearpage

%------------------------------------------------------------ 
\subsection{WRTDS Plotting Input}
\label{sec:wrtdsOutputVariables}
%------------------------------------------------------------

\begin{table}[ht]
{\footnotesize
\caption{Selected variables used in plots for analysis of WRTDS results 
\label{tab:wrtdsVariables}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Default}}} \\
\hline
qUnit & Determines what units will be used for discharge, see section \ref{sec:units} & 2\\
fluxUnit & An index indicating what flux units will be used , see section \ref{sec:units} & 3\\
stdResid & This is an option.  If FALSE, it prints the regular residuals (they are in ln concentration units).  If TRUE, it is the standardized residuals.  These are the residuals divided by their estimated standard error (each residual has its own unique standard error).  In theory, the standardized residuals should have mean zero and standard deviation of 1 & FALSE\\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption) & TRUE\\
startYear & The starting date for the graph, expressed as decimal years, for example, 1989 & NA\\
endYear & The ending date for the graph, expressed as decimal years, for example, 1996 & NA\\
moreTitle & A character variable that adds additional information to the graphic title.  Typically used to indicate the estimation method.\\
fluxMax & The upper limit on the vertical axis of graphs showing flux values. & NA\\
concMax & The upper limit on the vertical axis of graphs showing concentration values. & NA\\
plotFlowNorm & If TRUE the graph shows the annual values as circles and the flow-normalized values as a green curve.  If false, it only shows the annual values. & TRUE\\
\hline
\end{tabularx}
}
\end{table}

\begin{table}[ht]
{\footnotesize
\caption{Variables used in WRTDS contour plots: \texttt{plotContours} and \texttt{plotDiffContours} \label{tab:wrtdsContourVariables}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Defaults}}}\\
\hline
qUnit & Determines what units will be used for discharge, see section \ref{sec:units} & 2\\
qBottom & The lower limit of the discharge value for the graphs in the units specified by qUnit &\\
qTop & The upper limit of the discharge value for the graphs in the units specified by qUnit &\\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption) & TRUE \\
yearStart & The starting date for the graph, expressed as decimal years, for example, 1989 & \\
yearEnd & The ending date for the graph, expressed as decimal years, for example, 1996 & \\
whatSurface & This should generally be at its default value.  At whatSurface = 3, the plotted surface shows the expected value of concentration.  For whatSurface = 1, it shows the yHat surface (natural log of concentration).  For whatSurface = 2, it shows the SE surface (the standard error in log concentration). & 3\\
contourLevels & With the default value the contour intervals are set automatically, which generally will NOT be a very good choice, but they may provide a starting point.  If you want to specify contourLevels, use the \texttt{seq} function.  In general it would look like: contourLevels = seq(from,to,by). & NA\\
maxDiff & In the \texttt{plotDiffCountours} function instead of using contourLevels, the contours are set by maxDiff which is the absolute value of the maximum difference to be plotted.  Contour intervals are set to run from -maxDiff to maxDiff. &\\
span & Specifies the smoothness of the discharge duration information that goes on this graph.  A larger value will make it smoother.  The default should work well in most cases. & 60\\
pval & The probability value for the discharge frequency information shown on the plot.  When flowDuration=TRUE, the plot has two black curves on it.  In the default value case these are at the 5 and 95 percent levels on the seasonal discharge duration curve.  pval = 0.01 would place these at the 1 and 99 percent points.  pval = 0.1 would place them at 10  and 90. & 0.05\\
vert1 & This simply plots a vertical black line on the graph at a particular time (defined in decimal years).  It is used to illustrate the idea of a \enquote{vertical slice} through the contour plot, which might then be shown in a subsequent use of \texttt{plotConcQSmooth}. & NA  \\
vert2 & This gives the location of a second vertical black line on the graph at a particular time (defined in decimal years). & NA\\
horiz & This simply plots a horizontal black line on the graph at a particular discharge value (defined in the units specified by qUnit).  It is used to illustrate the idea of the seasonal cycle in concentrations for a given discharge and the long-term change in this cycle.  & NA\\
flowDuration & If TRUE it draws the discharge duration lines at the specified probabilities.  If FALSE, the discharge duration lines are left off. & TRUE\\
\hline
\end{tabularx}
}
\end{table}


\begin{table}[ht]
{\footnotesize
\caption{Variables used in WRTDS \texttt{plotConcQSmooth} and/or \texttt{plotConcTimeSmooth} functions \label{tab:wrtdsMultiVariables}}
\begin{tabularx}{\textwidth}{lXl}
\hline
\multicolumn{1}{c}{\textbf{\textsf{Argument}}} &
\multicolumn{1}{c}{\textbf{\textsf{Definition}}} &
\multicolumn{1}{c}{\textbf{\textsf{Default}}}\\
\hline
date1 & This is the date for the first curve to be shown on the \texttt{plotConcQSmooth} graph.  It must be in the form \texttt{"}yyyy-mm-dd\texttt{"} (it must be in quotes) &\\
date2 & This is the date for the second curve to be shown on the plot (\texttt{"}yyyy-mm-dd\texttt{"}), If you don't want a second curve then the argument must be date2=NA &\\
date3 & This is the date for the third curve to be shown on the plot (\texttt{"}yyyy-mm-dd\texttt{"}), If you don't want a third curve then the argument must be date3=NA &\\
q1 & This is the discharge for the first curve on the \texttt{plotConcTime} smooth graph. It is in units specified by qUnit &\\
q2 & This is the discharge for the second curve. If you don't want a second curve then the argument must be q2=NA &\\
q3 & This is the discharge for the third curve. If you don't want a third curve then the argument must be q3=NA &\\
qUnit & Determines what units will be used for discharge, see \texttt{printqUnitCheatSheet} & 2\\
qLow & The discharge value that should form the left edge of the plotConcQSmooth graph in the user-selected discharge units. & \\
qHigh & The discharge value that should form the right edge of the \texttt{plotConcQSmooth} graph in the user-selected discharge units. & \\
centerDate & This is the month and day at the center of the time window for the \texttt{plotConcTimeSmooth} graph. It must be in the form \texttt{"}mm-dd\texttt{"} in quotes &\\
yearStart & The starting year for the \texttt{plotConcTimeSmooth} graph &\\
yearEnd & The ending year for the \texttt{plotConcTimeSmooth} graph &\\

legendLeft & This determines the placement of the legend on the graph.  It establishes the left edge of the legend and is expressed in the discharge units being used.  The default (which is NA) will let it be placed automatically.  The legend can end up conflicting with one or more of the curves.  Once the location of the curves is established then this can be set in a way that avoids conflict. & 0\\
legendTop & This determines the placement of the legend on the graph.  It establishes the top edge of the legend and is expressed according to the concentration values on the y-axis.  The default (which is NA) will let it be placed automatically.  The legend can end up conflicting with one or more of the curves.  Once the location of the curves is established then this can be set in a way that avoids conflict. & 0\\
concMax & Maximum value for the vertical axis of the graph.  The reason to set concMax is if you want to make several plots that have the same vertical axis. & NA\\
concMin & [This one is only used when logScale=TRUE].  Minimum value for the vertical axis of the graph. The reason to set concMin is if you want to make several plots that have the same vertical axis. & NA\\
bw & Default is FALSE, which means we want a color plot.  If bw=TRUE that means it should be black and white.\\
printTitle & If TRUE the plot has a title.  If FALSE no title (useful for publications where there will be a caption). & FALSE\\
printValues & If TRUE the estimated values that make up the plotted lines are printed on the console.  If FALSE they are not printed.  This could be useful if you wanted to compute various comparisons across time periods. & FALSE\\
windowY & This is the half-window width for time in WRTDS.  It has units of years.  & 7 \\
windowQ & This is the half-window width for discharge in WRTDS.  It has units of ln(discharge).  & 2 \\
windowS & This is the half-window width for seasons in WRTDS.  It has units of years.  & 0.5 \\
\hline
\end{tabularx}
}
\end{table}

\FloatBarrier


%------------------------------------------------------------ 
\section{Creating tables in Microsoft\textregistered\ software from an R dataframe}
\label{app:createWordTable}
%------------------------------------------------------------
A few steps that are required to create a table in Microsoft\textregistered\ software (Excel, Word, PowerPoint, etc.) from an R dataframe. There are a variety of good methods, one of which is detailed here. The example we will step through is creation of a table in Microsoft\textregistered\ Excel based on the dataframe tableData:

<<label=getSiteApp, echo=TRUE,eval=FALSE>>=

tableData <- tableResults(returnDataFrame=TRUE)
@

<<label=getSiteApp2, echo=FALSE,eval=TRUE>>=

tableData <- tableResults(returnDataFrame=TRUE)
@

First, save the dataframe as a tab delimited file (you don't want to use comma delimited because there are commas in some of the data elements):


<<label=saveData, echo=TRUE, eval=FALSE>>=
write.table(tableData, file="tableData.tsv",sep="\t", 
            row.names = FALSE,quote=FALSE)
@

This will save a file in your working directory called tableData.tsv.  You can see your working directory by typing getwd() in the R console. Opening the file in a general-purpose text editor, you should see the following:

\singlespacing
\begingroup
    \fontsize{8pt}{10pt}
\begin{verbatim}
Year  Discharge [cms]	Conc [mg/L]	FN_Conc [mg/L]	Flux [10^6kg/yr]	FN_Flux [10^6kg/yr]
1980	   4.25	           0.949	      1.003	         0.1154	            0.106  
1981	   2.22	           1.035	      0.999	         0.0675	            0.108 
1982	   3.05	           1.036	      0.993	         0.0985	            0.110 
...
\end{verbatim}
\endgroup
% \doublespacing

Next, follow the steps below to open this file in Excel:
\begin{enumerate}
\item Open Excel
\item Click on the File tab
\item Click on the Open option
\item Navigate to the working directory (as shown in the results of getwd())
\item Next to the File name text box, change the dropdown type to All Files (*.*)
\item Double click tableData.tsv
\item A text import wizard will open up, in the first window, choose the Delimited radio button if it is not automatically picked, then click on Next.
\item In the second window, click on the Tab delimiter if it is not automatically checked, then click Finished.
\item Use the many formatting tools within Excel to customize the table
\end{enumerate}

From Excel, it is simple to copy and paste the tables in other word processing or presentation software products. An example using one of the default Excel table formats is here.

\begin{figure}[ht!]
\centering
 \resizebox{0.9\textwidth}{!}{\includegraphics{table1.png}} 
\caption{A simple table produced in Microsoft\textregistered\ Excel}
\label{overflow}
\end{figure}

\FloatBarrier

%------------------------------------------------------------ 
\section{Saving Plots}
\label{app:savingPlots}
%------------------------------------------------------------
Plots can be saved from R as JPG, PNG, PDF, and Postscript files. JPG and PNG are easy to use in any number of programs (Microsoft\textregistered\ Word or PowerPoint, for example), but the images cannot be resized later. PDF and Postscript images are easily re-sizable.

There are three steps to saving plots. The first is to open the \enquote{device} (and declare the output type and file name). The second step is to execute the function just as you would when plotting to the screen, but no output will appear. The third step is to turn off the device. It is also possible to put many plots within the same pdf.  Some simple examples should demonstrate this easily:

<<label=savePlots, echo=TRUE, eval=FALSE>>=
jpeg("plotFlowSingle.jpg")
plotFlowSingle(1)
dev.off()

png("plotFlowSingle.png")
plotFlowSingle(1)
dev.off()

pdf("plotFlowSingle.pdf")
plotFlowSingle(1)
dev.off()

postscript("plotFlowSingle.ps")
plotFlowSingle(1)
dev.off()

#Many plots saved to one pdf:
pdf("manyPlots.pdf")
plotFlowSingle(1)
plotFlowSingle(2)
plotFlowSingle(3)
plotFlowSingle(4)
dev.off()

@

There are many additional options for each of these devices. See the R help files for more information. One useful option for the larger \texttt{fluxBiasMulti} graph is to adjust the height and width of the output. The output of fluxBiasMulti is larger than the default pdf or postscript devices. Therefore, specifying the height and width eliminates R having to re-size the graphic:

<<label=savePlots2, echo=TRUE, eval=FALSE>>=
postscript("fluxBiasMulti.ps", height=10,width=8)
fluxBiasMulti()
dev.off()
@


\clearpage

%-------------------------------------
\section{Disclaimer}
%------------------------------------
This information is preliminary and is subject to revision. It is being provided to meet the need for timely best science. The information is provided on the condition that neither the U.S. Geological Survey nor the U.S. Government may be held liable for any damages resulting from the authorized or unauthorized use of the information.


%------------------------------------------------------------
% BIBLIO
%------------------------------------------------------------
\begin{thebibliography}{10}

% \bibitem{HirschI}
% Helsel, D.R. and R. M. Hirsch, 2002. Statistical Methods in Water Resources Techniques of Water Resources Investigations, Book 4, chapter A3. U.S. Geological Survey. 522 pages. \url{http://pubs.usgs.gov/twri/twri4a3/}

\bibitem{HirschII}
Hirsch, R. M., Moyer, D. L. and Archfield, S. A. (2010), Weighted Regressions on Time, Discharge, and Season (WRTDS), with an Application to Chesapeake Bay River Inputs. JAWRA Journal of the American Water Resources Association, 46: 857-880. doi: 10.1111/j.1752-1688.2010.00482.x \url{http://onlinelibrary.wiley.com/doi/10.1111/j.1752-1688.2010.00482.x/full}

\bibitem{HirschIII}
Sprague, L. A., Hirsch, R. M., and Aulenbach, B. T. (2011), Nitrate in the Mississippi River and Its Tributaries, 1980 to 2008: Are We Making Progress? Environmental Science \& Technology, 45 (17): 7209-7216. doi: 10.1021/es201221s 

\bibitem{HirschIV}
Moyer, D.L., Hirsch, R.M., and Hyer, K.E. (2012), Comparison of Two Regression-Based Approaches for Determining Nutrient and Sediment Fluxes and Trends in the Chesapeake Bay Watershed: U.S. Geological Survey Scientific Investigations Report 2012-5244, 118 p. \url{http://pubs.usgs.gov/sir/2012/5244/}

\bibitem{HirschV}
Rice, K.C., and Hirsch, R.M. (2012), Spatial and temporal trends in runoff at long-term streamgages within and near the Chesapeake Bay Watershed: U.S. Geological Survey Scientific Investigations Report 2012-5151, 56 p. \url{http://pubs.usgs.gov/sir/2012/5151}


\end{thebibliography}

\end{document}

